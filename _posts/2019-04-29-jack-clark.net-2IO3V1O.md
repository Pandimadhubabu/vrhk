---

layout: post
category: product
title: "Import AI 144: Facial recognition sighted in US airports; Amazon pairs humans&amp;AI for data labeling; Facebook translates videos into videogames"
date: 2019-04-29 17:31:40
link: https://vrhk.co/2IO3V1O
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Amazon uses machine learning to automate its own data-labeling&nbsp;humans:&hellip;We heard you like AI so much we put AI inside your AI-data-labeling&nbsp;system&hellip;Amazon reveals ProduceNet, an ImageNet-inspired dataset of products. ProductNet is designed to help researchers train models that have as subtle and thorough an understanding of products, as equivalently-trained systems have with regard to classes of images. The goal for Amazon is to be able to better learn how to categorize products, and the researchers say in tests that this system can significantly improve the effectiveness of human data labelers.
Dataset composition: ProductNet consists of 3900 categories of product, with roughly 40-60 products for each category. &ldquo;We aim at the diversity and representativeness of the products. Being representative, the labeled data can be used as reference products to power product search, pricing, and other business applications,&rdquo; they write. &ldquo;Being diverse, the models are able to achieve strong generalization ability for unlabeled data, and the product embedding is also able to represent richer information&rdquo;.
ProductNet, what is it good for? ProductNet&rsquo;s main purpose appears to be helping Amazon to develop better systems to help its human contractors more efficiently label data, and creating a system that can directly label itself.
Labelling: ProductNet is designed to be tightly-integrated with human workers, who can collectively help Amazon better label its various items while continuously calibrating the AI system. It works like this: they start off by using a basic system (eg, Inception-v4 trained on ImageNet for processing images, and fastText for processing text data) to use to search over unlabelled images, then the humans annotate these and the labels are fed back into the master model, which is then used to surface more specific products, which the humans then annotate, and so on.
 &nbsp;&nbsp;20X gain: In tests, Amazon says human annotators augmented via ProductNet can label 100 things to flesh out the edge of a model in about 30 minutes, compared to humans who don&rsquo;t have access to the model which only manage around five data points during this time period. This represents a 20X gain through the use of the system, Amazon says. &nbsp;&nbsp;Read more: ProductNet: a Collection of High-Quality Datasets for Product Representation Learning (Arxiv).
#####################################################
AI + Facial Recognition + Airlines:What does it mean when airlines use facial recognition instead of passports &amp; boarding passes to let people onto planes? We can get a sense of the complex feelings this experience provokes by reading a Twitter thread from someone who experienced it, then questioned the airline (JetBlue) about its use of the tech.&nbsp;Read about what happens when someone finds facial recognition systems deployed at the boarding gate. (Twitter).
#####################################################
Down on the construction site: How to deploy AI in a specific context and the challenges you&rsquo;ll encounter:&hellip;AI is useless unless you can deploy it&hellip;There&rsquo;s a big difference between having an idea and implementing that idea; research from Iowa State University highlights this by discussing the steps needed to go from selecting a problem (for example: training image recognition systems to recognize images from construction sites) to solving that problem.
&ldquo;Based on extensive literature review, we found that most of the studies focus on development of improved techniques for image analytics, but a very few look at the economics of final deployment and the trade-off between accuracy and costs of deployment,&rdquo; the authors write. &ldquo;This paper aims at providing the researchers and engineers a practical and comprehensive deep learning based solution to detect construction equipment from the very first step of development to the last step, which is deployment of the solution&rdquo;.
Deployment &ndash; more than just a discrete step: The paper highlights the sorts of tradeoffs people need to make as they try to deploy systems, ranging from the lack of good open datasets for specific contexts (eg, here the users try to train a model for use on construction sites off of the comparatively small &lsquo;AIM&rsquo; subset of ImageNet) to the need to source efficient models (they use MobileNet), to needing to customize those models for specific hardware platforms (Raspberry Pis, Intel Jetsons, Intel Neural Compute Sticks, and so on.
Why this matters: As AI enters its deployment phase, research like this gives us a sense of the gulf between most research papers and actual deployable systems. It also provides a further bit of evidence in favor of &lsquo;MobileNet&rsquo;, which I&rsquo;m seeing crop up in an ever-increasing number of papers concerned with deploying AI systems, as opposed to just inventing them. &nbsp;&nbsp;Read more: A deep learning based solution for construction equipment detection: from development to deployment (Arxiv).
#####################################################
Enter the AI-generated Dungeon:&hellip; One big language model plus some crafted sentences = fun&hellip;Language models have started to get much more powerful as researchers have combined flexible components (eg: Transformers) with large datasets to train big, effective general-purpose models (see: ULMFiT, GPT2, BERT, etc). Language models, much like image classifiers, have a ranger of uses, and so it&rsquo;s interesting to see someone use a GPT2 model to create an online AI Dungeon game, where you navigate a scenario via reading blocks of texts and picking options &ndash; the twist here is it&rsquo;s all generated by the model.&nbsp; Play the game here: AI Dungeon.
#####################################################
Facebook wants to make videos into videogames:&hellip;vid2game extracts playable characters from videos&hellip;Facebook AI Research has published vid2game, an AI system that lets you select a person in a public video on the internet and develop the ability to control them, as though they are a character in a videogame. The approach also lets them change the background, so a tennis player can &ndash; for instance &ndash; walk off of the court and onto a (rendered) dirt road, et cetera.
The technique relies on two components: Pose2Pose and Pose2Frame; Pose2Pose lets you select a person in some footage and extract their pose information by building a 3D model of their body and using that to help you move them. Pose2Frame helps to match this body to a background, which lets you use this technology to take a person, control them, and change the context around them.
Why this matters: Systems like this show how we can use AI to (artificially) add greater agency to the world around us. This approach &ldquo;paves the way for new types of realistic and personalized games, which can be casually created from everyday videos&rdquo;, Facebook wrote.&nbsp;&nbsp;Read more: Vid2Game: Controllable Characters Extracted from Real-World Videos (Arxiv). &nbsp;&nbsp;Watch the technology work here (YouTube).
#####################################################
Making AI systems that can read the visual world:&hellip;Facebook creates dataset and develops technology to help it train AI models to read text in pictures&hellip;Researchers with Facebook AI Research and the Georgia Institute of Technology want to create AI systems that can look at the world around us &ndash; including the written world &ndash; and answer questions about it. Such systems could be useful to people with vision impairments who could interact with the world by asking their AI system questions about it, eg: what is in front of me right now? What items are on the menu in the restaurant? Which is the least expensive item on the menu in the restaurant? And so on.
If this sounds so simple, why is it hard? Think about what you …"

---

### Import AI 144: Facial recognition sighted in US airports; Amazon pairs humans&amp;AI for data labeling; Facebook translates videos into videogames

Amazon uses machine learning to automate its own data-labeling&nbsp;humans:&hellip;We heard you like AI so much we put AI inside your AI-data-labeling&nbsp;system&hellip;Amazon reveals ProduceNet, an ImageNet-inspired dataset of products. ProductNet is designed to help researchers train models that have as subtle and thorough an understanding of products, as equivalently-trained systems have with regard to classes of images. The goal for Amazon is to be able to better learn how to categorize products, and the researchers say in tests that this system can significantly improve the effectiveness of human data labelers.
Dataset composition: ProductNet consists of 3900 categories of product, with roughly 40-60 products for each category. &ldquo;We aim at the diversity and representativeness of the products. Being representative, the labeled data can be used as reference products to power product search, pricing, and other business applications,&rdquo; they write. &ldquo;Being diverse, the models are able to achieve strong generalization ability for unlabeled data, and the product embedding is also able to represent richer information&rdquo;.
ProductNet, what is it good for? ProductNet&rsquo;s main purpose appears to be helping Amazon to develop better systems to help its human contractors more efficiently label data, and creating a system that can directly label itself.
Labelling: ProductNet is designed to be tightly-integrated with human workers, who can collectively help Amazon better label its various items while continuously calibrating the AI system. It works like this: they start off by using a basic system (eg, Inception-v4 trained on ImageNet for processing images, and fastText for processing text data) to use to search over unlabelled images, then the humans annotate these and the labels are fed back into the master model, which is then used to surface more specific products, which the humans then annotate, and so on.
 &nbsp;&nbsp;20X gain: In tests, Amazon says human annotators augmented via ProductNet can label 100 things to flesh out the edge of a model in about 30 minutes, compared to humans who don&rsquo;t have access to the model which only manage around five data points during this time period. This represents a 20X gain through the use of the system, Amazon says. &nbsp;&nbsp;Read more: ProductNet: a Collection of High-Quality Datasets for Product Representation Learning (Arxiv).
#####################################################
AI + Facial Recognition + Airlines:What does it mean when airlines use facial recognition instead of passports &amp; boarding passes to let people onto planes? We can get a sense of the complex feelings this experience provokes by reading a Twitter thread from someone who experienced it, then questioned the airline (JetBlue) about its use of the tech.&nbsp;Read about what happens when someone finds facial recognition systems deployed at the boarding gate. (Twitter).
#####################################################
Down on the construction site: How to deploy AI in a specific context and the challenges you&rsquo;ll encounter:&hellip;AI is useless unless you can deploy it&hellip;There&rsquo;s a big difference between having an idea and implementing that idea; research from Iowa State University highlights this by discussing the steps needed to go from selecting a problem (for example: training image recognition systems to recognize images from construction sites) to solving that problem.
&ldquo;Based on extensive literature review, we found that most of the studies focus on development of improved techniques for image analytics, but a very few look at the economics of final deployment and the trade-off between accuracy and costs of deployment,&rdquo; the authors write. &ldquo;This paper aims at providing the researchers and engineers a practical and comprehensive deep learning based solution to detect construction equipment from the very first step of development to the last step, which is deployment of the solution&rdquo;.
Deployment &ndash; more than just a discrete step: The paper highlights the sorts of tradeoffs people need to make as they try to deploy systems, ranging from the lack of good open datasets for specific contexts (eg, here the users try to train a model for use on construction sites off of the comparatively small &lsquo;AIM&rsquo; subset of ImageNet) to the need to source efficient models (they use MobileNet), to needing to customize those models for specific hardware platforms (Raspberry Pis, Intel Jetsons, Intel Neural Compute Sticks, and so on.
Why this matters: As AI enters its deployment phase, research like this gives us a sense of the gulf between most research papers and actual deployable systems. It also provides a further bit of evidence in favor of &lsquo;MobileNet&rsquo;, which I&rsquo;m seeing crop up in an ever-increasing number of papers concerned with deploying AI systems, as opposed to just inventing them. &nbsp;&nbsp;Read more: A deep learning based solution for construction equipment detection: from development to deployment (Arxiv).
#####################################################
Enter the AI-generated Dungeon:&hellip; One big language model plus some crafted sentences = fun&hellip;Language models have started to get much more powerful as researchers have combined flexible components (eg: Transformers) with large datasets to train big, effective general-purpose models (see: ULMFiT, GPT2, BERT, etc). Language models, much like image classifiers, have a ranger of uses, and so it&rsquo;s interesting to see someone use a GPT2 model to create an online AI Dungeon game, where you navigate a scenario via reading blocks of texts and picking options &ndash; the twist here is it&rsquo;s all generated by the model.&nbsp; Play the game here: AI Dungeon.
#####################################################
Facebook wants to make videos into videogames:&hellip;vid2game extracts playable characters from videos&hellip;Facebook AI Research has published vid2game, an AI system that lets you select a person in a public video on the internet and develop the ability to control them, as though they are a character in a videogame. The approach also lets them change the background, so a tennis player can &ndash; for instance &ndash; walk off of the court and onto a (rendered) dirt road, et cetera.
The technique relies on two components: Pose2Pose and Pose2Frame; Pose2Pose lets you select a person in some footage and extract their pose information by building a 3D model of their body and using that to help you move them. Pose2Frame helps to match this body to a background, which lets you use this technology to take a person, control them, and change the context around them.
Why this matters: Systems like this show how we can use AI to (artificially) add greater agency to the world around us. This approach &ldquo;paves the way for new types of realistic and personalized games, which can be casually created from everyday videos&rdquo;, Facebook wrote.&nbsp;&nbsp;Read more: Vid2Game: Controllable Characters Extracted from Real-World Videos (Arxiv). &nbsp;&nbsp;Watch the technology work here (YouTube).
#####################################################
Making AI systems that can read the visual world:&hellip;Facebook creates dataset and develops technology to help it train AI models to read text in pictures&hellip;Researchers with Facebook AI Research and the Georgia Institute of Technology want to create AI systems that can look at the world around us &ndash; including the written world &ndash; and answer questions about it. Such systems could be useful to people with vision impairments who could interact with the world by asking their AI system questions about it, eg: what is in front of me right now? What items are on the menu in the restaurant? Which is the least expensive item on the menu in the restaurant? And so on.
If this sounds so simple, why is it hard? Think about what you …