---

layout: post
category: product
title: "Import AI 114: Synthetic images take a big leap forward with BigGANs; US lawmakers call for national AI strategy; researchers probe language reasoning via HotspotQA"
date: 2018-10-01 17:16:46
link: https://vrhk.co/2IuxCSF
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Getting hip to multi-hop reasoning with HotpotQA:&hellip;New dataset and benchmark designed to test common sense reasoning capabilities&hellip;Researchers with Carnegie Mellon University, Stanford University, the Montreal Institute for Learning Algorithms, and Google AI, have created a new dataset and associated competition designed to test the capabilities of question answering systems. The new dataset, HotspotQA, is far larger than many prior datasets designed for such tasks, and has been designed to require &lsquo;multi-hop&rsquo; reasoning to thereby test the growing sophistication of newer NLP systems at performing increasing cognitive tasks.&nbsp; HotpotQA consists of around ~113,000 Wikipedia-based question-answer pairs. Answering these questions correctly is designed to test for &lsquo;multi-hop&rsquo; reasoning &ndash; the ability for systems to look at multiple documents and perform basic iterative problem-solving to come up with correct answers. These questions were &ldquo;collected by crowdsourcing based on Wikipedia articles, where crowd workers are shown multiple supporting context documents and asked explicitly to come up with questions requiring reasoning about all of the documents&rdquo;. These workers also provide the supporting facts they use to answer these questions, providing a strong supervised training set. &nbsp;&nbsp;It&rsquo;s the data, stupid: To develop HotpotQA the researchers needed to themselves create a kind of multi-hop pipeline to be able to figure out what documents to give cloud workers to use to compose questions for. To do this, they mapped the Wikipedia Hyperlink Graph and used this information to build a directed graph, then they try to detect correspondences between these pairs. They also created a hand-made list of categories to use to compare things of similar categories (eg, basketball players, etc).&nbsp; Testing: HotpotQA can be used to test models&rsquo; capabilities in different ways, ranging from information retrieval to question answering. The researchers train a system to give a baseline and the results show that the (relatively strong baseline) obtains performance significantly below that of a competent human across all tasks (with the exception of certain &lsquo;supporting fact&rsquo; evaluations, in which it obtains performance on par with an average human). &nbsp;&nbsp;Why it matters: Natural language processing research is currently going through what some have called an &lsquo;ImageNet moment&rsquo; following recent algorithmic developments relating to the usage of memory and attention-based systems, which have demonstrated significantly higher performance across a range of reasoning tasks compared to prior techniques, while also being typically much simpler. Like with ImageNet and the associated supervised classification systems, these new types of NLP approaches require larger datasets to be trained on and evaluated against, and as with ImageNet it&rsquo;s likely that by scaling up techniques to take on challenges defined by datasets like HotpotQA progress in this domain will increase further.&nbsp; Caveat: As with all datasets with an associated competitive leaderboard it is feasible that HotpotQA could be relatively easy and systems could end up exceeding human performance against it in a relatively short amount of time &ndash; this happened over the past year with the Stanford SQuAD dataset. Hopefully the relatively higher sophistication of HotspotQA will protect against this. &nbsp;&nbsp;Read more: HotpotQA website with leaderboard and data (HotpotQA Github).&nbsp; Read more: HOTPOTQA: A Dataset for Diverse, Explainable Multi-hop Question Answering (Arxiv).
Administrative note regarding ICLR papers:This week was the deadline for submissions for the International Conference on Learning Representations. These papers are published under a blind review process as they are currently under review. This year, there were 1600 submissions to ICLR, up from 1000 in 2017, 500 in 2016, and 250 in 2015. I&rsquo;ll be going through some of these papers in this issue and others and will try to avoid making predictions about which organizations are behind which papers so as to respect the blind review process.
Computers can now generate (some) fake images that are indistinguishable from real ones:&hellip;BigGAN&rsquo;s show significant progression in capabilities in synthetic imagery&hellip;The researchers train GAN models with 2-4X the parameters and 8X the batch size compared to prior papers, and also introduce improve the stability of GAN training.&nbsp; Some of the implemented techniques mean that samples generated by such GAN models can be tuned, allowing for &ldquo;explicit, fine-grained control of the trade-off between sample variety and fidelity&rdquo;. What this means in practice is that you can &lsquo;tune&rsquo; how similar the types of generated images are to specific sets of images within the dataset, so for instance if you wanted to generate an image of a field containing a pond you might pick a few images to prioritize in training that contain ponds, whereas if you wanted to also tune the generated size of the pond you might pick images containing ponds of various sizes. The addition of this kind of semantic dial seems useful to me, particularly for using such systems to generate faked images with specific constraints on what they depict. &nbsp;&nbsp;Image quality: Images generated via these GANs are of a far superior quality than prior systems, and and can be outputted at relatively large resolutions of 512X512pixels. I encourage you to take a look at the paper and judge for yourself, but it&rsquo;s evident from the (cherry-picked) samples that given sufficient patience a determined person can now generate photoreal faked images as long as they have a precise enough set of data from which to train on.&nbsp; Problems remain: There are still some drawbacks to the approach; GANs are notorious for their instability during training, and developers of such systems need to develop increasingly sophisticated approaches to deal with the instabilities in training that manifest at increasingly larger scales, leading to a certain time-investment tradeoff inherent to the scale-up process. The researchers do devise some tricks to deal with this, but they&rsquo;re quite elaborate. &ldquo;We demonstrate that a combination of novel and existing techniques can reduce these instabilities, but complete training stability can only be achieved at a dramatic cost to performance,&rdquo; they write. &nbsp;&nbsp;Why it matters: One of the most interesting aspects of the paper is how simple the approach is: take today&rsquo;s techniques, try to scale them up, and conduct some targeted research into dealing with some of the rough edges of the problem space. This seems analogous to recent work on scaling up algorithms in RL, where both DeepMind and OpenAI have developed increasingly large-scale training methodologies paired with simple scaled-up algorithms (eg DQN, PPO, A2C, etc).&nbsp; &ldquo;We find that current GAN techniques are sufficient to enable scaling to large models and distributed, large-batch training. We find that we can dramatically improve the state of the art and train models up to 512&times;512 resolution without need for explicit multiscale methods,&rdquo; the researchers write. &nbsp;&nbsp;Read more: Large Scale GAN Training For High Fidelity Natural Image Synthesis (ICLR 2018 submissions, OpenReview).&nbsp; Check out the samples: Memo Akten has pulled together a bunch of interesting and/or weird samples from the model here, which are worth checking out (Memo Akten, Twitter).
Want better RL performance? Try remembering what you&rsquo;ve been doing recently:&hellip;Recurrent Replay Distributed DQN (R2D2) obtains state-of-the-art on Atari &amp; DMLab by a wide margin&hellip;R2D2 is based on a tweaked version of Ape-X, a large-scale reinforcement learning system developed by DeepMind which displays…"

---

### Import AI 114: Synthetic images take a big leap forward with BigGANs; US lawmakers call for national AI strategy; researchers probe language reasoning via HotspotQA

Getting hip to multi-hop reasoning with HotpotQA:&hellip;New dataset and benchmark designed to test common sense reasoning capabilities&hellip;Researchers with Carnegie Mellon University, Stanford University, the Montreal Institute for Learning Algorithms, and Google AI, have created a new dataset and associated competition designed to test the capabilities of question answering systems. The new dataset, HotspotQA, is far larger than many prior datasets designed for such tasks, and has been designed to require &lsquo;multi-hop&rsquo; reasoning to thereby test the growing sophistication of newer NLP systems at performing increasing cognitive tasks.&nbsp; HotpotQA consists of around ~113,000 Wikipedia-based question-answer pairs. Answering these questions correctly is designed to test for &lsquo;multi-hop&rsquo; reasoning &ndash; the ability for systems to look at multiple documents and perform basic iterative problem-solving to come up with correct answers. These questions were &ldquo;collected by crowdsourcing based on Wikipedia articles, where crowd workers are shown multiple supporting context documents and asked explicitly to come up with questions requiring reasoning about all of the documents&rdquo;. These workers also provide the supporting facts they use to answer these questions, providing a strong supervised training set. &nbsp;&nbsp;It&rsquo;s the data, stupid: To develop HotpotQA the researchers needed to themselves create a kind of multi-hop pipeline to be able to figure out what documents to give cloud workers to use to compose questions for. To do this, they mapped the Wikipedia Hyperlink Graph and used this information to build a directed graph, then they try to detect correspondences between these pairs. They also created a hand-made list of categories to use to compare things of similar categories (eg, basketball players, etc).&nbsp; Testing: HotpotQA can be used to test models&rsquo; capabilities in different ways, ranging from information retrieval to question answering. The researchers train a system to give a baseline and the results show that the (relatively strong baseline) obtains performance significantly below that of a competent human across all tasks (with the exception of certain &lsquo;supporting fact&rsquo; evaluations, in which it obtains performance on par with an average human). &nbsp;&nbsp;Why it matters: Natural language processing research is currently going through what some have called an &lsquo;ImageNet moment&rsquo; following recent algorithmic developments relating to the usage of memory and attention-based systems, which have demonstrated significantly higher performance across a range of reasoning tasks compared to prior techniques, while also being typically much simpler. Like with ImageNet and the associated supervised classification systems, these new types of NLP approaches require larger datasets to be trained on and evaluated against, and as with ImageNet it&rsquo;s likely that by scaling up techniques to take on challenges defined by datasets like HotpotQA progress in this domain will increase further.&nbsp; Caveat: As with all datasets with an associated competitive leaderboard it is feasible that HotpotQA could be relatively easy and systems could end up exceeding human performance against it in a relatively short amount of time &ndash; this happened over the past year with the Stanford SQuAD dataset. Hopefully the relatively higher sophistication of HotspotQA will protect against this. &nbsp;&nbsp;Read more: HotpotQA website with leaderboard and data (HotpotQA Github).&nbsp; Read more: HOTPOTQA: A Dataset for Diverse, Explainable Multi-hop Question Answering (Arxiv).
Administrative note regarding ICLR papers:This week was the deadline for submissions for the International Conference on Learning Representations. These papers are published under a blind review process as they are currently under review. This year, there were 1600 submissions to ICLR, up from 1000 in 2017, 500 in 2016, and 250 in 2015. I&rsquo;ll be going through some of these papers in this issue and others and will try to avoid making predictions about which organizations are behind which papers so as to respect the blind review process.
Computers can now generate (some) fake images that are indistinguishable from real ones:&hellip;BigGAN&rsquo;s show significant progression in capabilities in synthetic imagery&hellip;The researchers train GAN models with 2-4X the parameters and 8X the batch size compared to prior papers, and also introduce improve the stability of GAN training.&nbsp; Some of the implemented techniques mean that samples generated by such GAN models can be tuned, allowing for &ldquo;explicit, fine-grained control of the trade-off between sample variety and fidelity&rdquo;. What this means in practice is that you can &lsquo;tune&rsquo; how similar the types of generated images are to specific sets of images within the dataset, so for instance if you wanted to generate an image of a field containing a pond you might pick a few images to prioritize in training that contain ponds, whereas if you wanted to also tune the generated size of the pond you might pick images containing ponds of various sizes. The addition of this kind of semantic dial seems useful to me, particularly for using such systems to generate faked images with specific constraints on what they depict. &nbsp;&nbsp;Image quality: Images generated via these GANs are of a far superior quality than prior systems, and and can be outputted at relatively large resolutions of 512X512pixels. I encourage you to take a look at the paper and judge for yourself, but it&rsquo;s evident from the (cherry-picked) samples that given sufficient patience a determined person can now generate photoreal faked images as long as they have a precise enough set of data from which to train on.&nbsp; Problems remain: There are still some drawbacks to the approach; GANs are notorious for their instability during training, and developers of such systems need to develop increasingly sophisticated approaches to deal with the instabilities in training that manifest at increasingly larger scales, leading to a certain time-investment tradeoff inherent to the scale-up process. The researchers do devise some tricks to deal with this, but they&rsquo;re quite elaborate. &ldquo;We demonstrate that a combination of novel and existing techniques can reduce these instabilities, but complete training stability can only be achieved at a dramatic cost to performance,&rdquo; they write. &nbsp;&nbsp;Why it matters: One of the most interesting aspects of the paper is how simple the approach is: take today&rsquo;s techniques, try to scale them up, and conduct some targeted research into dealing with some of the rough edges of the problem space. This seems analogous to recent work on scaling up algorithms in RL, where both DeepMind and OpenAI have developed increasingly large-scale training methodologies paired with simple scaled-up algorithms (eg DQN, PPO, A2C, etc).&nbsp; &ldquo;We find that current GAN techniques are sufficient to enable scaling to large models and distributed, large-batch training. We find that we can dramatically improve the state of the art and train models up to 512&times;512 resolution without need for explicit multiscale methods,&rdquo; the researchers write. &nbsp;&nbsp;Read more: Large Scale GAN Training For High Fidelity Natural Image Synthesis (ICLR 2018 submissions, OpenReview).&nbsp; Check out the samples: Memo Akten has pulled together a bunch of interesting and/or weird samples from the model here, which are worth checking out (Memo Akten, Twitter).
Want better RL performance? Try remembering what you&rsquo;ve been doing recently:&hellip;Recurrent Replay Distributed DQN (R2D2) obtains state-of-the-art on Atari &amp; DMLab by a wide margin&hellip;R2D2 is based on a tweaked version of Ape-X, a large-scale reinforcement learning system developed by DeepMind which displays…