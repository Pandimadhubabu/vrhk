---

layout: post
category: product
title: "Import AI 118: AirBnB splices neural net into its search engine; simulating robots that touch with UnrealROX; and how long it takes to build a quadcopter from scratch"
date: 2018-10-30 05:01:45
link: https://vrhk.co/2DbLykG
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Building a quadcopter from scratch in ten weeks:&hellip;Modeling the drone ecosystem by what it takes to build one&hellip;The University of California at San Diego recently ran a course where students got the chance to design, build, and program their own drones. A writeup of the paper outlines how the course is structured and gives us a sense of what it takes to build a drone today.&nbsp; &nbsp;Four easy pieces: The course breaks building the drones into four phases: designing the PCB, implementing the flight control software, assembling the PCB, and getting the quadcopter flying. Each of this phases has numerous discrete steps which are detailed in the report. One of the nice things about the curriculum is the focus on the cost of errors: &ldquo;Students &lsquo;pay&rsquo; for design reviews (by course staff or QuadLint) with points deduced from their lab grade,&rdquo; they write. &ldquo;This incentivizes them to find and fix problems themselves by inspection rather than relying on QuadLint or the staff&rdquo;. &nbsp;&nbsp;The surprising difficulty of drone software: Building the flight controller software for the drone proves to be one of the most challenging aspects of the research because of the numerous potential causes for bugs, so root cause analysis can be challenging.&nbsp;&nbsp;Teaching tools: While developing the course the instructors noticed that they were spending a lot of time checking and evaluating PCB designs for correctness, so they designed their own program called &lsquo;QuadLint&rsquo; to try to auto-analyze and grade these submissions. &ldquo;QuadLint is, we believe, the first autograder that checks specific design requirements for PCB designs,&rdquo; they write. &nbsp;&nbsp;Costs: The report includes some interesting details on the cost of these low-powered drones, with the quadcopter itself costing about $35 per PCB plus $40 for the components. Currently, the most expensive component of the course is the remote ($150) and for the next course the teachers are evaluating cheaper options. &nbsp;&nbsp;Small scale: The quadcopters all use a PCB to host their electronics and serve as an airframe. They measure less than 10 cm on a side and are suitable for flight indoors over short distances. &ldquo;The motors are moderately powerful, &ldquo;brushed&rdquo; electric motors powered by a small lithium-polymer (LiPo) battery, and we use small, plastic propellers. The quadcopters are easy to operate safely, and a blow from the propeller at full speed is painful but not particularly dangerous. Students wear eye protection around their flying quadcopters.&rdquo; &nbsp;&nbsp;Why it matters: In paper notes that the &lsquo;killer apps&rsquo; of the future &ldquo;will lie at the intersection of hardware, software, sensing, robotics, and/or wireless communications&rdquo;. This seems true &ndash; especially when we look at the chance for major uptake from the success of companies like DJI and the possibility for unit economics driving the price down. Therefore, tracking and measuring the cost and ease with which people can build and assemble them out of (hard to track, commodity) components gives us better intuitions about this aspect of drones+security. While the hardware and software is under-powered and somewhat pricey today it won&rsquo;t stay that way for long. &nbsp;&nbsp;Read more: Trial by Flyer: Building Quadcopters From Scratch in a Ten-Week Capstone Course (Arxiv).
Amazon tries to make Alexa smarter via richer conversational data:&hellip;Who needs AI breakthroughs when you&rsquo;ve got a BiLSTM, lots of data, and patience?&hellip;Amazon researchers are trying to give personal assistants like Alexa the ability to have long-term, conversations about specific topics. The (rather unsurprising) finding they make in a new research paper is is that you can &ldquo;extend previous work on neural topic classification and unsupervised topic keyword detection by incorporating conversational context and dialog act features&rdquo;, yielding personal assistants capable of longer and more coherent conversations than their forebears, if you can afford to annotate the data.&nbsp; Data used: The researchers used data collected during the 2017 &lsquo;Alexa Prize&rsquo; competition, which consists of over 100,000 utterances containing interactions between users and chatbots. They augmented this data by classifying the topic for each utterance into one of 12 categories (eg: politics, fashion, science &amp; technology, etc), and also trying to classify the goal of the user or chatbot (eg: clarification, information request, topic switch, etc). They also asked other annotators to rank every single chatbot response with metrics relating to how comprehensible &nbsp;it was, how relevant the response was, how interesting it was, and whether a user might want to continue the conversation with the bot. &nbsp;&nbsp;Baselines and BiLSTMs: The researchers implement two baselines (DAN, based on a bag-of-words neural model; ADAN, which is DAN extend with attention), and then develop two versions of a bidirectional LSTM (BiLSTM) system, where one uses context from the annotated dataset and the other doesn&rsquo;t. They then evaluate all these methods by testing their baselines (which contain only the current utterance) against systems which incorporate context, systems which incorporate data, and systems which incorporate both context and data. The results show that a BiLSTM fed with context in sequence does almost twice as well as a baseline ADAN system that uses context and dialog, and almost 25% better than a DAN fed with both context and dialog.&nbsp; Why it matters: The results indicate that &ndash; if a developer can afford the labeling cost &ndash; it&rsquo;s possible to augment language interaction datasets with additional information about context and topic to create more powerful systems, which seems to imply that in the language space we can expect to see large companies invest in teams of people to not just transcribe and label text at a basic level, but also perform more elaborate meta-classifications as well. The industrialization of deep learning continues! &nbsp;&nbsp;Read more: Contextual Topic Modeling For Dialog Systems (Arxiv).
Why AI won&rsquo;t be efficiently solving a 2D gridworld quest soon:&hellip;Want humans to be able to train AIs? The key is curriculum learning and interactive learning, says BabyAI creators&hellip;Researchers with the Montreal Institute for Learning Algorithms (MILA) have designed a free tool called BabyAI to let them test AI systems&rsquo; ability to learn generalizable skills from curriculums of tasks set in an efficient 2D gridworld environment &ndash; and the results show that today&rsquo;s AI algorithms display poor data efficiency and generalization at this sort of task. &nbsp;&nbsp;Data efficiency: BabyAI uses gridworlds for its environment, which the researchers have written to be efficient enough that researchers can use the platform without needing access to vast pools of compute; the BabyAI environments can be run at up to 3,000 frames per second &ldquo;on a modern multi-core laptop&rdquo; and can also be integrated with OpenAI Gym). &nbsp;&nbsp;A specific language: BabyAI uses &ldquo;a comparatively small yet combinatorially rich subset of English&rdquo; called Baby Language. This is meant to help researchers write increasingly sophisticated strings of instructions for agents, while keeping the state space from exploding too quickly. &nbsp;&nbsp;Levels as a curriculum: BabyAI ships with 19 levels which increase in difficulty of both the environment, and the complexity of the language required to solve it. The levels test each agent on a variety of 13 different competencies, ranging from things like being able to unlock doors, navigating to locations, ignoring distractors placed into the environment, navigating mazes, and so on. The researchers also design a bot which can solve any of the levels using a variety o…"

---

### Import AI 118: AirBnB splices neural net into its search engine; simulating robots that touch with UnrealROX; and how long it takes to build a quadcopter from scratch

Building a quadcopter from scratch in ten weeks:&hellip;Modeling the drone ecosystem by what it takes to build one&hellip;The University of California at San Diego recently ran a course where students got the chance to design, build, and program their own drones. A writeup of the paper outlines how the course is structured and gives us a sense of what it takes to build a drone today.&nbsp; &nbsp;Four easy pieces: The course breaks building the drones into four phases: designing the PCB, implementing the flight control software, assembling the PCB, and getting the quadcopter flying. Each of this phases has numerous discrete steps which are detailed in the report. One of the nice things about the curriculum is the focus on the cost of errors: &ldquo;Students &lsquo;pay&rsquo; for design reviews (by course staff or QuadLint) with points deduced from their lab grade,&rdquo; they write. &ldquo;This incentivizes them to find and fix problems themselves by inspection rather than relying on QuadLint or the staff&rdquo;. &nbsp;&nbsp;The surprising difficulty of drone software: Building the flight controller software for the drone proves to be one of the most challenging aspects of the research because of the numerous potential causes for bugs, so root cause analysis can be challenging.&nbsp;&nbsp;Teaching tools: While developing the course the instructors noticed that they were spending a lot of time checking and evaluating PCB designs for correctness, so they designed their own program called &lsquo;QuadLint&rsquo; to try to auto-analyze and grade these submissions. &ldquo;QuadLint is, we believe, the first autograder that checks specific design requirements for PCB designs,&rdquo; they write. &nbsp;&nbsp;Costs: The report includes some interesting details on the cost of these low-powered drones, with the quadcopter itself costing about $35 per PCB plus $40 for the components. Currently, the most expensive component of the course is the remote ($150) and for the next course the teachers are evaluating cheaper options. &nbsp;&nbsp;Small scale: The quadcopters all use a PCB to host their electronics and serve as an airframe. They measure less than 10 cm on a side and are suitable for flight indoors over short distances. &ldquo;The motors are moderately powerful, &ldquo;brushed&rdquo; electric motors powered by a small lithium-polymer (LiPo) battery, and we use small, plastic propellers. The quadcopters are easy to operate safely, and a blow from the propeller at full speed is painful but not particularly dangerous. Students wear eye protection around their flying quadcopters.&rdquo; &nbsp;&nbsp;Why it matters: In paper notes that the &lsquo;killer apps&rsquo; of the future &ldquo;will lie at the intersection of hardware, software, sensing, robotics, and/or wireless communications&rdquo;. This seems true &ndash; especially when we look at the chance for major uptake from the success of companies like DJI and the possibility for unit economics driving the price down. Therefore, tracking and measuring the cost and ease with which people can build and assemble them out of (hard to track, commodity) components gives us better intuitions about this aspect of drones+security. While the hardware and software is under-powered and somewhat pricey today it won&rsquo;t stay that way for long. &nbsp;&nbsp;Read more: Trial by Flyer: Building Quadcopters From Scratch in a Ten-Week Capstone Course (Arxiv).
Amazon tries to make Alexa smarter via richer conversational data:&hellip;Who needs AI breakthroughs when you&rsquo;ve got a BiLSTM, lots of data, and patience?&hellip;Amazon researchers are trying to give personal assistants like Alexa the ability to have long-term, conversations about specific topics. The (rather unsurprising) finding they make in a new research paper is is that you can &ldquo;extend previous work on neural topic classification and unsupervised topic keyword detection by incorporating conversational context and dialog act features&rdquo;, yielding personal assistants capable of longer and more coherent conversations than their forebears, if you can afford to annotate the data.&nbsp; Data used: The researchers used data collected during the 2017 &lsquo;Alexa Prize&rsquo; competition, which consists of over 100,000 utterances containing interactions between users and chatbots. They augmented this data by classifying the topic for each utterance into one of 12 categories (eg: politics, fashion, science &amp; technology, etc), and also trying to classify the goal of the user or chatbot (eg: clarification, information request, topic switch, etc). They also asked other annotators to rank every single chatbot response with metrics relating to how comprehensible &nbsp;it was, how relevant the response was, how interesting it was, and whether a user might want to continue the conversation with the bot. &nbsp;&nbsp;Baselines and BiLSTMs: The researchers implement two baselines (DAN, based on a bag-of-words neural model; ADAN, which is DAN extend with attention), and then develop two versions of a bidirectional LSTM (BiLSTM) system, where one uses context from the annotated dataset and the other doesn&rsquo;t. They then evaluate all these methods by testing their baselines (which contain only the current utterance) against systems which incorporate context, systems which incorporate data, and systems which incorporate both context and data. The results show that a BiLSTM fed with context in sequence does almost twice as well as a baseline ADAN system that uses context and dialog, and almost 25% better than a DAN fed with both context and dialog.&nbsp; Why it matters: The results indicate that &ndash; if a developer can afford the labeling cost &ndash; it&rsquo;s possible to augment language interaction datasets with additional information about context and topic to create more powerful systems, which seems to imply that in the language space we can expect to see large companies invest in teams of people to not just transcribe and label text at a basic level, but also perform more elaborate meta-classifications as well. The industrialization of deep learning continues! &nbsp;&nbsp;Read more: Contextual Topic Modeling For Dialog Systems (Arxiv).
Why AI won&rsquo;t be efficiently solving a 2D gridworld quest soon:&hellip;Want humans to be able to train AIs? The key is curriculum learning and interactive learning, says BabyAI creators&hellip;Researchers with the Montreal Institute for Learning Algorithms (MILA) have designed a free tool called BabyAI to let them test AI systems&rsquo; ability to learn generalizable skills from curriculums of tasks set in an efficient 2D gridworld environment &ndash; and the results show that today&rsquo;s AI algorithms display poor data efficiency and generalization at this sort of task. &nbsp;&nbsp;Data efficiency: BabyAI uses gridworlds for its environment, which the researchers have written to be efficient enough that researchers can use the platform without needing access to vast pools of compute; the BabyAI environments can be run at up to 3,000 frames per second &ldquo;on a modern multi-core laptop&rdquo; and can also be integrated with OpenAI Gym). &nbsp;&nbsp;A specific language: BabyAI uses &ldquo;a comparatively small yet combinatorially rich subset of English&rdquo; called Baby Language. This is meant to help researchers write increasingly sophisticated strings of instructions for agents, while keeping the state space from exploding too quickly. &nbsp;&nbsp;Levels as a curriculum: BabyAI ships with 19 levels which increase in difficulty of both the environment, and the complexity of the language required to solve it. The levels test each agent on a variety of 13 different competencies, ranging from things like being able to unlock doors, navigating to locations, ignoring distractors placed into the environment, navigating mazes, and so on. The researchers also design a bot which can solve any of the levels using a variety o…