---

layout: post
category: product
title: "Import AI 107: Training ImageNet in 18 minutes for $40; courteous self-driving cars; and Google evolves alternatives to backprop"
date: 2018-08-13 22:56:49
link: https://vrhk.co/2P7DNP8
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Better robot cars through programmed courteousness:&hellip;Defining polite behaviors leads to better driving for everyone&hellip;How will self-driving cars and humans interact? That&rsquo;s a difficult question, since AI systems tend to behave differently to humans when trying to solve tasks. Now researchers with the University of California at Berkeley have tried to come up with a way to program &lsquo;courteous&rsquo; behavior into self-driving cars to make them easier for humans to interact with. Their work deals with situations where humans and cars must anticipate each other&rsquo;s actions, like when both approach an intersection, or change lanes. &ldquo;We focus on what the robot should optimize in such situations, particularly if we consider the fact that humans are not perfectly rational&rdquo;, they write.&nbsp; Programmed courteousness: Because &ldquo;humans &hellip; weight losses higher than gains when evaluating their actions&rdquo; the researchers formalize the relationship between robot-driven and human-driven cars with this constraint, and develop a theoretical framework to let the car predict actions it can take to benefit the driving experience of a human. The researchers test their courteous approach by simulating scenarios involving simulated humans and self-driving cars. These include: changing lanes, in which more courteous cars lead to less inconvenience for the human; and turning left, in which the self-driving car will wait for the human to pass at an intersection and thereby reduce disruption. The results show that cars programmed with a sense of courteousness tend to improve the experience of human&rsquo;s driving on their roads, and the higher the scientist sets the courteousness parameter, the better the experience the human drivers have. &nbsp;&nbsp;Multiple agents: The researchers also observe how courteousness works in complex situations that involve multiple cars. In one scenario &ldquo;an interesting behavior emerges: the autonomous car first backs up to block the third agent (the following car) from interrupting the human driver until the human driver safely passes them, and then the robot car finishes its task. This displays truly collaborative behavior, and only happens with high enough weight on the courtesy term. This may not be practical for real on-road driving, but it enables the design of highly courteous robots in some particular scenarios where human have higher priority over all other autonomous agents,&rdquo; they write.&nbsp;&nbsp;Why it matters: We&rsquo;re heading into a future where we deploy autonomous systems into the same environments as humans, so figuring out how to create AI systems that can adapt to human behaviors and account for the peculiarities of people will speed uptake. In the long term, development of such systems may also give us a better sense of how humans themselves behave &ndash; in this paper, the researchers make a preliminary attempt at this by modeling how well their courteousness techniques predict real human behaviors. &nbsp;&nbsp;&nbsp;Read more: Courteous Autonomous Cars (Arxiv).
Backprop is great, but have you tried BACKPROP EVOLUTION?&hellip;Googlers try to evolve replacement to the widely used gradient calculation technique&hellip;Google researchers have used evolution to try and find a replacement for back-propagation, one of the fundamental algorithms used in today&rsquo;s neural network-based systems. The Google researchers try to do this by offloading the task of figuring out such an alternative to computers. They do this by designing a domain-specific language (DSL) which describes mathematical formulas like back-propagation in functional terms, then they use this DSL to search through the mathematical space to find improved versions of the algorithm. This lets them run an evolutionary search process where they use the DSL to automatically explore the mathematical space of such algorithms and periodically evaluated evolved candidates by using candidate algorithms to train a Wide ResNet with 16 layers on the CIFAR-10 dataset. &nbsp;&nbsp;Evaluation: Following the evolution search, the researchers evaluate well-performing algorithms on a Wide ResNet (the same one used during the evolution phase) as well as a larger ResNet, both tested for 20 epochs; they also evaluate performance in longer training regimes by testing performance on a ResNet for 100 epochs.&nbsp; So, did they come up with something better than back-propagation? Sort of: The best performing algorithms found through this evolutionary search display faster initial training times than back-propagation, but when evaluated for 100 epochs show the same performance as methods trained with traditional back-propagation. &ldquo;The previous search experiment finds update equations that work well at the beginning of training but do not outperform back-propagation at convergence. The latter result is potentially due to the mismatch between the search and the testing regimes, since the search used 20 epochs to train child models whereas the test regime uses 100 epochs,&rdquo; they write. That initial speedup could hold some advantages, but the method will need to be proved out more at larger epochs to see if it can develop something that scales better to larger-than-trained-upon temporal sequences. &nbsp;&nbsp;Why it matters: This work fits within a pattern displayed by some AI researchers &ndash; typically ones who work at organizations with very large quantities of computers &ndash; of trying to evolve algorithmic breakthroughs, rather than designing them themselves. This sort of research seems of a different kind to other research, seeing people try to offload the work of problem solving to computers, and instead use their scientific skills to set up the parameters of the evolutionary process that might find a solution. It remains to be seen how effective these techniques are in practice, but it&rsquo;s a definite trend. The question is whether the relative computational inefficiency of such techniques is worth the trade-off. &nbsp;&nbsp;&nbsp;Read more: Backprop Evolution (Arxiv).
Think your image classifier is tough? Test it on the Adversarial Vision Challenge:&hellip;Challenge tests participants&rsquo; ability to create more powerful adversarial inputs&hellip;A team of researchers from the University of Tubingen, Google Brain, Pennsylvania State University and EPFL have created the &lsquo;Adversarial Vision Challenge&rsquo;, which &ldquo;is designed to facilitate measurable progress towards robust machine vision models and more generally applicable adversarial attacks&rdquo;. Adversarial attacks are like optical illusions for machine learning systems, altering the pixels of an image in a way indistinguishable to human eyes but which causes the deployed AI classifier to label an image incorrectly. &nbsp;&nbsp;The tasks: Participants will be evaluated on their skills at three tasks: generating untargeted adversarial examples (given a sample image and access to a model, try to create an adversarial image which is superficially identical to the sample image but is incorrectly labelled); generating targeted adversarial examples (given a sample image, a target label, and the model, try to force the sample image to be mislabeled with the target label; for example, getting an image of a $10 cheque re-classified as a $10,000 cheque); and increasing the size of minimum adversarial examples (trying to create the most severe adversarial examples that are still superficially similar to the provided image). &nbsp;&nbsp;Dataset used: The competition uses the Tiny ImageNet dataset, which contains 100,000 images across 200 classes from ImageNet, scaled down to 64X64 pixel dimensions, making the dataset cheaper and easier to test models on.&nbsp;&nbsp;Details: Submissions are open now. Deadline for final submissions is November 1st 2018. Amazon Web Services is sponsoring roughly $65,000 worth of compute resources which will …"

---

### Import AI 107: Training ImageNet in 18 minutes for $40; courteous self-driving cars; and Google evolves alternatives to backprop

Better robot cars through programmed courteousness:&hellip;Defining polite behaviors leads to better driving for everyone&hellip;How will self-driving cars and humans interact? That&rsquo;s a difficult question, since AI systems tend to behave differently to humans when trying to solve tasks. Now researchers with the University of California at Berkeley have tried to come up with a way to program &lsquo;courteous&rsquo; behavior into self-driving cars to make them easier for humans to interact with. Their work deals with situations where humans and cars must anticipate each other&rsquo;s actions, like when both approach an intersection, or change lanes. &ldquo;We focus on what the robot should optimize in such situations, particularly if we consider the fact that humans are not perfectly rational&rdquo;, they write.&nbsp; Programmed courteousness: Because &ldquo;humans &hellip; weight losses higher than gains when evaluating their actions&rdquo; the researchers formalize the relationship between robot-driven and human-driven cars with this constraint, and develop a theoretical framework to let the car predict actions it can take to benefit the driving experience of a human. The researchers test their courteous approach by simulating scenarios involving simulated humans and self-driving cars. These include: changing lanes, in which more courteous cars lead to less inconvenience for the human; and turning left, in which the self-driving car will wait for the human to pass at an intersection and thereby reduce disruption. The results show that cars programmed with a sense of courteousness tend to improve the experience of human&rsquo;s driving on their roads, and the higher the scientist sets the courteousness parameter, the better the experience the human drivers have. &nbsp;&nbsp;Multiple agents: The researchers also observe how courteousness works in complex situations that involve multiple cars. In one scenario &ldquo;an interesting behavior emerges: the autonomous car first backs up to block the third agent (the following car) from interrupting the human driver until the human driver safely passes them, and then the robot car finishes its task. This displays truly collaborative behavior, and only happens with high enough weight on the courtesy term. This may not be practical for real on-road driving, but it enables the design of highly courteous robots in some particular scenarios where human have higher priority over all other autonomous agents,&rdquo; they write.&nbsp;&nbsp;Why it matters: We&rsquo;re heading into a future where we deploy autonomous systems into the same environments as humans, so figuring out how to create AI systems that can adapt to human behaviors and account for the peculiarities of people will speed uptake. In the long term, development of such systems may also give us a better sense of how humans themselves behave &ndash; in this paper, the researchers make a preliminary attempt at this by modeling how well their courteousness techniques predict real human behaviors. &nbsp;&nbsp;&nbsp;Read more: Courteous Autonomous Cars (Arxiv).
Backprop is great, but have you tried BACKPROP EVOLUTION?&hellip;Googlers try to evolve replacement to the widely used gradient calculation technique&hellip;Google researchers have used evolution to try and find a replacement for back-propagation, one of the fundamental algorithms used in today&rsquo;s neural network-based systems. The Google researchers try to do this by offloading the task of figuring out such an alternative to computers. They do this by designing a domain-specific language (DSL) which describes mathematical formulas like back-propagation in functional terms, then they use this DSL to search through the mathematical space to find improved versions of the algorithm. This lets them run an evolutionary search process where they use the DSL to automatically explore the mathematical space of such algorithms and periodically evaluated evolved candidates by using candidate algorithms to train a Wide ResNet with 16 layers on the CIFAR-10 dataset. &nbsp;&nbsp;Evaluation: Following the evolution search, the researchers evaluate well-performing algorithms on a Wide ResNet (the same one used during the evolution phase) as well as a larger ResNet, both tested for 20 epochs; they also evaluate performance in longer training regimes by testing performance on a ResNet for 100 epochs.&nbsp; So, did they come up with something better than back-propagation? Sort of: The best performing algorithms found through this evolutionary search display faster initial training times than back-propagation, but when evaluated for 100 epochs show the same performance as methods trained with traditional back-propagation. &ldquo;The previous search experiment finds update equations that work well at the beginning of training but do not outperform back-propagation at convergence. The latter result is potentially due to the mismatch between the search and the testing regimes, since the search used 20 epochs to train child models whereas the test regime uses 100 epochs,&rdquo; they write. That initial speedup could hold some advantages, but the method will need to be proved out more at larger epochs to see if it can develop something that scales better to larger-than-trained-upon temporal sequences. &nbsp;&nbsp;Why it matters: This work fits within a pattern displayed by some AI researchers &ndash; typically ones who work at organizations with very large quantities of computers &ndash; of trying to evolve algorithmic breakthroughs, rather than designing them themselves. This sort of research seems of a different kind to other research, seeing people try to offload the work of problem solving to computers, and instead use their scientific skills to set up the parameters of the evolutionary process that might find a solution. It remains to be seen how effective these techniques are in practice, but it&rsquo;s a definite trend. The question is whether the relative computational inefficiency of such techniques is worth the trade-off. &nbsp;&nbsp;&nbsp;Read more: Backprop Evolution (Arxiv).
Think your image classifier is tough? Test it on the Adversarial Vision Challenge:&hellip;Challenge tests participants&rsquo; ability to create more powerful adversarial inputs&hellip;A team of researchers from the University of Tubingen, Google Brain, Pennsylvania State University and EPFL have created the &lsquo;Adversarial Vision Challenge&rsquo;, which &ldquo;is designed to facilitate measurable progress towards robust machine vision models and more generally applicable adversarial attacks&rdquo;. Adversarial attacks are like optical illusions for machine learning systems, altering the pixels of an image in a way indistinguishable to human eyes but which causes the deployed AI classifier to label an image incorrectly. &nbsp;&nbsp;The tasks: Participants will be evaluated on their skills at three tasks: generating untargeted adversarial examples (given a sample image and access to a model, try to create an adversarial image which is superficially identical to the sample image but is incorrectly labelled); generating targeted adversarial examples (given a sample image, a target label, and the model, try to force the sample image to be mislabeled with the target label; for example, getting an image of a $10 cheque re-classified as a $10,000 cheque); and increasing the size of minimum adversarial examples (trying to create the most severe adversarial examples that are still superficially similar to the provided image). &nbsp;&nbsp;Dataset used: The competition uses the Tiny ImageNet dataset, which contains 100,000 images across 200 classes from ImageNet, scaled down to 64X64 pixel dimensions, making the dataset cheaper and easier to test models on.&nbsp;&nbsp;Details: Submissions are open now. Deadline for final submissions is November 1st 2018. Amazon Web Services is sponsoring roughly $65,000 worth of compute resources which will …