---

layout: post
category: product
title: "Import AI 143: Predicting car accident risks by looking at the houses people live in; why data matters as much as compute; and using capsule networks to generate synthetic data"
date: 2019-04-22 18:46:38
link: https://vrhk.co/2L4pCNc
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Predicting car accident risks from Google Street View images:&hellip;The surprising correspondences between different types of data&hellip;Researchers with the University of Warsaw and Stanford University have shown how to use pictures from people&rsquo;s houses to better predict the chances of that person getting into a car accident. (Import AI administrative note &ndash; standard warnings about &lsquo;correlation does not imply&rsquo; causation apply).
For the project, the researchers analyzed 20,000 addresses of insurance company clients &ndash; a random sample of an insurer&rsquo;s portfolio collected in Poland between January 2012 and December 2015. For each address, they collect an overhead Google satellite view and a Google Street View image of the property, and humans then annotate the image with labels relating to the type of property, age, condition, estimate wealth of its residents, along with the type and density of buildings in the neighborhood. They subsequently test these variables and find that five of the seven have significant with regard to the insurance prediction problem. 
 &nbsp;&nbsp;&ldquo;Despite the high volatility of data, adding our five simple variables to the insurer&rsquo;s model improves its performance in 18 out of 20 resampling trials and the average improvement of the Gini coefficient is nearly 2 percentage points,&rdquo; they write.
Ultimately, they show that &ndash; to a statistically significant extent &ndash; &ldquo;features visible on a picture of a house can be predictive of car accident risk, independently from classically used variables such as age, or zip code&rdquo;.
Why this matters: Studies like this speak to the power of large-scale data analysis, highlighting how data that is innocuous at the level of the individual can become significant when compared and contrasted with a vast amount of other data. The researchers acknowledge this, noting that: &nbsp;&ldquo;modern data collection and computational techniques, which allow for unprecedented exploitation of personal data, can outpace development of legislation and raise privacy threats&rdquo;.&nbsp;&nbsp;Read more: Google Street View image of a house predicts car accident risk of its resident (Arxiv).
#####################################################
Your next pothole could be inspected via drone:&hellip;Drones + NVIDIA cards + smart algorithms = automated robot inspectors&hellip;Researchers with HKUST Robotics Institute have created a prototype drone system that can be used to automatically analyze a road surface. The project sees the researchers develop a dense stereo vision algorithm which the UAV uses to analyze the road surface. They&rsquo;re able to use this algorithm to process road images on the drone in real-time, automatically identifying surface-area disparities.
Hardware: To accomplish this, they use a ZED stereo camera mounted on a DJI Matrice 100 drone, which itself has a JETSON TX2 GPU installed onboard for real-time processing.
Why this matters: AI approaches make it cheap for robots to automatically sense&amp;analyze aspects of the world, and experiments like this suggest that we&rsquo;re rapidly approaching the era when we&rsquo;ll start to automate various types of surveillance (both for civil and military purposes) via drones.&nbsp;&nbsp;Read more: Real-Time Dense Stereo Embedded in a UAV for Road Inspection (Arxiv). &nbsp;&nbsp;Get the datasets used in the experiment here (Rui Fan, HKUST, personal website). &nbsp;&nbsp;Check out a video of the drone here (Rui Fan, YouTube).
#####################################################
Train AI to watch over the world with the iWildCam dataset:&hellip;Monitoring the planet with deep learning-based systems&hellip;Researchers with the California Institute of Technology have published the iWildCam dataset to help people develop AI systems that can automatically analyze wildlife seen in camera traps spread across the American Southwest. They&rsquo;ve also created a challenge based around the dataset, letting researchers compete in developing AI systems capable of automatically monitoring the world.
Testing generalization: &ldquo;If we wish to build systems that are trained once to detect and classify animals, and then deployed to new locations without further training, we must measure the ability of machine learning and computer vision to generalize to new environments,&rdquo; the researchers write.
Common nuisances: There are six problems relating to the data gathered from the traps: variable illumination, motion blur, size of the region of interest (eg, an animal might be small and far away from the camera), occlusion, camouflage, and perspective.
iWildCam: The images come from cameras installed across the American Southwest, consisting of 292,732 images spread between 143 locations. iWildCam is designed to capture the complexities of the datasets that human biologists need to deal with: &ldquo;therefore the data is unbalanced in the number of images per location, distribution of species per location, and distribution of species overall&rdquo;, they write.
Why this matters: Datasets like this &ndash; and AI systems built on top of it &ndash; will be fundamental to automating the observation and analysis of the world around us; given the increasingly chaotic circumstances of the world, it seems useful to be able to have machines automatically analyze changes in the environment for us.&nbsp; &nbsp;Read more: The iWildCam 2018 Challenge Dataset (Arxiv).&nbsp; &nbsp;Get the dataset: iWildCam &nbsp;2019 challenge (GitHub).
#####################################################
Compute may matter, but so does data, says Max Welling:&hellip;&rdquo;The most fundamental lesson of ML is the bias-variance tradeoff&rdquo;&hellip; A few weeks ago Richard Sutton, one of the pioneers of reinforcement learning, wrote a post about the &ldquo;bitter lesson&rdquo; of AI research (Import AI #138), namely that techniques which use huge amounts of computation and relatively simple algorithms are better to focus on. Now, Max Welling, a researcher with the University of Amsterdam, has written a response claiming that data may be just as important as compute. 
 &nbsp;&nbsp;&ldquo;The most fundamental lesson of ML is the bias-variance tradeoff: when you have sufficient data, you do not need to impose a lot of human generated inductive bias on your model,&rdquo; he writes. &ldquo;However, when you do not have sufficient data available you will need to use human-knowledge to fill the gaps.&rdquo;
Self-driving cars are a good example of a place where compute can&rsquo;t solve most problems, and you need to invest in injecting stronger priors (eg, an understanding of the physics of the world) into your models, Welling says. He also suggests generative models could help fill in some of these gaps, especially when it comes to generalization.
Ultimately, Welling ends up somewhere between the &lsquo;compute matters&rsquo; versus the &lsquo;strong priors matter&rsquo; (eg, data) arguments. &ldquo;I would say if we ever want to solve Artificial General Intelligence (AGI) then we will need model-based RL,&rdquo; he writes. &ldquo;We cannot answer the question of whether we need human designed models without talking about the availability of data.&rdquo;
Why this matters: There&rsquo;s an inherent tension in AI research between bets that revolve predominantly around compute and those that revolve around data. That&rsquo;s likely because different bets encourage different research avenues and different specializations. I do worry about a world where people that do lots of &lsquo;big compute&rsquo; experiments end up speaking a different language to those without, leading to different priors when approaching the question of how much computation matters.&nbsp; Read more: Do we still need models or just more data and compute? (Max Welling, PDF).
#####################################################
Want to train AI on something b…"

---

### Import AI 143: Predicting car accident risks by looking at the houses people live in; why data matters as much as compute; and using capsule networks to generate synthetic data

Predicting car accident risks from Google Street View images:&hellip;The surprising correspondences between different types of data&hellip;Researchers with the University of Warsaw and Stanford University have shown how to use pictures from people&rsquo;s houses to better predict the chances of that person getting into a car accident. (Import AI administrative note &ndash; standard warnings about &lsquo;correlation does not imply&rsquo; causation apply).
For the project, the researchers analyzed 20,000 addresses of insurance company clients &ndash; a random sample of an insurer&rsquo;s portfolio collected in Poland between January 2012 and December 2015. For each address, they collect an overhead Google satellite view and a Google Street View image of the property, and humans then annotate the image with labels relating to the type of property, age, condition, estimate wealth of its residents, along with the type and density of buildings in the neighborhood. They subsequently test these variables and find that five of the seven have significant with regard to the insurance prediction problem. 
 &nbsp;&nbsp;&ldquo;Despite the high volatility of data, adding our five simple variables to the insurer&rsquo;s model improves its performance in 18 out of 20 resampling trials and the average improvement of the Gini coefficient is nearly 2 percentage points,&rdquo; they write.
Ultimately, they show that &ndash; to a statistically significant extent &ndash; &ldquo;features visible on a picture of a house can be predictive of car accident risk, independently from classically used variables such as age, or zip code&rdquo;.
Why this matters: Studies like this speak to the power of large-scale data analysis, highlighting how data that is innocuous at the level of the individual can become significant when compared and contrasted with a vast amount of other data. The researchers acknowledge this, noting that: &nbsp;&ldquo;modern data collection and computational techniques, which allow for unprecedented exploitation of personal data, can outpace development of legislation and raise privacy threats&rdquo;.&nbsp;&nbsp;Read more: Google Street View image of a house predicts car accident risk of its resident (Arxiv).
#####################################################
Your next pothole could be inspected via drone:&hellip;Drones + NVIDIA cards + smart algorithms = automated robot inspectors&hellip;Researchers with HKUST Robotics Institute have created a prototype drone system that can be used to automatically analyze a road surface. The project sees the researchers develop a dense stereo vision algorithm which the UAV uses to analyze the road surface. They&rsquo;re able to use this algorithm to process road images on the drone in real-time, automatically identifying surface-area disparities.
Hardware: To accomplish this, they use a ZED stereo camera mounted on a DJI Matrice 100 drone, which itself has a JETSON TX2 GPU installed onboard for real-time processing.
Why this matters: AI approaches make it cheap for robots to automatically sense&amp;analyze aspects of the world, and experiments like this suggest that we&rsquo;re rapidly approaching the era when we&rsquo;ll start to automate various types of surveillance (both for civil and military purposes) via drones.&nbsp;&nbsp;Read more: Real-Time Dense Stereo Embedded in a UAV for Road Inspection (Arxiv). &nbsp;&nbsp;Get the datasets used in the experiment here (Rui Fan, HKUST, personal website). &nbsp;&nbsp;Check out a video of the drone here (Rui Fan, YouTube).
#####################################################
Train AI to watch over the world with the iWildCam dataset:&hellip;Monitoring the planet with deep learning-based systems&hellip;Researchers with the California Institute of Technology have published the iWildCam dataset to help people develop AI systems that can automatically analyze wildlife seen in camera traps spread across the American Southwest. They&rsquo;ve also created a challenge based around the dataset, letting researchers compete in developing AI systems capable of automatically monitoring the world.
Testing generalization: &ldquo;If we wish to build systems that are trained once to detect and classify animals, and then deployed to new locations without further training, we must measure the ability of machine learning and computer vision to generalize to new environments,&rdquo; the researchers write.
Common nuisances: There are six problems relating to the data gathered from the traps: variable illumination, motion blur, size of the region of interest (eg, an animal might be small and far away from the camera), occlusion, camouflage, and perspective.
iWildCam: The images come from cameras installed across the American Southwest, consisting of 292,732 images spread between 143 locations. iWildCam is designed to capture the complexities of the datasets that human biologists need to deal with: &ldquo;therefore the data is unbalanced in the number of images per location, distribution of species per location, and distribution of species overall&rdquo;, they write.
Why this matters: Datasets like this &ndash; and AI systems built on top of it &ndash; will be fundamental to automating the observation and analysis of the world around us; given the increasingly chaotic circumstances of the world, it seems useful to be able to have machines automatically analyze changes in the environment for us.&nbsp; &nbsp;Read more: The iWildCam 2018 Challenge Dataset (Arxiv).&nbsp; &nbsp;Get the dataset: iWildCam &nbsp;2019 challenge (GitHub).
#####################################################
Compute may matter, but so does data, says Max Welling:&hellip;&rdquo;The most fundamental lesson of ML is the bias-variance tradeoff&rdquo;&hellip; A few weeks ago Richard Sutton, one of the pioneers of reinforcement learning, wrote a post about the &ldquo;bitter lesson&rdquo; of AI research (Import AI #138), namely that techniques which use huge amounts of computation and relatively simple algorithms are better to focus on. Now, Max Welling, a researcher with the University of Amsterdam, has written a response claiming that data may be just as important as compute. 
 &nbsp;&nbsp;&ldquo;The most fundamental lesson of ML is the bias-variance tradeoff: when you have sufficient data, you do not need to impose a lot of human generated inductive bias on your model,&rdquo; he writes. &ldquo;However, when you do not have sufficient data available you will need to use human-knowledge to fill the gaps.&rdquo;
Self-driving cars are a good example of a place where compute can&rsquo;t solve most problems, and you need to invest in injecting stronger priors (eg, an understanding of the physics of the world) into your models, Welling says. He also suggests generative models could help fill in some of these gaps, especially when it comes to generalization.
Ultimately, Welling ends up somewhere between the &lsquo;compute matters&rsquo; versus the &lsquo;strong priors matter&rsquo; (eg, data) arguments. &ldquo;I would say if we ever want to solve Artificial General Intelligence (AGI) then we will need model-based RL,&rdquo; he writes. &ldquo;We cannot answer the question of whether we need human designed models without talking about the availability of data.&rdquo;
Why this matters: There&rsquo;s an inherent tension in AI research between bets that revolve predominantly around compute and those that revolve around data. That&rsquo;s likely because different bets encourage different research avenues and different specializations. I do worry about a world where people that do lots of &lsquo;big compute&rsquo; experiments end up speaking a different language to those without, leading to different priors when approaching the question of how much computation matters.&nbsp; Read more: Do we still need models or just more data and compute? (Max Welling, PDF).
#####################################################
Want to train AI on something b…