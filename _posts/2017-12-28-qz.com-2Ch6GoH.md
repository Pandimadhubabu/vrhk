---

layout: post
category: C7WAG6QGN
title: "The data that transformed AI research—and possibly the world"
date: 2017-12-28 09:54:40
link: http://vrhk.co/2Ch6GoH
image: https://qzprod.files.wordpress.com/2017/07/ap_318979552057.jpg?quality=80&strip=all&w=1200&fit=200%2C150
domain: qz.com
author: "Dave Gershgorn"
icon: https://app.qz.com/img/icons/touch_144.png
excerpt: "In 2006, Fei-Fei Li started ruminating on an idea.
Li, a newly-minted computer science professor at University of Illinois Urbana-Champaign, saw her colleagues across academia and the AI industry hammering away at the same concept: a better algorithm would make better decisions, regardless of the data.
But she realized a limitation to this approach&mdash;the best algorithm wouldn&rsquo;t work well if the data it learned from didn&rsquo;t reflect the real world.
Her solution: build a better dataset.
&ldquo;We decided we wanted to do something that was completely historically unprecedented,&rdquo; Li said, referring to a small team who would initially work with her. &ldquo;We&rsquo;re going to map out the entire world of objects.&rdquo;
The resulting dataset was called ImageNet. Originally published in 2009 as a research poster stuck in the corner of a Miami Beach conference center, the dataset quickly evolved into an annual competition to see which algorithms could identify objects in the dataset&rsquo;s images with the lowest error rate. Many see it as the catalyst for the AI boom the world is experiencing today.
Alumni of the ImageNet challenge can be found in every corner of the tech world. The contest&rsquo;s first winners in 2010 went on to take senior roles at Baidu, Google, and Huawei. Matthew Zeiler built Clarifai based off his 2013 ImageNet win, and is now backed by $40 million in VC funding. In 2014, Google split the winning title with two researchers from Oxford, who were quickly snapped up and added to its recently-acquired DeepMind lab.
Li herself is now chief scientist at Google Cloud, a professor at Stanford, and director of the university&rsquo;s AI lab.
Today, she&rsquo;ll take the stage at CVPR to talk about ImageNet&rsquo;s annual results for the last time&mdash;2017 was the final year of the competition. In just seven years, the winning accuracy in classifying objects in the dataset rose from 71.8% to 97.3%, surpassing human abilities and effectively proving that bigger data leads to better decisions.
Even as the competition ends, its legacy is already taking shape. Since 2009, dozens of new AI research datasets have been introduced in subfields like computer vision, natural language processing, and voice recognition.
&ldquo;The paradigm shift of the ImageNet thinking is that while a lot of people are paying attention to models, let&rsquo;s pay attention to data,&rdquo; Li said. &ldquo;Data will redefine how we think about models.&rdquo;
What&rsquo;s ImageNet?
In the late 1980s, Princeton psychologist George Miller started a project called WordNet, with the aim of building a hierarchal structure for the English language. It would be sort of like a dictionary, but words would be shown in relation to other words rather than alphabetical order. For example, within WordNet, the word &ldquo;dog&rdquo; would be nested under &ldquo;canine,&rdquo; which would be nested under &ldquo;mammal,&rdquo; and so on. It was a way to organize language that relied on machine-readable logic, and amassed more than 155,000 indexed words.
The ImageNet hierarchy derived from WordNet. (ImageNet)Li, in her first teaching job at UIUC, had been grappling with one of the core tensions in machine learning: overfitting and generalization. When an algorithm can only work with data that&rsquo;s close to what it&rsquo;s seen before, the model is considered overfitting to the data; it can&rsquo;t understand anything more general past those examples. On the other hand, if a model doesn&rsquo;t pick up the right patterns between the data, it&rsquo;s overgeneralizing.
Finding the perfect algorithm seemed distant, Li says. She saw that previous datasets didn&rsquo;t capture how variable the world could be&mdash;even just identifying pictures of cats is infinitely complex. But by giving the algorithms more examples of how complex the world could be, it made mathematic sense they could fare better. If you only saw five pictures of cats, you&rsquo;d only have five camera angles, lighting conditions, and maybe variety of cat. But if you&rsquo;ve seen 500 pictures of cats, there are many more examples to draw commonalities from.
Li started to read about how others had attempted to catalogue a fair representation of the world with data. During that search, she found WordNet.
Having read about WordNet&rsquo;s approach, Li met with professor Christiane Fellbaum, a researcher influential in the continued work on WordNet, during a 2006 visit to Princeton. Fellbaum had the idea that WordNet could have an image associated with each of the words, more as a reference rather than a computer vision dataset. Coming from that meeting, Li imagined something grander&mdash;a large-scale dataset with many examples of each word.
Months later Li joined the Princeton faculty, her alma mater, and started on the ImageNet project in early 2007. She started to build a team to help with the challenge, first recruiting a fellow professor, Kai Li, who then convinced Ph.D student Jia Deng to transfer into Li&rsquo;s lab. Deng has helped run the ImageNet project through 2017.
&ldquo;It was clear to me that this was something that was very different from what other people were doing, were focused on at the time,&rdquo; Deng said. &ldquo;I had a clear idea that this would change how the game was played in vision research, but I didn&rsquo;t know how it would change.&rdquo;
The objects in the dataset would range from concrete objects, like pandas or churches, to abstract ideas like love.
Li&rsquo;s first idea was to hire undergraduate students for $10 an hour to manually find images and add them to the dataset. But back-of-the-napkin math quickly made Li realize that at the undergrads&rsquo; rate of collecting images it would take 90 years to complete.
After the undergrad task force was disbanded, Li and the team went back to the drawing board. What if computer-vision algorithms could pick the photos from the internet, and humans would then just curate the images? But after a few months of tinkering with algorithms, the team came to the conclusion that this technique wasn&rsquo;t sustainable either&mdash;future algorithms would be constricted to only judging what algorithms were capable of recognizing at the time the dataset was compiled.
Undergrads were time-consuming, algorithms were flawed, and the team didn&rsquo;t have money&mdash;Li said the project failed to win any of the federal grants she applied for, receiving comments on proposals that it was shameful Princeton would research this topic, and that the only strength of proposal was that Li was a woman.
A solution finally surfaced in a chance hallway conversation with a graduate student who asked Li whether she had heard of Amazon Mechanical Turk, a service where hordes of humans sitting at computers around the world would complete small online tasks for pennies.
&ldquo;He showed me the website, and I can tell you literally that day I knew the ImageNet project was going to happen,&rdquo; she said. &ldquo;Suddenly we found a tool that could scale, that we could not possibly dream of by hiring Princeton undergrads.&rdquo;
The Amazon Mechanical Turk backend for classifying images. (ImageNet)Mechanical Turk brought its own slew of hurdles, with much of the work fielded by two of Li&rsquo;s Ph.D students, Jia Deng and Olga Russakovsky . For example, how many Turkers needed to look at each image? Maybe two people could determine that a cat was a cat, but an image of a miniature husky might require 10 rounds of validation. What if some Turkers tried to game or cheat the system? Li&rsquo;s team ended up creating a batch of statistical models for Turker&rsquo;s behaviors to help ensure the dataset only included correct images.
Even after finding Mechanical Turk, the dataset took two and a half years to complete. It consisted of 3.2 million labelled images, separated into 5,247 categories, sorted into 12 subtrees like &ldquo;mammal,&rdquo; &ldquo;vehicle,&…"

---

### The data that transformed AI research—and possibly the world

In 2006, Fei-Fei Li started ruminating on an idea.
Li, a newly-minted computer science professor at University of Illinois Urbana-Champaign, saw her colleagues across academia and the AI industry hammering away at the same concept: a better algorithm would make better decisions, regardless of the data.
But she realized a limitation to this approach&mdash;the best algorithm wouldn&rsquo;t work well if the data it learned from didn&rsquo;t reflect the real world.
Her solution: build a better dataset.
&ldquo;We decided we wanted to do something that was completely historically unprecedented,&rdquo; Li said, referring to a small team who would initially work with her. &ldquo;We&rsquo;re going to map out the entire world of objects.&rdquo;
The resulting dataset was called ImageNet. Originally published in 2009 as a research poster stuck in the corner of a Miami Beach conference center, the dataset quickly evolved into an annual competition to see which algorithms could identify objects in the dataset&rsquo;s images with the lowest error rate. Many see it as the catalyst for the AI boom the world is experiencing today.
Alumni of the ImageNet challenge can be found in every corner of the tech world. The contest&rsquo;s first winners in 2010 went on to take senior roles at Baidu, Google, and Huawei. Matthew Zeiler built Clarifai based off his 2013 ImageNet win, and is now backed by $40 million in VC funding. In 2014, Google split the winning title with two researchers from Oxford, who were quickly snapped up and added to its recently-acquired DeepMind lab.
Li herself is now chief scientist at Google Cloud, a professor at Stanford, and director of the university&rsquo;s AI lab.
Today, she&rsquo;ll take the stage at CVPR to talk about ImageNet&rsquo;s annual results for the last time&mdash;2017 was the final year of the competition. In just seven years, the winning accuracy in classifying objects in the dataset rose from 71.8% to 97.3%, surpassing human abilities and effectively proving that bigger data leads to better decisions.
Even as the competition ends, its legacy is already taking shape. Since 2009, dozens of new AI research datasets have been introduced in subfields like computer vision, natural language processing, and voice recognition.
&ldquo;The paradigm shift of the ImageNet thinking is that while a lot of people are paying attention to models, let&rsquo;s pay attention to data,&rdquo; Li said. &ldquo;Data will redefine how we think about models.&rdquo;
What&rsquo;s ImageNet?
In the late 1980s, Princeton psychologist George Miller started a project called WordNet, with the aim of building a hierarchal structure for the English language. It would be sort of like a dictionary, but words would be shown in relation to other words rather than alphabetical order. For example, within WordNet, the word &ldquo;dog&rdquo; would be nested under &ldquo;canine,&rdquo; which would be nested under &ldquo;mammal,&rdquo; and so on. It was a way to organize language that relied on machine-readable logic, and amassed more than 155,000 indexed words.
The ImageNet hierarchy derived from WordNet. (ImageNet)Li, in her first teaching job at UIUC, had been grappling with one of the core tensions in machine learning: overfitting and generalization. When an algorithm can only work with data that&rsquo;s close to what it&rsquo;s seen before, the model is considered overfitting to the data; it can&rsquo;t understand anything more general past those examples. On the other hand, if a model doesn&rsquo;t pick up the right patterns between the data, it&rsquo;s overgeneralizing.
Finding the perfect algorithm seemed distant, Li says. She saw that previous datasets didn&rsquo;t capture how variable the world could be&mdash;even just identifying pictures of cats is infinitely complex. But by giving the algorithms more examples of how complex the world could be, it made mathematic sense they could fare better. If you only saw five pictures of cats, you&rsquo;d only have five camera angles, lighting conditions, and maybe variety of cat. But if you&rsquo;ve seen 500 pictures of cats, there are many more examples to draw commonalities from.
Li started to read about how others had attempted to catalogue a fair representation of the world with data. During that search, she found WordNet.
Having read about WordNet&rsquo;s approach, Li met with professor Christiane Fellbaum, a researcher influential in the continued work on WordNet, during a 2006 visit to Princeton. Fellbaum had the idea that WordNet could have an image associated with each of the words, more as a reference rather than a computer vision dataset. Coming from that meeting, Li imagined something grander&mdash;a large-scale dataset with many examples of each word.
Months later Li joined the Princeton faculty, her alma mater, and started on the ImageNet project in early 2007. She started to build a team to help with the challenge, first recruiting a fellow professor, Kai Li, who then convinced Ph.D student Jia Deng to transfer into Li&rsquo;s lab. Deng has helped run the ImageNet project through 2017.
&ldquo;It was clear to me that this was something that was very different from what other people were doing, were focused on at the time,&rdquo; Deng said. &ldquo;I had a clear idea that this would change how the game was played in vision research, but I didn&rsquo;t know how it would change.&rdquo;
The objects in the dataset would range from concrete objects, like pandas or churches, to abstract ideas like love.
Li&rsquo;s first idea was to hire undergraduate students for $10 an hour to manually find images and add them to the dataset. But back-of-the-napkin math quickly made Li realize that at the undergrads&rsquo; rate of collecting images it would take 90 years to complete.
After the undergrad task force was disbanded, Li and the team went back to the drawing board. What if computer-vision algorithms could pick the photos from the internet, and humans would then just curate the images? But after a few months of tinkering with algorithms, the team came to the conclusion that this technique wasn&rsquo;t sustainable either&mdash;future algorithms would be constricted to only judging what algorithms were capable of recognizing at the time the dataset was compiled.
Undergrads were time-consuming, algorithms were flawed, and the team didn&rsquo;t have money&mdash;Li said the project failed to win any of the federal grants she applied for, receiving comments on proposals that it was shameful Princeton would research this topic, and that the only strength of proposal was that Li was a woman.
A solution finally surfaced in a chance hallway conversation with a graduate student who asked Li whether she had heard of Amazon Mechanical Turk, a service where hordes of humans sitting at computers around the world would complete small online tasks for pennies.
&ldquo;He showed me the website, and I can tell you literally that day I knew the ImageNet project was going to happen,&rdquo; she said. &ldquo;Suddenly we found a tool that could scale, that we could not possibly dream of by hiring Princeton undergrads.&rdquo;
The Amazon Mechanical Turk backend for classifying images. (ImageNet)Mechanical Turk brought its own slew of hurdles, with much of the work fielded by two of Li&rsquo;s Ph.D students, Jia Deng and Olga Russakovsky . For example, how many Turkers needed to look at each image? Maybe two people could determine that a cat was a cat, but an image of a miniature husky might require 10 rounds of validation. What if some Turkers tried to game or cheat the system? Li&rsquo;s team ended up creating a batch of statistical models for Turker&rsquo;s behaviors to help ensure the dataset only included correct images.
Even after finding Mechanical Turk, the dataset took two and a half years to complete. It consisted of 3.2 million labelled images, separated into 5,247 categories, sorted into 12 subtrees like &ldquo;mammal,&rdquo; &ldquo;vehicle,&…