---

layout: post
category: threads
title: "[R] How is FlipOut any different the local reparametarization trick (LRT)?"
date: 2018-03-16 10:12:59
link: https://vrhk.co/2pg9tWs
image: https://i.redditmedia.com/uqSXAZWnIeNKGNM9S7DGpGLOnzm_mxUMvr6Y0yks4jY.jpg?w=320&s=8d3e77c7b010692868ed2d877c2fe24c
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "Paper: Flipout: Efficient Pseudo-Independent Weight Perturbations on Mini-Batches [<https://openreview.net/forum?id=rJNpifWAb>] The paper..."

---

### [R] How is FlipOut any different the local reparametarization trick (LRT)? â€¢ r/MachineLearning

Paper: Flipout: Efficient Pseudo-Independent Weight Perturbations on Mini-Batches [<https://openreview.net/forum?id=rJNpifWAb>] The paper...