---

layout: post
category: C7VJAGM2R
title: "Google Cloud Platform cuts the price of GPUs by up to 36 percent"
date: 2017-11-20 19:41:26
link: https://vrhk.co/2Ahb3PV
image: https://tctechcrunch2011.files.wordpress.com/2017/09/gettyimages-480522145.jpg?w=1200&fit=200%2C150
domain: techcrunch.com
author: "TechCrunch"
icon: https://s0.wp.com/wp-content/themes/vip/techcrunch-2013/assets/images/favicon.ico
excerpt: "Google today announced that it&rsquo;s cutting the price of using Nvidia&rsquo;s Tesla GPUs through its Compute Engine by up to 36 percent. In U.S. regions, using the somewhat older K80 GPUs will now cost $0.45 per hour while using the newer and more powerful P100 machines will cost $1.46 per minute (all with per-second billing).
In addition, the company is also dropping the prices for preemptible local SSDs by almost 40 percent as well. &ldquo;Preemptible local SSDs&rdquo; refers to local SSDs attached to Google&rsquo;s preemptible VMs. You can&rsquo;t attach GPUs to preemptible instances, though, so this is a nice little bonus announcement but it isn&rsquo;t going to directly benefit GPU users.
As for the new GPU pricing, it&rsquo;s clear that Google is aiming this feature at developers who want to run their own machine learning workloads on its cloud, though there are also a number of other applications &mdash; including physical simulations and molecular modeling &mdash; that greatly benefit from the hundreds of cores that are now available on these GPUs. The P100, which is officially still in beta on the Google Cloud Platform, features 3594 cores, for example.
Developers can attach up to four P100 and eight K80 dies to each instance. Like regular VMs, GPU users will also receive sustained use discounts, though most users probably don&rsquo;t keep their GPUs running for a full month.
It&rsquo;s hard not to see this announcement in the light of AWS&rsquo;s upcoming annual developer conference which will take over most of Las Vegas&rsquo;s hotel conference space next week. AWS is expected to make a number of AI and machine learning announcement and chances are, we&rsquo;ll see some price cuts from AWS, too."

---

### Google Cloud Platform cuts the price of GPUs by up to 36 percent

Google today announced that it&rsquo;s cutting the price of using Nvidia&rsquo;s Tesla GPUs through its Compute Engine by up to 36 percent. In U.S. regions, using the somewhat older K80 GPUs will now cost $0.45 per hour while using the newer and more powerful P100 machines will cost $1.46 per minute (all with per-second billing).
In addition, the company is also dropping the prices for preemptible local SSDs by almost 40 percent as well. &ldquo;Preemptible local SSDs&rdquo; refers to local SSDs attached to Google&rsquo;s preemptible VMs. You can&rsquo;t attach GPUs to preemptible instances, though, so this is a nice little bonus announcement but it isn&rsquo;t going to directly benefit GPU users.
As for the new GPU pricing, it&rsquo;s clear that Google is aiming this feature at developers who want to run their own machine learning workloads on its cloud, though there are also a number of other applications &mdash; including physical simulations and molecular modeling &mdash; that greatly benefit from the hundreds of cores that are now available on these GPUs. The P100, which is officially still in beta on the Google Cloud Platform, features 3594 cores, for example.
Developers can attach up to four P100 and eight K80 dies to each instance. Like regular VMs, GPU users will also receive sustained use discounts, though most users probably don&rsquo;t keep their GPUs running for a full month.
It&rsquo;s hard not to see this announcement in the light of AWS&rsquo;s upcoming annual developer conference which will take over most of Las Vegas&rsquo;s hotel conference space next week. AWS is expected to make a number of AI and machine learning announcement and chances are, we&rsquo;ll see some price cuts from AWS, too.