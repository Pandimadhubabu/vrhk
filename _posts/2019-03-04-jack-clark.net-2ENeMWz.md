---

layout: post
category: product
title: "Import AI 136: What machine learning + power infrastructure means for humanity; New GCA benchmark&amp;dataset challenges image-captioning systems; and Google uses FrankenRL to create more mobile robots"
date: 2019-03-04 20:01:58
link: https://vrhk.co/2ENeMWz
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "DeepMind uses machine learning to improve efficiency of Google&rsquo;s wind turbines:&hellip;Project represents a step-up from datacenters, where DeepMind had previously deployed its technology&hellip;DeepMind has used a neural network-based system to improve the efficiency of Google&rsquo;s fleet of wind turbines (700 megawatts of capacity) by better predicting ahead of time how much power the systems may generate. DM&rsquo;s system has been trained to predict the wind power around 36 hours ahead of actual generation and has shown some success &ndash; &ldquo;this is important, because energy sources that can be scheduled (i.e. can deliver a set amount of electricity at a set time) are often more valuable to the grid,&rdquo; the company says.
 &nbsp;&nbsp;The big number: 20%. That&rsquo;s the amount by which the system has improved the (somewhat nebulously defined) &lsquo;value&rsquo; of these systems, &ldquo;compared to the baseline scenario of no time-based commitments to the grid&rdquo;.
 &nbsp;&nbsp;&nbsp;Why this matters: Artificial intelligence will help us create a sense&amp;respond infrastructure for the entire planet, and we can imagine sowing various machine learning-based approaches across various utility infrastructures worldwide to increase the efficiency of the planet&rsquo;s power infrastructure.&nbsp; &nbsp;Read more: Machine learning can boost the value of wind energy (DeepMind blog).
#######################################
Google uses FrankenRL to teach its robots to drive:&hellip;PRM-RL fuses Probabilistic Roadmaps with smarter, learned components&hellip;Researchers with Google Brain have shown how to use a combination of reinforcement learning with other techniques can create robots capable of autonomously navigating large, previously mapped spaces. The technique developed by the researchers is called PRM-RL (Probabilistic Roadmap &ndash; Reinforcement Learning) and is a type of FrankenRL &ndash; that is, it combines RL with other techniques, leading to a system with performance greater than obtainable via a purely RL-based system, or purely PRm-based one.
 &nbsp;&nbsp;How it works: &ldquo;In PRM-RL, an RL agent learns a local point-to-point task, incorporating system dynamics and sensor noise independent of long-range environment structure. The agent&rsquo;s learned behavior then influences roadmap construction; PRM-RL builds a roadmap by connecting two configuration points only if the agent consistently navigates the point-to-point path between them collision free, thereby learning the long-range environment structure&rdquo;, the researchers write. In addition, they developed algorithms to aid transfer between simulated and real maps.
 &nbsp;&nbsp;Close, but not quite: Learning effective robot navigation policies is a big challenge for AI researchers, given the tendency for physical robots to break, run into un-anticipated variations of reality, and generally frustrate and embarrass AI researchers. Just building the maps that the robot can use to subsequently learn to navigate a space are difficult &ndash; it took Google 4 days using a cluster of 300 workers to build a map of a set of four interconnected buildings. &ldquo;PRM-RL successfully navigates this roadmap 57.3% of the time evaluated over 1,000 random navigation attempts with a maximum path distance of 1000 m&rdquo;, Google writes.
 &nbsp;&nbsp;Real robots: The researchers also test their system in a real robot, and show that such systems exhibit better transfer than those built without the learned RL component.
 &nbsp;&nbsp;Why this matters: Getting robots to do _anything_ useful that involves a reasonable amount of independent decision-making is difficult, and this work shows that RL techniques are starting to pay off by letting us teach robots to learn things that would be unachievable by other means. We&rsquo;ll need smarter, more sample-efficient techniques to be able to work with larger buildings and to increase reliability.&nbsp;&nbsp;Check out a video of the robot navigating a room here (Long-Range Indoor Navigation with PRM-RL, YouTube). &nbsp;&nbsp;Read more: Long-Range Indoor Navigation with PRM-RL (Arxiv).
#######################################
Think your visual question answering algorithm is good? Test it out on GCA:&hellip;VQA was too easy. GCA may be just right&hellip;.Stanford University researchers have published details on GQA, &ldquo;a dataset for real-world visual reasoning and compositional question answering&rdquo; which is designed to overcome the short-comings of other visual question answering (VQA) datasets.
 &nbsp;&nbsp;GQA datapoints: GQA consists of 113k images and 22 million questions of various types and compositionality. The questions are designed to measure performance &ldquo;on an array of reasoning skills such as object and attribute recognition, transitive relation tracking, spatial reasoning, logical inference and comparisons&rdquo;. These questions are algorithmically created via a &lsquo;Question Engine&rsquo; (less interesting than the name suggests, but worth reading about if you like reading about auto-data-creating-pipelines.
 &nbsp;&nbsp;GQA example questions: Some of the questions generated by GQA include: &lsquo;Are the napkin and the cup the same color?&rsquo;; &nbsp;&lsquo;What color is the bear?&rsquo;; &lsquo;Which side of the image is the plate on?&rsquo;; &lsquo;Are there any clocks or mirrors?&rsquo;, and so on. While these questions lack some of the diversity of human-written questions, they do have the nice property of being numerous and easy to generate.
 &nbsp;&nbsp;GQA: Reassuringly Difficult: One of the failure cases for new AI testing regimes is that they&rsquo;re too easy. This can lead to people &lsquo;solving&rsquo; datasets very soon after they&rsquo;re released. (One example here is SQuAD, a question-answering dataset and challenge which algorithms mastered in around a year, leading to the invention of SQuAD 2.0, a more difficult dataset.) To avoid this, the researchers behind GQA test a bunch of models against it and in the process reassure themselves that the dataset is genuinely difficult to solve.
&nbsp; Baseline results (accuracy): &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lsquo;Blind&rsquo; LSTM: Gets 41.07% without ever seeing any images.&nbsp; &nbsp; &nbsp;&lsquo;Deaf&rsquo; CNN: Gets 17.82% without ever seeing any questions. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CNN + LSTM: 46.55%. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Bottom-Up Attention model (winner of the 2017 visual question answering challenge): 49.74%. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MAC (State-of-the-art on CLEVR, a similarly-scoped dataset): 54.06%. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Humans: 89.3%.
 &nbsp;&nbsp;Why this matters: Datasets and challenges have a history of driving progress in AI research; GQA appears to give us a challenging benchmark to test systems against. Meanwhile, developing systems that can understand the world around themselves via a combination of image analysis and responsiveness to textual queries about the images, is a major goal of AI research with significant economic applications.&nbsp;&nbsp;Read more: GQA: A new dataset for compositional question answering over real-world images (Arxiv).
#######################################
Use big compute to revolutionize science, say researchers:&hellip;University researchers see ability to wield increasingly large amounts of computers as key to scientific discoveries&hellip;
Researchers with Stanford University, University of Zurich, the University of California at Berkeley, and the University of Illinois Urbana-Champaign have pulled together notes from a lecture series held at Stanford in 2017 to issue a manifesto for the usage of large-scale cloud computing technology by academic researchers. This is written in response to two prevailing trends:
In some fields of science (for instance, machine learning) a number of discoveries have been made through the usage of increasingly large-scale compu…"

---

### Import AI 136: What machine learning + power infrastructure means for humanity; New GCA benchmark&amp;dataset challenges image-captioning systems; and Google uses FrankenRL to create more mobile robots

DeepMind uses machine learning to improve efficiency of Google&rsquo;s wind turbines:&hellip;Project represents a step-up from datacenters, where DeepMind had previously deployed its technology&hellip;DeepMind has used a neural network-based system to improve the efficiency of Google&rsquo;s fleet of wind turbines (700 megawatts of capacity) by better predicting ahead of time how much power the systems may generate. DM&rsquo;s system has been trained to predict the wind power around 36 hours ahead of actual generation and has shown some success &ndash; &ldquo;this is important, because energy sources that can be scheduled (i.e. can deliver a set amount of electricity at a set time) are often more valuable to the grid,&rdquo; the company says.
 &nbsp;&nbsp;The big number: 20%. That&rsquo;s the amount by which the system has improved the (somewhat nebulously defined) &lsquo;value&rsquo; of these systems, &ldquo;compared to the baseline scenario of no time-based commitments to the grid&rdquo;.
 &nbsp;&nbsp;&nbsp;Why this matters: Artificial intelligence will help us create a sense&amp;respond infrastructure for the entire planet, and we can imagine sowing various machine learning-based approaches across various utility infrastructures worldwide to increase the efficiency of the planet&rsquo;s power infrastructure.&nbsp; &nbsp;Read more: Machine learning can boost the value of wind energy (DeepMind blog).
#######################################
Google uses FrankenRL to teach its robots to drive:&hellip;PRM-RL fuses Probabilistic Roadmaps with smarter, learned components&hellip;Researchers with Google Brain have shown how to use a combination of reinforcement learning with other techniques can create robots capable of autonomously navigating large, previously mapped spaces. The technique developed by the researchers is called PRM-RL (Probabilistic Roadmap &ndash; Reinforcement Learning) and is a type of FrankenRL &ndash; that is, it combines RL with other techniques, leading to a system with performance greater than obtainable via a purely RL-based system, or purely PRm-based one.
 &nbsp;&nbsp;How it works: &ldquo;In PRM-RL, an RL agent learns a local point-to-point task, incorporating system dynamics and sensor noise independent of long-range environment structure. The agent&rsquo;s learned behavior then influences roadmap construction; PRM-RL builds a roadmap by connecting two configuration points only if the agent consistently navigates the point-to-point path between them collision free, thereby learning the long-range environment structure&rdquo;, the researchers write. In addition, they developed algorithms to aid transfer between simulated and real maps.
 &nbsp;&nbsp;Close, but not quite: Learning effective robot navigation policies is a big challenge for AI researchers, given the tendency for physical robots to break, run into un-anticipated variations of reality, and generally frustrate and embarrass AI researchers. Just building the maps that the robot can use to subsequently learn to navigate a space are difficult &ndash; it took Google 4 days using a cluster of 300 workers to build a map of a set of four interconnected buildings. &ldquo;PRM-RL successfully navigates this roadmap 57.3% of the time evaluated over 1,000 random navigation attempts with a maximum path distance of 1000 m&rdquo;, Google writes.
 &nbsp;&nbsp;Real robots: The researchers also test their system in a real robot, and show that such systems exhibit better transfer than those built without the learned RL component.
 &nbsp;&nbsp;Why this matters: Getting robots to do _anything_ useful that involves a reasonable amount of independent decision-making is difficult, and this work shows that RL techniques are starting to pay off by letting us teach robots to learn things that would be unachievable by other means. We&rsquo;ll need smarter, more sample-efficient techniques to be able to work with larger buildings and to increase reliability.&nbsp;&nbsp;Check out a video of the robot navigating a room here (Long-Range Indoor Navigation with PRM-RL, YouTube). &nbsp;&nbsp;Read more: Long-Range Indoor Navigation with PRM-RL (Arxiv).
#######################################
Think your visual question answering algorithm is good? Test it out on GCA:&hellip;VQA was too easy. GCA may be just right&hellip;.Stanford University researchers have published details on GQA, &ldquo;a dataset for real-world visual reasoning and compositional question answering&rdquo; which is designed to overcome the short-comings of other visual question answering (VQA) datasets.
 &nbsp;&nbsp;GQA datapoints: GQA consists of 113k images and 22 million questions of various types and compositionality. The questions are designed to measure performance &ldquo;on an array of reasoning skills such as object and attribute recognition, transitive relation tracking, spatial reasoning, logical inference and comparisons&rdquo;. These questions are algorithmically created via a &lsquo;Question Engine&rsquo; (less interesting than the name suggests, but worth reading about if you like reading about auto-data-creating-pipelines.
 &nbsp;&nbsp;GQA example questions: Some of the questions generated by GQA include: &lsquo;Are the napkin and the cup the same color?&rsquo;; &nbsp;&lsquo;What color is the bear?&rsquo;; &lsquo;Which side of the image is the plate on?&rsquo;; &lsquo;Are there any clocks or mirrors?&rsquo;, and so on. While these questions lack some of the diversity of human-written questions, they do have the nice property of being numerous and easy to generate.
 &nbsp;&nbsp;GQA: Reassuringly Difficult: One of the failure cases for new AI testing regimes is that they&rsquo;re too easy. This can lead to people &lsquo;solving&rsquo; datasets very soon after they&rsquo;re released. (One example here is SQuAD, a question-answering dataset and challenge which algorithms mastered in around a year, leading to the invention of SQuAD 2.0, a more difficult dataset.) To avoid this, the researchers behind GQA test a bunch of models against it and in the process reassure themselves that the dataset is genuinely difficult to solve.
&nbsp; Baseline results (accuracy): &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lsquo;Blind&rsquo; LSTM: Gets 41.07% without ever seeing any images.&nbsp; &nbsp; &nbsp;&lsquo;Deaf&rsquo; CNN: Gets 17.82% without ever seeing any questions. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CNN + LSTM: 46.55%. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Bottom-Up Attention model (winner of the 2017 visual question answering challenge): 49.74%. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MAC (State-of-the-art on CLEVR, a similarly-scoped dataset): 54.06%. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Humans: 89.3%.
 &nbsp;&nbsp;Why this matters: Datasets and challenges have a history of driving progress in AI research; GQA appears to give us a challenging benchmark to test systems against. Meanwhile, developing systems that can understand the world around themselves via a combination of image analysis and responsiveness to textual queries about the images, is a major goal of AI research with significant economic applications.&nbsp;&nbsp;Read more: GQA: A new dataset for compositional question answering over real-world images (Arxiv).
#######################################
Use big compute to revolutionize science, say researchers:&hellip;University researchers see ability to wield increasingly large amounts of computers as key to scientific discoveries&hellip;
Researchers with Stanford University, University of Zurich, the University of California at Berkeley, and the University of Illinois Urbana-Champaign have pulled together notes from a lecture series held at Stanford in 2017 to issue a manifesto for the usage of large-scale cloud computing technology by academic researchers. This is written in response to two prevailing trends:
In some fields of science (for instance, machine learning) a number of discoveries have been made through the usage of increasingly large-scale compu…