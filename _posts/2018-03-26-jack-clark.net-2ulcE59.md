---

layout: post
category: product
title: "ImportAI: #87: Salesforce research shows the value of simplicity, Kindred’s repeatable robotics experiment, plus: think your AI understands physics? Run it on IntPhys and see what happens."
date: 2018-03-26 18:47:14
link: https://vrhk.co/2ulcE59
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Chinese AI star says society must prepare for unprecedented job destruction:&hellip;Kai-Ful Lee, venture capitalist and former AI researchers, discusses impact of AI and why today&rsquo;s techniques will have a huge impact on the world&hellip;Today&rsquo;s AI systems are going to influence the world&rsquo;s economy so much that their uptake will lead to what looks in hindsight like another industrial revolution, says Chinese venture capitalist Kai-Fu Lee, in an interview with Edge. &ldquo;We&rsquo;re all going to face a very challenging next fifteen or twenty years, when half of the jobs are going to be replaced by machines. Humans have never seen this scale of massive job decimation.&nbsp;The industrial revolution took a lot longer,&rdquo; he said.&nbsp; &nbsp;He also says that he worries deep learning might be a one-trick pony, in the sense that we can&rsquo;t expect other similarly scaled breakthroughs to occur in the next few years, and we should adjust our notions of AI progress on this basis. &ldquo;You cannot go ahead and predict that we&rsquo;re going to have a breakthrough next year, and then the month after that, and then the day after that. That would be exponential. Exponential adoption of applications is, for now, happening. That&rsquo;s great, but the idea of exponential inventions is a ridiculous concept. The people who make those claims and who claim singularity is ahead of us, I think that&rsquo;s just based on absolutely no engineering reality,&rdquo; he says. &nbsp;&nbsp;AI Haves and Have-Nots: Countries like China and the USA that have large populations and significant investments in AI stand to fair well in the new AI era, he says. &ldquo;The countries that are not in good shape are the countries that have perhaps a large population, but no AI, no technologies, no Google, no Tencent, no Baidu, no Alibaba, no Facebook, no Amazon. These people will basically be data points to countries whose software is dominant in their country.&rdquo; &nbsp;&nbsp;Read more: We Are Here To Create, A Conversation With Kai-Fu Lee (Edge).
AI practitioners&nbsp;grapple with the upcoming information apocalypse:..And you thought DeepFakes was bad. Wait till DeepWar&hellip;Members of the AI community are beginning to sound the alarm about the imminent arrival of stunningly good, stunningly easy to make synthetic images and videos. In a blog post, AI practitioners say that the increasing availability of data combined with easily accessible AI infrastructure (cloud-rentable GPUs) is lowering the barrier to entry for people that want to make this stuff, and that ongoing progress in AI capabilities means the quality of these fake media is increasing over time.&nbsp;&nbsp;How can we deal with these information threats? We could look at how society already makes it hard to forge currencies via making it costly to produce high-fidelity copies and in parallel developing technologies to verify the authenticity of currency materials. Unfortunately, though this may help with some of the problems brought about by AI forgery, it doesn&rsquo;t deal with the root problems: AI is predominantly embodied in software rather than hardware and so it&rsquo;s going to be difficult to insert detectable (and non-spoofable) distinct visual/audio signatures into generated media barring some kind of DRM-on-steroids. One solution could be to train AI classifiers on real and faked datasets from the same domain so as to provide classifiers to spot faked media in the wild.&nbsp; Read more: Commoditisation of AI, digital forgery and the end of trust: how we can fix it.
Berkeley researchers use Soft Q-Learning to let robots compose solutions to tasks:&hellip;Research reduces the time it takes to learn new behaviors on robots&hellip;Berkeley researchers have figured out how to use soft q-learning, a recently introduced variant of traditional q-learning, to let robots learn more efficiently. They introduce a new trick where they&rsquo;re able to learn to compose new q-functions from existing learned policies, letting them, for example, train a robot to move its arm to a particular distribution of X positions, then to a particular distribution of Y positions, then they can create a new policy which moves the arm to the intersection of the X and Y positions without having been trained on the combination previously. This sort of learning is typically quite difficult to achieve in a single policy as it requires so much exploration that most algorithms will spend a long time trying and failing to succeed at the task.&nbsp; Real world: The researchers train real robots to succeed at tasks like reaching to a specific location and stacking Lego blocks. They also demonstrate the utility of combining policies by training a robot to avoid an obstacle near its arm and separately training it to stack legos, then combine the two policies allowing the robot to stack blocks while avoiding an obstacle, despite having never been trained on the combination before.&nbsp;&nbsp;Why it matters: The past few years of AI progress have let us get very good at developing systems which excel at individual capabilities; being able to combine capabilities in an ad-hoc manner to generate new behaviors further increases the capabilities of AI systems and makes it possible to learn a distribution of atomic behaviors then chain these together to succeed at far more complex tasks than those found within the training set.&nbsp; Read more: Composable Deep Reinforcement Learning for Robotic Manipulation (Arxiv).
Think your AI model has a good understanding of physics? Run it on IntPhys and prepare to be embarrassed:&hellip;Testing AI systems in the same way we test infants and creatures&hellip;INRIA and Facebook and CNRS researchers have released IntPhys, a new way to evaluate AI systems&rsquo; ability to model the physical world around them using what the researchers call a &lsquo;physical plausibility test&rsquo;. IntPhys follows in a recent trend in AI for testing systems on tougher problems that more closely map to the sorts of problems humans typically tackle (see, AI2&rsquo;s &lsquo;ARC&rsquo; dataset for written reasoning, and DeepMind&rsquo;s cognitive science-inspired &lsquo;PsychLab&rsquo; environment).&nbsp; How it works: IntPhys presents AI systems with movies of scenes rendered in UnrealEngine4 and challenges them to figure out whether one scene can lead to another, letting them test models&rsquo; ability to internalize fundamental concepts about the world like object permanence, causality, etc. Systems need to compute a &ldquo;plausibility score&rdquo; for each of the scenes or scene combinations they are shown, then use this to figure out if the systems have learned about the underlying dynamics of the world.&nbsp; The IntPhys Benchmark: v1 of IntPhys focuses on unsupervised learning. The first version tests systems&rsquo; ability to understand object permanence. Future releases will include more tests for things like shape constancy, spatio-temporal continuity, and so on. The initial IntPhys release contains 15,000 videos of possible events, each video around 7 seconds long running at 15fps, totalling 21 hours of videos. It also incorporates some additional information so you don&rsquo;t have to attempt to solve the task in a purely unsupervised manner, including depth of field data for each image, as well as object instance segmentation masks.&nbsp; Baseline Systems VERSUS Humans: The researchers create two baselines for others to evaluate their systems against: a CNN encoder-decoder system, and a conditional GAN. &ldquo;Preliminary work with predictions at the pixel level revealed that our models failed at predicting convincing object motions, especially for small objects on a rich background. For this reason, we switched to computing predictions at a higher level, using object masks.&rdquo; The researchers tested humans on their system, finding that humans had an average error rate of about 8 percent when …"

---

### ImportAI: #87: Salesforce research shows the value of simplicity, Kindred’s repeatable robotics experiment, plus: think your AI understands physics? Run it on IntPhys and see what happens.

Chinese AI star says society must prepare for unprecedented job destruction:&hellip;Kai-Ful Lee, venture capitalist and former AI researchers, discusses impact of AI and why today&rsquo;s techniques will have a huge impact on the world&hellip;Today&rsquo;s AI systems are going to influence the world&rsquo;s economy so much that their uptake will lead to what looks in hindsight like another industrial revolution, says Chinese venture capitalist Kai-Fu Lee, in an interview with Edge. &ldquo;We&rsquo;re all going to face a very challenging next fifteen or twenty years, when half of the jobs are going to be replaced by machines. Humans have never seen this scale of massive job decimation.&nbsp;The industrial revolution took a lot longer,&rdquo; he said.&nbsp; &nbsp;He also says that he worries deep learning might be a one-trick pony, in the sense that we can&rsquo;t expect other similarly scaled breakthroughs to occur in the next few years, and we should adjust our notions of AI progress on this basis. &ldquo;You cannot go ahead and predict that we&rsquo;re going to have a breakthrough next year, and then the month after that, and then the day after that. That would be exponential. Exponential adoption of applications is, for now, happening. That&rsquo;s great, but the idea of exponential inventions is a ridiculous concept. The people who make those claims and who claim singularity is ahead of us, I think that&rsquo;s just based on absolutely no engineering reality,&rdquo; he says. &nbsp;&nbsp;AI Haves and Have-Nots: Countries like China and the USA that have large populations and significant investments in AI stand to fair well in the new AI era, he says. &ldquo;The countries that are not in good shape are the countries that have perhaps a large population, but no AI, no technologies, no Google, no Tencent, no Baidu, no Alibaba, no Facebook, no Amazon. These people will basically be data points to countries whose software is dominant in their country.&rdquo; &nbsp;&nbsp;Read more: We Are Here To Create, A Conversation With Kai-Fu Lee (Edge).
AI practitioners&nbsp;grapple with the upcoming information apocalypse:..And you thought DeepFakes was bad. Wait till DeepWar&hellip;Members of the AI community are beginning to sound the alarm about the imminent arrival of stunningly good, stunningly easy to make synthetic images and videos. In a blog post, AI practitioners say that the increasing availability of data combined with easily accessible AI infrastructure (cloud-rentable GPUs) is lowering the barrier to entry for people that want to make this stuff, and that ongoing progress in AI capabilities means the quality of these fake media is increasing over time.&nbsp;&nbsp;How can we deal with these information threats? We could look at how society already makes it hard to forge currencies via making it costly to produce high-fidelity copies and in parallel developing technologies to verify the authenticity of currency materials. Unfortunately, though this may help with some of the problems brought about by AI forgery, it doesn&rsquo;t deal with the root problems: AI is predominantly embodied in software rather than hardware and so it&rsquo;s going to be difficult to insert detectable (and non-spoofable) distinct visual/audio signatures into generated media barring some kind of DRM-on-steroids. One solution could be to train AI classifiers on real and faked datasets from the same domain so as to provide classifiers to spot faked media in the wild.&nbsp; Read more: Commoditisation of AI, digital forgery and the end of trust: how we can fix it.
Berkeley researchers use Soft Q-Learning to let robots compose solutions to tasks:&hellip;Research reduces the time it takes to learn new behaviors on robots&hellip;Berkeley researchers have figured out how to use soft q-learning, a recently introduced variant of traditional q-learning, to let robots learn more efficiently. They introduce a new trick where they&rsquo;re able to learn to compose new q-functions from existing learned policies, letting them, for example, train a robot to move its arm to a particular distribution of X positions, then to a particular distribution of Y positions, then they can create a new policy which moves the arm to the intersection of the X and Y positions without having been trained on the combination previously. This sort of learning is typically quite difficult to achieve in a single policy as it requires so much exploration that most algorithms will spend a long time trying and failing to succeed at the task.&nbsp; Real world: The researchers train real robots to succeed at tasks like reaching to a specific location and stacking Lego blocks. They also demonstrate the utility of combining policies by training a robot to avoid an obstacle near its arm and separately training it to stack legos, then combine the two policies allowing the robot to stack blocks while avoiding an obstacle, despite having never been trained on the combination before.&nbsp;&nbsp;Why it matters: The past few years of AI progress have let us get very good at developing systems which excel at individual capabilities; being able to combine capabilities in an ad-hoc manner to generate new behaviors further increases the capabilities of AI systems and makes it possible to learn a distribution of atomic behaviors then chain these together to succeed at far more complex tasks than those found within the training set.&nbsp; Read more: Composable Deep Reinforcement Learning for Robotic Manipulation (Arxiv).
Think your AI model has a good understanding of physics? Run it on IntPhys and prepare to be embarrassed:&hellip;Testing AI systems in the same way we test infants and creatures&hellip;INRIA and Facebook and CNRS researchers have released IntPhys, a new way to evaluate AI systems&rsquo; ability to model the physical world around them using what the researchers call a &lsquo;physical plausibility test&rsquo;. IntPhys follows in a recent trend in AI for testing systems on tougher problems that more closely map to the sorts of problems humans typically tackle (see, AI2&rsquo;s &lsquo;ARC&rsquo; dataset for written reasoning, and DeepMind&rsquo;s cognitive science-inspired &lsquo;PsychLab&rsquo; environment).&nbsp; How it works: IntPhys presents AI systems with movies of scenes rendered in UnrealEngine4 and challenges them to figure out whether one scene can lead to another, letting them test models&rsquo; ability to internalize fundamental concepts about the world like object permanence, causality, etc. Systems need to compute a &ldquo;plausibility score&rdquo; for each of the scenes or scene combinations they are shown, then use this to figure out if the systems have learned about the underlying dynamics of the world.&nbsp; The IntPhys Benchmark: v1 of IntPhys focuses on unsupervised learning. The first version tests systems&rsquo; ability to understand object permanence. Future releases will include more tests for things like shape constancy, spatio-temporal continuity, and so on. The initial IntPhys release contains 15,000 videos of possible events, each video around 7 seconds long running at 15fps, totalling 21 hours of videos. It also incorporates some additional information so you don&rsquo;t have to attempt to solve the task in a purely unsupervised manner, including depth of field data for each image, as well as object instance segmentation masks.&nbsp; Baseline Systems VERSUS Humans: The researchers create two baselines for others to evaluate their systems against: a CNN encoder-decoder system, and a conditional GAN. &ldquo;Preliminary work with predictions at the pixel level revealed that our models failed at predicting convincing object motions, especially for small objects on a rich background. For this reason, we switched to computing predictions at a higher level, using object masks.&rdquo; The researchers tested humans on their system, finding that humans had an average error rate of about 8 percent when …