---

layout: post
category: C7VJAGM2R
title: "Google shares developer preview of TensorFlow Lite"
date: 2017-11-15 01:31:26
link: https://vrhk.co/2zYq490
image: https://tctechcrunch2011.files.wordpress.com/2017/05/google-io-2017-0284.jpg?w=1200&fit=200%2C150
domain: techcrunch.com
author: "TechCrunch"
icon: https://s0.wp.com/wp-content/themes/vip/techcrunch-2013/assets/images/favicon.ico
excerpt: "Developers were pretty psyched by the announcement&nbsp;at Google I/O back in May that a new version of TensorFlow was being built from the ground up for mobile devices.&nbsp;Today, Google has released a developer preview of TensorFlow Lite.
The software library is aimed at&nbsp;creating a more lightweight machine learning solution for smartphone and embedded devices. The company is calling it an evolution of TensorFlow for mobile and it&rsquo;s available now for both Android and iOS app developers.
The focus here won&rsquo;t be on training models but rather on bringing low-latency inference from machine learning models to less robust devices. In layman&rsquo;s terms this means TensorFlow Lite will focus on applying existing capabilities of models to new data it&rsquo;s given rather than learning new capabilities from existing data, something most mobile devices simply don&rsquo;t have the horsepower to handle.
Google detailed that the big priorities when they designed TF Lite from scratch was to emphasize a lightweight product that could initialize quickly and improve model load times on a variety of mobile devices.&nbsp;TensorFlow Lite supports the Android Neural Networks API.
This isn&rsquo;t a full release so there&rsquo;s still much more to come as the library takes shape and things get added. Right now Google says TensorFlow Lite is tuned and ready for a few different vision and natural language processing models like MobileNet, Inception v3 and Smart Reply.
&ldquo;With this developer preview, we have intentionally started with a constrained platform to ensure performance on some of the most important common models,&rdquo; a post authored by the TensorFlow team read. &ldquo;We plan to prioritize future functional expansion based on the needs of our users. The goals for our continued development are to simplify the developer experience, and enable model deployment for a range of mobile and embedded devices.&rdquo;
Interested developers can dig into the TF Lite documentation and get to obsessing."

---

### Google shares developer preview of TensorFlow Lite

Developers were pretty psyched by the announcement&nbsp;at Google I/O back in May that a new version of TensorFlow was being built from the ground up for mobile devices.&nbsp;Today, Google has released a developer preview of TensorFlow Lite.
The software library is aimed at&nbsp;creating a more lightweight machine learning solution for smartphone and embedded devices. The company is calling it an evolution of TensorFlow for mobile and it&rsquo;s available now for both Android and iOS app developers.
The focus here won&rsquo;t be on training models but rather on bringing low-latency inference from machine learning models to less robust devices. In layman&rsquo;s terms this means TensorFlow Lite will focus on applying existing capabilities of models to new data it&rsquo;s given rather than learning new capabilities from existing data, something most mobile devices simply don&rsquo;t have the horsepower to handle.
Google detailed that the big priorities when they designed TF Lite from scratch was to emphasize a lightweight product that could initialize quickly and improve model load times on a variety of mobile devices.&nbsp;TensorFlow Lite supports the Android Neural Networks API.
This isn&rsquo;t a full release so there&rsquo;s still much more to come as the library takes shape and things get added. Right now Google says TensorFlow Lite is tuned and ready for a few different vision and natural language processing models like MobileNet, Inception v3 and Smart Reply.
&ldquo;With this developer preview, we have intentionally started with a constrained platform to ensure performance on some of the most important common models,&rdquo; a post authored by the TensorFlow team read. &ldquo;We plan to prioritize future functional expansion based on the needs of our users. The goals for our continued development are to simplify the developer experience, and enable model deployment for a range of mobile and embedded devices.&rdquo;
Interested developers can dig into the TF Lite documentation and get to obsessing.