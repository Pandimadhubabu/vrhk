---

layout: post
category: threads
title: "[D] Batch Normalization exploding/vanishing WEIGHTS?"
date: 2018-05-26 19:07:52
link: https://vrhk.co/2xghVfU
image: https://www.redditstatic.com/icon.png
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "Multiplying weights by a constant has no effect if I normalize. So how can I ensure the weights don't just drift together towards really large..."

---

### [D] Batch Normalization exploding/vanishing WEIGHTS? â€¢ r/MachineLearning

Multiplying weights by a constant has no effect if I normalize. So how can I ensure the weights don't just drift together towards really large...