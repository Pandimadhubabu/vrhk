---

layout: post
category: research
title: "Generative Modeling with Sparse Transformers"
date: 2019-04-23 16:03:44
link: https://vrhk.co/2UPklxa
image: 
domain: openai.com
author: "OpenAI"
icon: https://openai.com/assets/images/favicon.png
excerpt: "We've developed the Sparse Transformer, a deep neural network which sets new records at predicting what comes next in a sequence — whether text, images, or sound. It uses an algorithmic improvement of the attention mechanism to extract patterns from sequences 30x longer than possible previously. Read Paper [<https://d4mucfpksywv.cloudfront.net/Sparse_Transformer/sparse_transformers.pdf>] View Code [<https://github.com/openai/sparse_attention>]One existing challenge in AI research is modeling long"

---

### Generative Modeling with Sparse Transformers

We've developed the Sparse Transformer, a deep neural network which sets new records at predicting what comes next in a sequence — whether text, images, or sound. It uses an algorithmic improvement of the attention mechanism to extract patterns from sequences 30x longer than possible previously. Read Paper [<https://d4mucfpksywv.cloudfront.net/Sparse_Transformer/sparse_transformers.pdf>] View Code [<https://github.com/openai/sparse_attention>]One existing challenge in AI research is modeling long