---

layout: post
category: threads
title: "[D] Why does gated convolution work for language modeling but self-attention model doesn't?"
date: 2018-05-24 09:12:55
link: https://vrhk.co/2IJpJrF
image: https://www.redditstatic.com/icon.png
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "I've applied modifications of Transformer to language modeling datasets such as PTB, WikiText-2, char-PTB and enwik8 in a way similar to that of..."

---

### [D] Why does gated convolution work for language modeling but self-attention model doesn't? â€¢ r/MachineLearning

I've applied modifications of Transformer to language modeling datasets such as PTB, WikiText-2, char-PTB and enwik8 in a way similar to that of...