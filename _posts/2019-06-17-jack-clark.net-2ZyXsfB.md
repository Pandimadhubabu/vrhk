---

layout: post
category: product
title: "Import AI 151: US Army trains StarCraft II AI; teaching drones to dodge thrown objects; and fighting climate change with machine learning"
date: 2019-06-17 16:26:31
link: https://vrhk.co/2ZyXsfB
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Drones that dodge, evade, and avoid objects &ndash; they&rsquo;re closer than you think:&hellip;Drones are an omni-use platform, and they&rsquo;re about to get really smart&hellip;The University of Maryland and the University of Zurich have taught drones how to dodge rapidly moving objects, taking a further step towards building semi-autonomous, adaptive small-scale aircraft. The research shows that drones equipped with a few basic sensors and some clever AI software can learn to dodge (and chase) a variety of objects. &ldquo;To our knowledge, this is the first deep learning based solution to the problem of dynamic obstacle avoidance using event cameras on a quadrotor&rdquo;, they write.
How it works: The approach has three key components, which are each specialized modules that use neural networks or optical flow approaches. These systems and their corresponding functions are as follows: 
EVDeBlurNet &ndash; deblur and denoise the event image sequences before any computation takes place
EVHomographyNet &ndash; approximate background motion 
EVSegFlowNet &ndash; segment moving objects and compute their image motion
 &nbsp;&nbsp;These three systems let the drones clean up its input images so it can compute over them, then work out where it is, then look at the objects around itself and react.
How well does it work? The researchers approach is promising but not ready for any kind of real-world deployment, due to insufficient accuracy. However, the system displays promising breadth when it comes to dealing with a variety of objects to dodge. For assessment, the researchers run 30 tests with each object and report the result. In tests, the researchers find that the drone can easily dodge thrown balls and model cars (86% success), can dodge and chase another drone (83%), can dodge two objects thrown at it in quick success (76%), struggles a bit with an oddly shaped model plane (73%), and achieves a success rate of 70% in a low-light experiment.
Why this matters: Drones are getting smaller and smarter, and research like this shows how pretty soon we&rsquo;re likely going to be able to build DIY drones that have what I&rsquo;d term &lsquo;dumb spatial intelligence&rsquo;, that is, we can start to train these systems to do things like dodge moving objects, navigate around obstacles, deal with occluded environments, and learn to follow or fly towards specific people or objects. The implications for this are significant, unlocking numerous commercial applications, while also changing the landscape of asymmetric warfare in profound ways, the consequences of which shall likely highlight the difficulty of controlling AI capability use and diffusion.&nbsp; Read more: EVDodge: Embodied AI For High-Speed Dodging On A Quadrotor Using Event Cameras (Arxiv).
#####################################################
&ldquo;Build marines!&rdquo; &ndash; US Army trains teaches RL agents to respond to voice commands:&hellip;StarCraft II research highlights military interest in complex, real-time strategy games&hellip;US Army Research Laboratory researchers have developed a reinforcement learning agent that can carry out actions in response to pre-defined human commands. For this experiment, they test in the domain of StarCraft II, a complex real-time strategy game. The goal of this is to work out smarter ways in which humans can control semi-autonomous AI systems in the future. &ldquo;Our mutual-embedding model provides a promising mechanism for creating a generalized sequential reward that capitalizes on a human&rsquo;s capacity to utilize higher order knowledge to achieve long-term goals,&rdquo; they write. &ldquo;By providing a means for a human to guide a learning agent via natural language, generalizable sequential policies may be learned without the overhead of creating hand-crafted sub-tasks or checkpoints that would depend critically on expert knowledge about RL reward functions&rdquo;.
How it works: The researchers use a relatively simple technique of &ldquo;training a mutual-embedding model using a multi-input deep-neural network that projects a sequence of natural language commands into the same high-dimensional representation space as corresponding goal states&rdquo;. In a prototype experiment, they see how well they can use voice commands to succeed at the &lsquo;BuildMarines&rsquo; challenge, a mini-game within the StarCraft 2 environment.
Why this matters: Developing more natural interfaces between humans and AI systems is a long-standing goal of AI research, and it&rsquo;s interesting to see how military organizations think about this problem. I wouldn&rsquo;t be surprised to see more military organizations explore using StarCraft 2 as a basic testing ground for advanced AI systems, given its overlap with natural military interests of logistics, supply chains, and the marshaling and deployment of forces.&nbsp;&nbsp;Read more: Grounding Natural Language Commands to StarCraft II Game States for Narration-Guided Reinforcement Learning (Arxiv).
#####################################################
UN researchers generate fake UN speeches:&hellip;Machine-driven diplomacy&hellip;Researchers affiliated with the United Nations&rsquo; &lsquo;Global Pulse&rsquo; and the University of &nbsp;Durham, have used AI systems to generate remarks in the style of political leaders speaking at the UN General Assembly. For this experiment, they train on the English language transcripts of 7,507 speeches given by political leaders at the UN General Assembly (UNGA) between 1970 and 2015.
Training tools and costs: The core of this system as an AWD-LSTM model pre-trained on Wikitext-103, then fine-tuned against the corpus of UN data. Training cost as little as $7.80 total when using AWS spot instances, and took about 13 hours using NVIDIA k80 GPUs.
Dataset bias: The experiment serves as a proof-of-concept that also highlights some of the ways in which dataset bias can influence language models &ndash; while it was relatively easy for the authors to prompt the language model to generate UN-style speeches, they found it was more difficult to generate &lsquo;inflammatory&rsquo; speeches as there are fewer of these in the UN dataset.
How well does it work: Qualitatively, the model is able to periodically generate samples that can read like convincing extracts from real speeches. For instance, a model prompted with &ldquo;The Secretary-General strongly condemns the deadly terrorist attacks that took place in Mogadishu&rdquo; generates the outputs &ldquo;We fully support the action undertaken by the United Nations and the international community in that regard, as well as to the United Nations and the African Union, to ensure that the children of this country are left alone in the process of rebuilding their societies.&rdquo;
Implications: Language models like these have a few implications, the researchers write. These include the likelihood of broad diffusion of the technology (for example, though OpenAI chose not to fully release its GPT-2 model, others might); it being generally easier to generate disinformation; it being easy to automatically generate hate speech; and it becoming easier to train models to impersonate people.
Recommendations: So, what do we do? The authors recommend we map the human rights impacts of these technologies, develop tools for systematically and continuously monitoring AI-generated content, set up strategies for countermeasures, and build alliances between various AI actors to develop a &ldquo;coherent and proactive global strategy&rdquo;.
Why this matters: Research like this highlights the concern some people feel about increasingly powerful models, and emphasizes the significant implications of them for society, as well as the need for us to think creatively about interventions to deal with the most easy-to-anticipate malicious uses of such systems.&nbsp;&nbsp;Read more: Automated Speech Generation from UN General Assembly Statements: Mapping Risks in AI Gen…"

---

### Import AI 151: US Army trains StarCraft II AI; teaching drones to dodge thrown objects; and fighting climate change with machine learning

Drones that dodge, evade, and avoid objects &ndash; they&rsquo;re closer than you think:&hellip;Drones are an omni-use platform, and they&rsquo;re about to get really smart&hellip;The University of Maryland and the University of Zurich have taught drones how to dodge rapidly moving objects, taking a further step towards building semi-autonomous, adaptive small-scale aircraft. The research shows that drones equipped with a few basic sensors and some clever AI software can learn to dodge (and chase) a variety of objects. &ldquo;To our knowledge, this is the first deep learning based solution to the problem of dynamic obstacle avoidance using event cameras on a quadrotor&rdquo;, they write.
How it works: The approach has three key components, which are each specialized modules that use neural networks or optical flow approaches. These systems and their corresponding functions are as follows: 
EVDeBlurNet &ndash; deblur and denoise the event image sequences before any computation takes place
EVHomographyNet &ndash; approximate background motion 
EVSegFlowNet &ndash; segment moving objects and compute their image motion
 &nbsp;&nbsp;These three systems let the drones clean up its input images so it can compute over them, then work out where it is, then look at the objects around itself and react.
How well does it work? The researchers approach is promising but not ready for any kind of real-world deployment, due to insufficient accuracy. However, the system displays promising breadth when it comes to dealing with a variety of objects to dodge. For assessment, the researchers run 30 tests with each object and report the result. In tests, the researchers find that the drone can easily dodge thrown balls and model cars (86% success), can dodge and chase another drone (83%), can dodge two objects thrown at it in quick success (76%), struggles a bit with an oddly shaped model plane (73%), and achieves a success rate of 70% in a low-light experiment.
Why this matters: Drones are getting smaller and smarter, and research like this shows how pretty soon we&rsquo;re likely going to be able to build DIY drones that have what I&rsquo;d term &lsquo;dumb spatial intelligence&rsquo;, that is, we can start to train these systems to do things like dodge moving objects, navigate around obstacles, deal with occluded environments, and learn to follow or fly towards specific people or objects. The implications for this are significant, unlocking numerous commercial applications, while also changing the landscape of asymmetric warfare in profound ways, the consequences of which shall likely highlight the difficulty of controlling AI capability use and diffusion.&nbsp; Read more: EVDodge: Embodied AI For High-Speed Dodging On A Quadrotor Using Event Cameras (Arxiv).
#####################################################
&ldquo;Build marines!&rdquo; &ndash; US Army trains teaches RL agents to respond to voice commands:&hellip;StarCraft II research highlights military interest in complex, real-time strategy games&hellip;US Army Research Laboratory researchers have developed a reinforcement learning agent that can carry out actions in response to pre-defined human commands. For this experiment, they test in the domain of StarCraft II, a complex real-time strategy game. The goal of this is to work out smarter ways in which humans can control semi-autonomous AI systems in the future. &ldquo;Our mutual-embedding model provides a promising mechanism for creating a generalized sequential reward that capitalizes on a human&rsquo;s capacity to utilize higher order knowledge to achieve long-term goals,&rdquo; they write. &ldquo;By providing a means for a human to guide a learning agent via natural language, generalizable sequential policies may be learned without the overhead of creating hand-crafted sub-tasks or checkpoints that would depend critically on expert knowledge about RL reward functions&rdquo;.
How it works: The researchers use a relatively simple technique of &ldquo;training a mutual-embedding model using a multi-input deep-neural network that projects a sequence of natural language commands into the same high-dimensional representation space as corresponding goal states&rdquo;. In a prototype experiment, they see how well they can use voice commands to succeed at the &lsquo;BuildMarines&rsquo; challenge, a mini-game within the StarCraft 2 environment.
Why this matters: Developing more natural interfaces between humans and AI systems is a long-standing goal of AI research, and it&rsquo;s interesting to see how military organizations think about this problem. I wouldn&rsquo;t be surprised to see more military organizations explore using StarCraft 2 as a basic testing ground for advanced AI systems, given its overlap with natural military interests of logistics, supply chains, and the marshaling and deployment of forces.&nbsp;&nbsp;Read more: Grounding Natural Language Commands to StarCraft II Game States for Narration-Guided Reinforcement Learning (Arxiv).
#####################################################
UN researchers generate fake UN speeches:&hellip;Machine-driven diplomacy&hellip;Researchers affiliated with the United Nations&rsquo; &lsquo;Global Pulse&rsquo; and the University of &nbsp;Durham, have used AI systems to generate remarks in the style of political leaders speaking at the UN General Assembly. For this experiment, they train on the English language transcripts of 7,507 speeches given by political leaders at the UN General Assembly (UNGA) between 1970 and 2015.
Training tools and costs: The core of this system as an AWD-LSTM model pre-trained on Wikitext-103, then fine-tuned against the corpus of UN data. Training cost as little as $7.80 total when using AWS spot instances, and took about 13 hours using NVIDIA k80 GPUs.
Dataset bias: The experiment serves as a proof-of-concept that also highlights some of the ways in which dataset bias can influence language models &ndash; while it was relatively easy for the authors to prompt the language model to generate UN-style speeches, they found it was more difficult to generate &lsquo;inflammatory&rsquo; speeches as there are fewer of these in the UN dataset.
How well does it work: Qualitatively, the model is able to periodically generate samples that can read like convincing extracts from real speeches. For instance, a model prompted with &ldquo;The Secretary-General strongly condemns the deadly terrorist attacks that took place in Mogadishu&rdquo; generates the outputs &ldquo;We fully support the action undertaken by the United Nations and the international community in that regard, as well as to the United Nations and the African Union, to ensure that the children of this country are left alone in the process of rebuilding their societies.&rdquo;
Implications: Language models like these have a few implications, the researchers write. These include the likelihood of broad diffusion of the technology (for example, though OpenAI chose not to fully release its GPT-2 model, others might); it being generally easier to generate disinformation; it being easy to automatically generate hate speech; and it becoming easier to train models to impersonate people.
Recommendations: So, what do we do? The authors recommend we map the human rights impacts of these technologies, develop tools for systematically and continuously monitoring AI-generated content, set up strategies for countermeasures, and build alliances between various AI actors to develop a &ldquo;coherent and proactive global strategy&rdquo;.
Why this matters: Research like this highlights the concern some people feel about increasingly powerful models, and emphasizes the significant implications of them for society, as well as the need for us to think creatively about interventions to deal with the most easy-to-anticipate malicious uses of such systems.&nbsp;&nbsp;Read more: Automated Speech Generation from UN General Assembly Statements: Mapping Risks in AI Gen…