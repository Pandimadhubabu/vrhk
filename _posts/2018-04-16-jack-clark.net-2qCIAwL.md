---

layout: post
category: product
title: "Import AI: #90: Training massive networks via ‘codistillation’, talking to books via a new Google AI experiment, and why the ACM thinks researchers should consider the downsides of research"
date: 2018-04-16 20:04:49
link: https://vrhk.co/2qCIAwL
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Training unprecedentedly large networks with &lsquo;codistillation&rsquo;:&hellip;New technique makes it easier to train very large, distributed AI systems, without adding too much complexity&hellip;When it comes to applied AI, bigger can frequently be better; access to more data, more compute, and (occasionally) more complex infrastructures can frequently allow people to obtain better performance at lower cost. But there are limits. One limit is in the ability for people to parallelize the computation of a single neural network during training. To deal with that, researchers at places like Google have introduced techniques like &lsquo;ensemble distillation&rsquo; which let you train multiple networks in parallel and use these to train a single &lsquo;student&rsquo; network that benefits from the aggregated learnings of its many parents. Though this technique has shown to be effective it is also quite fiddly and introduces additional complexity which can make people less keen to use it. New research from Google simplifies this idea via a technique they call &lsquo;codistillaiton&rsquo;.&nbsp; How it works: &ldquo;Codistillation trains n copies of a model in parallel by adding a term to the loss function of the ith model to match the average prediction of the other models.&rdquo; This approach is superior to distributed stochastic gradient descent in terms of accuracy and training time and is also not too bad from a reproducability perspective.&nbsp; Testing: Codistillation was recently proposed in separate research. But this is Google, so the difference with this paper is that they validate the technique at truly vast scales. How vast? Google took a subset of the Common Crawl to create a dataset consisting 20 terabytes of text spread across 915 million documents which, after processing, consist of about 673 billion distinct word tokens. This is &ldquo;much larger than any previous neural language modeling data set we are aware of,&rdquo; they write. It&rsquo;s so large it&rsquo;s still unfeasible to train models on the entire corpus, even with techniques like this. They also test the dataset on ImageNet and on the &lsquo;Criteo Display Ad Challenge&rsquo; dataset for predicting click through rates for ads.&nbsp; Results: In tests on the &lsquo;Common Crawl&lsquo; dataset using distributed SGD the researchers find that they can scale the number of distinct GPUs working on the task and discovered that after around 128 GPUs you tend to encounter diminishing returns and that jumping to 256 GPUs is actively counterproductive. They find they can significantly outperform distributed SGD baselines via the use of codistillation and that this obtains performance on par with the more fiddly ensembling technique. The researchers demonstrate more rapid training on ImageNet compared to baselines, also, and showed on Criteo that two-way codistillation can achieve a lower log loss than an equivalent ensembled baseline.&nbsp; Why it matters: As datasets get larger, companies will want to train them in their entirety and will want to use more computers than before to speed training times. Techniques like codistillation will make that sort of thing easier to do. Combine that with ambitious schemes like Google&rsquo;s own &lsquo;One Model to Rule Them All&rsquo; theory (train an absolutely vast model on a whole bunch of different inputs on the assumption it can learn useful, abstract representations that it derives from its diverse inputs) and you have the ingredient for smarter services at a world-spanning scale.&nbsp; Read more: Large scale distributed neural network training through online distillation (Arxiv).
AI is not a cure all, do not treat it as such:&hellip;When automation goes wrong, Tesla edition&hellip;It&rsquo;s worth remembering that AI isn&rsquo;t a cure-all and it&rsquo;s frequently better to try to automate a discrete task within a larger job than to automate everything in an end-to-end manner. Elon Musk learned this lesson recently with the heavily automated production line for the Model 3 at Tesla. &ldquo;Excessive automation at Tesla was a mistake,&rdquo; wrote the entrepreneur in a tweet. &ldquo;To be price, my mistake. Humans are underrated.&rdquo;&nbsp;&nbsp;Read the tweet here (Twitter).
Google adds probabilistic programming tools to TensorFlow:&hellip;Probability add-ons are probably a good thing, probably&hellip;Google has added a suite of new probabilistic programming features to its TensorFlow programming framework. The free update includes a bunch of statistical building blocks for TF, a new probabilistic programming language called Edward2 (which is based on Edward, developed by Dustin Tran), algorithms for probabilistic inference, and pre-made models and inference tools.&nbsp; Read more: Introducing TensorFlow Probability (TensorFlow Medium).&nbsp; Get the code: TensorFlow Probability (GitHub).
#COMMUNITY SERVICE#
I&rsquo;m currently participating in the &lsquo;Assembly&rsquo; program at the Berkman Klein Center and the MIT Media Lab. As part of that program our group of assemblers are working on a bunch of projects relating to issues of AI and ethics and governance. One of those groups would benefit from the help of readers of this newsletter. Their blurb follows&hellip;Do you work with data? Want to make AI work better for more people? We need your help! Please fill out a quick and easy survey.We are a group of researchers at Assembly creating standards for dataset quality. We&rsquo;d love to hear how you work with data and get your feedback on a &lsquo;Nutrition Label for Datasets&rsquo; prototype that we&rsquo;re building.Take our anonymous (5 min) survey.Thanks so much in advance!
Learning generalizable skills with Universal Planning Networks:&hellip;Unsupervised objectives? No thanks! Auxiliary objectives? No thanks! Plannable representations as an objective? Yes please!&hellip;Researchers with the University of California at Berkeley have published details on Universal Planning Networks, a new way to try to train AI systems to be able to complete objectives. Their technique relies on encouraging the AI system to try to learn things about the world which it can chain together, allowing it to be trained to plan how to solve tasks.&nbsp; The main component of the technique is what the researchers call a &lsquo;gradient descent planner&rsquo;. This is a differentiable module that uses autoencoders to encode the current observations and the goal observations into a system which then figures out actions it can take to get from its current observations to its goal observation. The exciting part of this research is that the researchers have figured out how to integrate planning in such a way that it is end-to-end differentiable, so you can set it running and augment it with helpful inputs &ndash; in this case, an imitation learning loss to help it learn from human demonstrations &ndash; to let it learn how to plan effectively for the given task it is solving. &ldquo;&rdquo;By embedding a differentiable planning computation inside the policy, our method enables joint training of the planner and its underlying latent encoder and forward dynamics representations,&rdquo; they explain.&nbsp;&nbsp;Results: The researchers evaluate their system on two simulated robot tasks, using a small force-controlled point robot and a 3-link torque-controlled reacher robot. UPNs outperform &lsquo;reactive imitation learning&rsquo; and &lsquo;auto-regressive imitation learner&rsquo; baselines, converging faster on higher scores from fewer numbers of demonstrations than comparisons.&nbsp;&nbsp;Why it matters: If we want AI systems to be able to take actions in the real world then we need to be able to train them to plan their way through tricky, multi-stage tasks. Efforts like this research will help us achieve that, allowing us to test AI systems against increasingly rich and multi-faceted environments.&nbsp;&nbsp;Read more: Universal Planning Networks (Arxi…"

---

### Import AI: #90: Training massive networks via ‘codistillation’, talking to books via a new Google AI experiment, and why the ACM thinks researchers should consider the downsides of research

Training unprecedentedly large networks with &lsquo;codistillation&rsquo;:&hellip;New technique makes it easier to train very large, distributed AI systems, without adding too much complexity&hellip;When it comes to applied AI, bigger can frequently be better; access to more data, more compute, and (occasionally) more complex infrastructures can frequently allow people to obtain better performance at lower cost. But there are limits. One limit is in the ability for people to parallelize the computation of a single neural network during training. To deal with that, researchers at places like Google have introduced techniques like &lsquo;ensemble distillation&rsquo; which let you train multiple networks in parallel and use these to train a single &lsquo;student&rsquo; network that benefits from the aggregated learnings of its many parents. Though this technique has shown to be effective it is also quite fiddly and introduces additional complexity which can make people less keen to use it. New research from Google simplifies this idea via a technique they call &lsquo;codistillaiton&rsquo;.&nbsp; How it works: &ldquo;Codistillation trains n copies of a model in parallel by adding a term to the loss function of the ith model to match the average prediction of the other models.&rdquo; This approach is superior to distributed stochastic gradient descent in terms of accuracy and training time and is also not too bad from a reproducability perspective.&nbsp; Testing: Codistillation was recently proposed in separate research. But this is Google, so the difference with this paper is that they validate the technique at truly vast scales. How vast? Google took a subset of the Common Crawl to create a dataset consisting 20 terabytes of text spread across 915 million documents which, after processing, consist of about 673 billion distinct word tokens. This is &ldquo;much larger than any previous neural language modeling data set we are aware of,&rdquo; they write. It&rsquo;s so large it&rsquo;s still unfeasible to train models on the entire corpus, even with techniques like this. They also test the dataset on ImageNet and on the &lsquo;Criteo Display Ad Challenge&rsquo; dataset for predicting click through rates for ads.&nbsp; Results: In tests on the &lsquo;Common Crawl&lsquo; dataset using distributed SGD the researchers find that they can scale the number of distinct GPUs working on the task and discovered that after around 128 GPUs you tend to encounter diminishing returns and that jumping to 256 GPUs is actively counterproductive. They find they can significantly outperform distributed SGD baselines via the use of codistillation and that this obtains performance on par with the more fiddly ensembling technique. The researchers demonstrate more rapid training on ImageNet compared to baselines, also, and showed on Criteo that two-way codistillation can achieve a lower log loss than an equivalent ensembled baseline.&nbsp; Why it matters: As datasets get larger, companies will want to train them in their entirety and will want to use more computers than before to speed training times. Techniques like codistillation will make that sort of thing easier to do. Combine that with ambitious schemes like Google&rsquo;s own &lsquo;One Model to Rule Them All&rsquo; theory (train an absolutely vast model on a whole bunch of different inputs on the assumption it can learn useful, abstract representations that it derives from its diverse inputs) and you have the ingredient for smarter services at a world-spanning scale.&nbsp; Read more: Large scale distributed neural network training through online distillation (Arxiv).
AI is not a cure all, do not treat it as such:&hellip;When automation goes wrong, Tesla edition&hellip;It&rsquo;s worth remembering that AI isn&rsquo;t a cure-all and it&rsquo;s frequently better to try to automate a discrete task within a larger job than to automate everything in an end-to-end manner. Elon Musk learned this lesson recently with the heavily automated production line for the Model 3 at Tesla. &ldquo;Excessive automation at Tesla was a mistake,&rdquo; wrote the entrepreneur in a tweet. &ldquo;To be price, my mistake. Humans are underrated.&rdquo;&nbsp;&nbsp;Read the tweet here (Twitter).
Google adds probabilistic programming tools to TensorFlow:&hellip;Probability add-ons are probably a good thing, probably&hellip;Google has added a suite of new probabilistic programming features to its TensorFlow programming framework. The free update includes a bunch of statistical building blocks for TF, a new probabilistic programming language called Edward2 (which is based on Edward, developed by Dustin Tran), algorithms for probabilistic inference, and pre-made models and inference tools.&nbsp; Read more: Introducing TensorFlow Probability (TensorFlow Medium).&nbsp; Get the code: TensorFlow Probability (GitHub).
#COMMUNITY SERVICE#
I&rsquo;m currently participating in the &lsquo;Assembly&rsquo; program at the Berkman Klein Center and the MIT Media Lab. As part of that program our group of assemblers are working on a bunch of projects relating to issues of AI and ethics and governance. One of those groups would benefit from the help of readers of this newsletter. Their blurb follows&hellip;Do you work with data? Want to make AI work better for more people? We need your help! Please fill out a quick and easy survey.We are a group of researchers at Assembly creating standards for dataset quality. We&rsquo;d love to hear how you work with data and get your feedback on a &lsquo;Nutrition Label for Datasets&rsquo; prototype that we&rsquo;re building.Take our anonymous (5 min) survey.Thanks so much in advance!
Learning generalizable skills with Universal Planning Networks:&hellip;Unsupervised objectives? No thanks! Auxiliary objectives? No thanks! Plannable representations as an objective? Yes please!&hellip;Researchers with the University of California at Berkeley have published details on Universal Planning Networks, a new way to try to train AI systems to be able to complete objectives. Their technique relies on encouraging the AI system to try to learn things about the world which it can chain together, allowing it to be trained to plan how to solve tasks.&nbsp; The main component of the technique is what the researchers call a &lsquo;gradient descent planner&rsquo;. This is a differentiable module that uses autoencoders to encode the current observations and the goal observations into a system which then figures out actions it can take to get from its current observations to its goal observation. The exciting part of this research is that the researchers have figured out how to integrate planning in such a way that it is end-to-end differentiable, so you can set it running and augment it with helpful inputs &ndash; in this case, an imitation learning loss to help it learn from human demonstrations &ndash; to let it learn how to plan effectively for the given task it is solving. &ldquo;&rdquo;By embedding a differentiable planning computation inside the policy, our method enables joint training of the planner and its underlying latent encoder and forward dynamics representations,&rdquo; they explain.&nbsp;&nbsp;Results: The researchers evaluate their system on two simulated robot tasks, using a small force-controlled point robot and a 3-link torque-controlled reacher robot. UPNs outperform &lsquo;reactive imitation learning&rsquo; and &lsquo;auto-regressive imitation learner&rsquo; baselines, converging faster on higher scores from fewer numbers of demonstrations than comparisons.&nbsp;&nbsp;Why it matters: If we want AI systems to be able to take actions in the real world then we need to be able to train them to plan their way through tricky, multi-stage tasks. Efforts like this research will help us achieve that, allowing us to test AI systems against increasingly rich and multi-faceted environments.&nbsp;&nbsp;Read more: Universal Planning Networks (Arxi…