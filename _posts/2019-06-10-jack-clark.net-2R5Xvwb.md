---

layout: post
category: product
title: "Import AI 150: Training a kiss detector; bias in AI, rich VS poor edition; and just how good is deep learning surveillance getting?"
date: 2019-06-10 16:31:25
link: https://vrhk.co/2R5Xvwb
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "What happens when AI alters society as much as computers and the web have done?&hellip;Researchers contemplate long-term trajectory of AI, and detail a lens to use to look at its evolution&hellip;Based on how the World Wide Web and the Computing industry altered society, how might we expect the progression of artificial intelligence to influence society? That&rsquo;s the question researchers with Cognizant Technology Solutions and the University of Texas at Austin try to answer in a new research paper. 
The four phases of technology: According to the researchers, any technology has four defining phases &ndash; standardization; usability; consumerization; and foundationalization [?]. For example, the &lsquo;usability&rsquo; phase for computing was when people adopted GUI interfaces, while for the web, it was when people adopted stylesheets to separate content from presentation. By stage four (where computing is now and where the web is heading) &ldquo;people do not have to care where and how it happens &ndash; they simply interact with its results, the same way we interact with a light switch or a faucet&rdquo;, they write.
Lessons for the AI sector: Right now, AI as a technology is at the pre-standardization stage/. 
 &nbsp;&nbsp;Standardization: We need standards for how we connect AI systems together. &ldquo;It should be possible to transport the functionality from one task to another,&rdquo; they write, &ldquo;e.g. to learn to recognize a different category of objects&rdquo; across different classification infrastructures using shared systems.
&nbsp;&nbsp;Usability: AI needs interfaces that everyone can use and access, the authors write. They then reference Microsoft&rsquo;s dominance of the PC industry in the 1990s as an example of the sort of thing we want to avoid with AI, though it&rsquo;s pretty unclear from the paper what they mean by usability and accessibility here.
&nbsp;&nbsp;Consumerization: The general public will need to be able to easily create AI services. &ldquo;People can routinely produce, configure, teach, and such systems for different purposes and domains,&rdquo; they write. &ldquo;They may include intelligent assistants that manage an individual&rsquo;s everyday activities, finances, and health, but also AI systems that design interiors, gardents, and clothing, maintain buildings, appliances and vehicles, and interact with other people and their AIs.
&nbsp;&nbsp;Foundationalization, &ldquo;AI will be routinely running business operations, optimizing government policies, transportation, agriculture, and healthcare,&rdquo; they write. AI will be particularly useful for directing societies to solve complex, intractable problems, they write. &ldquo;For instance, we may decide to maximize productivity and growth, but at the same time minimize cost and environmental impact, and promote equal access and diversity.&rdquo;
Why this matters: AI researchers are increasingly seeking to situate themselves and their research in relation to the social as well as technical phenomena of AI, and papers like this are artefacts of this process. I think this prefigures the general politicization of the AI community. I suspect that in a couple of years we may even need an additional Arxiv sub-category to contain such papers as these.&nbsp;&nbsp;Read more: Better Future through AI: Avoiding Pitfalls and Guiding AI Towards its Full Potential (Arxiv).
#####################################################
Deep learning + surveillance = it&rsquo;s getting better all the time:&hellip;Vehicle re-identification survey shows how significant deep learning is for automating surveillance systems&hellip;How good has deep learning been for vehicle surveillance? A significant effect, according to a survey paper from researchers with the University of Hail in Saudi Arabia. 
Sensor-based methods: In the early 90s, researchers developed sensor-based methods for identifying and re-identifying vehicles; these methods used things like inductive loops, as well as sensors for infrared, ultrasonic, microwave, magnetic, and piezoelectric. Other methods have explored using systems like GPS, mobile phone signatures, and RFID and MAC address-based identification. People have also explored using multi-sensor systems to increase the accuracy of identifications. All of these systems had drawbacks, mostly relating to them breaking in the presence of unanticipated things, like modified or occluded vehicles.
Vision-based methods: Pre-deep learning and from the early 2000s, people experimented with a bunch of hand-crafted feature-based methods to try to create more flexible less sensor-dependent approaches to the task of vehicle identification. These techniques can do things like generate bounding boxes around vehicles, and even match specific vehicles between non-overlapping camera fields. But these methods also have drawbacks relating to their brittleness, and dependence on features that may change or be occluded. &ldquo;The performance of appearance based approaches is limited due to different colors and shapes of vehicles&rdquo;, they write.
Deep learning: Since the ImageNet breakthrough in 2012, researchers have increasingly used these techniques for vision problems, including for vehicle re-identification, mostly because they&rsquo;re simpler systems to implement and tend to have better generalization properties. These methods typically use convolutional neural networks, sometimes paired with an LSTM. Any deep learning method appears to outperform hand-crafted based methods, according to tests in which 12 deep learning-based methods were compared against 8 hand-crafted ones. 
The future of vehicle re-identification: Vehicles vary in appearance a lot more than humans, so it will be more difficult to train classifiers that can accurately identify all the vehicles that can pass through a city on a given day. Additionally, we&rsquo;ll need to build larger datasets to be able to better model the temporal aspect of entity-tracking &ndash; this should also let us accurately identify vehicles with bigger lags between them. 
Why this matters: The maturation of deep learning technology is irrevocably changing surveillance, improving the capabilities and scalability of a bunch of surveillance techniques, including vehicle re-identification. 
 &nbsp;&nbsp;Read more: A survey of advances in vision-based vehicle re-identification (Arxiv). 
#####################################################
AI Stock Image of the Week:Thanks to Delip Rao for surfacing this delightful contribution to the burgeoning media genre.
#####################################################
Spotting intimacy in Hollywood films with a kiss detector:&hellip;Conv and Lution sitting in a tree, K-I-S-S-I-N-G!&hellip;Amir Ziai, a researcher at Stanford University, has built a deep learning-based kissing detector! The unbearably cute project takes in a video clip, spots all the kissing scenes in it, then splices thouse scenes together into an output. 
Classifying Kissing: So, how do you spot kissing? Here, we use a multi-modal classifier which uses a network to detect the visual appearance of a kiss, and another network which scans the audio over that same period, extracting features out of it (architecture used: &lsquo;VGGish&rsquo;, &ldquo;a very effective feature extractor for downstream Acoustic Event Detection).
&nbsp; &nbsp;The dataset: The data for this research is a 2.3TB database of ~600 Hollywood films spanning 1915 to 2016, with files ranging in size from 200MB and 12GB. 100 of these movies have been annotated with kissing segments, for a total of 263 kissing segments and 363 non-kissing segments across 100 films. 
The trained &lsquo;kiss detector&rsquo; gets an F1 score of 0.95 or so, so in a particularly salacious movie you might expect to get a few mis-hits in the output, but you&rsquo;ll likely capture the majority of the moments if you run this over it. 
&nbsp; &nbsp;Why this matters: This is a good examp…"

---

### Import AI 150: Training a kiss detector; bias in AI, rich VS poor edition; and just how good is deep learning surveillance getting?

What happens when AI alters society as much as computers and the web have done?&hellip;Researchers contemplate long-term trajectory of AI, and detail a lens to use to look at its evolution&hellip;Based on how the World Wide Web and the Computing industry altered society, how might we expect the progression of artificial intelligence to influence society? That&rsquo;s the question researchers with Cognizant Technology Solutions and the University of Texas at Austin try to answer in a new research paper. 
The four phases of technology: According to the researchers, any technology has four defining phases &ndash; standardization; usability; consumerization; and foundationalization [?]. For example, the &lsquo;usability&rsquo; phase for computing was when people adopted GUI interfaces, while for the web, it was when people adopted stylesheets to separate content from presentation. By stage four (where computing is now and where the web is heading) &ldquo;people do not have to care where and how it happens &ndash; they simply interact with its results, the same way we interact with a light switch or a faucet&rdquo;, they write.
Lessons for the AI sector: Right now, AI as a technology is at the pre-standardization stage/. 
 &nbsp;&nbsp;Standardization: We need standards for how we connect AI systems together. &ldquo;It should be possible to transport the functionality from one task to another,&rdquo; they write, &ldquo;e.g. to learn to recognize a different category of objects&rdquo; across different classification infrastructures using shared systems.
&nbsp;&nbsp;Usability: AI needs interfaces that everyone can use and access, the authors write. They then reference Microsoft&rsquo;s dominance of the PC industry in the 1990s as an example of the sort of thing we want to avoid with AI, though it&rsquo;s pretty unclear from the paper what they mean by usability and accessibility here.
&nbsp;&nbsp;Consumerization: The general public will need to be able to easily create AI services. &ldquo;People can routinely produce, configure, teach, and such systems for different purposes and domains,&rdquo; they write. &ldquo;They may include intelligent assistants that manage an individual&rsquo;s everyday activities, finances, and health, but also AI systems that design interiors, gardents, and clothing, maintain buildings, appliances and vehicles, and interact with other people and their AIs.
&nbsp;&nbsp;Foundationalization, &ldquo;AI will be routinely running business operations, optimizing government policies, transportation, agriculture, and healthcare,&rdquo; they write. AI will be particularly useful for directing societies to solve complex, intractable problems, they write. &ldquo;For instance, we may decide to maximize productivity and growth, but at the same time minimize cost and environmental impact, and promote equal access and diversity.&rdquo;
Why this matters: AI researchers are increasingly seeking to situate themselves and their research in relation to the social as well as technical phenomena of AI, and papers like this are artefacts of this process. I think this prefigures the general politicization of the AI community. I suspect that in a couple of years we may even need an additional Arxiv sub-category to contain such papers as these.&nbsp;&nbsp;Read more: Better Future through AI: Avoiding Pitfalls and Guiding AI Towards its Full Potential (Arxiv).
#####################################################
Deep learning + surveillance = it&rsquo;s getting better all the time:&hellip;Vehicle re-identification survey shows how significant deep learning is for automating surveillance systems&hellip;How good has deep learning been for vehicle surveillance? A significant effect, according to a survey paper from researchers with the University of Hail in Saudi Arabia. 
Sensor-based methods: In the early 90s, researchers developed sensor-based methods for identifying and re-identifying vehicles; these methods used things like inductive loops, as well as sensors for infrared, ultrasonic, microwave, magnetic, and piezoelectric. Other methods have explored using systems like GPS, mobile phone signatures, and RFID and MAC address-based identification. People have also explored using multi-sensor systems to increase the accuracy of identifications. All of these systems had drawbacks, mostly relating to them breaking in the presence of unanticipated things, like modified or occluded vehicles.
Vision-based methods: Pre-deep learning and from the early 2000s, people experimented with a bunch of hand-crafted feature-based methods to try to create more flexible less sensor-dependent approaches to the task of vehicle identification. These techniques can do things like generate bounding boxes around vehicles, and even match specific vehicles between non-overlapping camera fields. But these methods also have drawbacks relating to their brittleness, and dependence on features that may change or be occluded. &ldquo;The performance of appearance based approaches is limited due to different colors and shapes of vehicles&rdquo;, they write.
Deep learning: Since the ImageNet breakthrough in 2012, researchers have increasingly used these techniques for vision problems, including for vehicle re-identification, mostly because they&rsquo;re simpler systems to implement and tend to have better generalization properties. These methods typically use convolutional neural networks, sometimes paired with an LSTM. Any deep learning method appears to outperform hand-crafted based methods, according to tests in which 12 deep learning-based methods were compared against 8 hand-crafted ones. 
The future of vehicle re-identification: Vehicles vary in appearance a lot more than humans, so it will be more difficult to train classifiers that can accurately identify all the vehicles that can pass through a city on a given day. Additionally, we&rsquo;ll need to build larger datasets to be able to better model the temporal aspect of entity-tracking &ndash; this should also let us accurately identify vehicles with bigger lags between them. 
Why this matters: The maturation of deep learning technology is irrevocably changing surveillance, improving the capabilities and scalability of a bunch of surveillance techniques, including vehicle re-identification. 
 &nbsp;&nbsp;Read more: A survey of advances in vision-based vehicle re-identification (Arxiv). 
#####################################################
AI Stock Image of the Week:Thanks to Delip Rao for surfacing this delightful contribution to the burgeoning media genre.
#####################################################
Spotting intimacy in Hollywood films with a kiss detector:&hellip;Conv and Lution sitting in a tree, K-I-S-S-I-N-G!&hellip;Amir Ziai, a researcher at Stanford University, has built a deep learning-based kissing detector! The unbearably cute project takes in a video clip, spots all the kissing scenes in it, then splices thouse scenes together into an output. 
Classifying Kissing: So, how do you spot kissing? Here, we use a multi-modal classifier which uses a network to detect the visual appearance of a kiss, and another network which scans the audio over that same period, extracting features out of it (architecture used: &lsquo;VGGish&rsquo;, &ldquo;a very effective feature extractor for downstream Acoustic Event Detection).
&nbsp; &nbsp;The dataset: The data for this research is a 2.3TB database of ~600 Hollywood films spanning 1915 to 2016, with files ranging in size from 200MB and 12GB. 100 of these movies have been annotated with kissing segments, for a total of 263 kissing segments and 363 non-kissing segments across 100 films. 
The trained &lsquo;kiss detector&rsquo; gets an F1 score of 0.95 or so, so in a particularly salacious movie you might expect to get a few mis-hits in the output, but you&rsquo;ll likely capture the majority of the moments if you run this over it. 
&nbsp; &nbsp;Why this matters: This is a good examp…