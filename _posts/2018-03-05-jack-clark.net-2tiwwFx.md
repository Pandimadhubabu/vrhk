---

layout: post
category: product
title: "Import AI: #84: xView dataset means the planet is about to learn how to see itself, a $125 million investment in common sense AI, and SenseTime shows off TrumpObama AI face swap"
date: 2018-03-05 20:07:06
link: https://vrhk.co/2tiwwFx
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s0.wp.com/i/webclip.png
excerpt: "Chinese AI startup SenseTime joins MIT&rsquo;s &lsquo;Intelligence Quest&rsquo; initiative:&hellip;Funding plus&nbsp;politics in one neat package&hellip;
Chinese AI giant SenseTime is joining the &lsquo;MIT Intelligence Quest&rsquo;, a pan-MIT AI research and development initiative. The Chinese company specializes in facial recognition and self-driving cars and has signed strategic partnerships with large companies like Honda, Qualcomm, and others. At an AI event at MIT recently SenseTime&rsquo;s founder Xiao&rsquo;ou Tang gave a short speech with a couple of eyebrow-raising demonstrations to discuss the partnership. &ldquo;I think together we will definitely go beyond just deep learning we will go to the uncharted territory of deep thinking,&rdquo; Tang said.&nbsp;&nbsp;Data growth: Tang said SenseTime is developing better facial recognition algorithms using larger amounts of data, saying the company in 2016 improved its facial recognition accuracy to &ldquo;one over a million&rdquo; using 60 million photos, then in 2017 improved that to &ldquo;one over a hundred million&rdquo; via a dataset of two billion photos. (That&rsquo;s not a typo.)&nbsp;&nbsp;Fake Presidents: He also gave a brief demonstration of a SenseTime synthetic video project which generatively morphed footage of President Obama speaking into President Trump speaking, and vice versa. I recorded a quick video of this demonstration which you can view on Twitter here (Video).Read more: MIT and SenseTime announce effort to advance artificial intelligence research (MIT).
Chinese state media calls for collaboration on AI development:&hellip;Xinhua commentary says China&rsquo;s rise in AI &lsquo;is a boon instead of a threat&rsquo;&hellip;
A comment piece in Chinese state media Xinhua tries to debunk some of the cold war lingo surrounding China&rsquo;s rise in AI, pushing back on accusations that Chinese AI is &ldquo;copycat&rdquo; and calling for more cooperation and less competition. Liu Qingfeng, iFlyTek&rsquo;s CEO, told Xinhua at CES that massive data sets, algorithms and professionals are a must-have combination for AI, which &ldquo;requires global cooperation&rdquo; and &ldquo;no company can play hegemony&rdquo;, Xinhua wrote.Read more: Commentary: AI development needs global cooperation, not China-phobia (Xinhua).
New xView dataset represents a new era of geopolitics as countries seek to automate the analysis of the world:&hellip;US defense researchers release dataset and associated competition to push the envelop on satellite imagery analysis&hellip;
Researchers with the DoD&rsquo;s Defense Innovation Unit Experimental (DIUx), DigitalGlobe, and the National Geospatial-Intelligence Agency, have released xView, a dataset and associated competition used to assess the ability for AI methods to classify overhead satellite imagery. xView includes one million distinct objects across 60 classes, spread across 1,400km2 of satellite imagery with a maximum ground sample resolution of 0.3m. The dataset is designed to test various frontiers of image recognition, including: learning efficiency, fine-grained class detection, and multiscale recognition, among others. The competition includes $100,000 of prize money, along with compute credits.Why it matters: The earth is beginning to look at itself. As launch capabilities get cheaper via new rockets like SpaceX, Rocket Labs, etc, better hardware comes online as a consequent of further improvements in electronics, and more startups stick satellites into orbit, the amount of data available about the earth is going to grow by several orders of magnitude. If we can figure out how to analyze these datasets using AI techniques we can ultimately better respond to the changes in our planet and to marshal resources for the purposes of remediating natural disasters and, more generally, to better equip large losticis organizations like militaries to better understand the world around them and plan and act accordingly. A new era of high-information geopolitics is approaching&hellip;&nbsp;&nbsp;I spy with my satelite eye: xView includes numerous objects with parent classes and sub-classes, such as &lsquo;maritime vessels&rsquo; with sub-classes including sailboat and oil tanker. Other classes include fixed wing aircraft, passenger vehicles, trucks, engineering vehicles, railway vehicles, and buildings. &ldquo;xView contributes a large, multi-class, multi-location dataset in the object detection and satellite imagery space, built with the benchmark capabilities of PASCAL VOC, the quality control methodologies of COCO, and the contributions of other overhead datasets in mind,&rdquo; they write. Some of the most frequently covered objects in the dataset include buildings and small cars, while some of the rarest include vehicles like a reach stacker and a tractor, and vessels like an oil tanker.&nbsp;&nbsp;Baseline results: The researchers created a classification baseline via implementing a Single Shot Multibox Detector meta-architecture (SSD) and testing it on three variants of the dataset: standard xView, multi-resolution, and multi-resolution augmented via image augmentation. The best results were found from training on the multi-resolution dataset, with accuracies climbing to as high as over 67% for cargo planes. The scores are mostly pretty underwhelming, so it&rsquo;ll be interesting to see what scores people get when they apply more sophisticated deep learning-based methods to the problem.&nbsp;&nbsp;Milspec data precision: &ldquo;We achieved consistency by having all annotation performed at a single facility, following detailed guidelines, with output subject to multiple quality control checks. Workers extensively annotated image chips with bounding boxes using an open source tool,&rdquo; write the authors. Other AI researchers may want to aspire to equally high standards, if they can afford it.&nbsp;&nbsp;Read more: xView: Objects in Context in Overhead Imagery (Arxiv).&nbsp;&nbsp;Get the dataset: xView website.
Adobe researchers try to give robots a better sense of navigation with &lsquo;AdobeIndoorNav&rsquo; dataset:&hellip;Plus: automating data collection with Tango phones + commodity robots&hellip;
Adobe researchers have released AdobeIndoorNav, a dataset intended to help robots navigate the real-world. The contains 3,544 distinct locations across 24 individual &lsquo;scenes&rsquo; that a virtual robot can learn to navigate. Each scene corresponds to a real-world location and contains a 3D reconstruction via a point cloud, a 360-degree panoramic view, and front/back/left/right views from the perspective of a small ground-based robot. Combined, the dataset gives AI researchers a set of environments to develop robot navigation systems in. &ldquo;The proposed setting is an intentionally simplified version of real-world robot visual navigation with neither moving obstacles nor continuous actuation,&rdquo; the researchers write.&nbsp;&nbsp;Why it matters: For real-world robotic AI systems to be more useful they&rsquo;ll have to be capable of being dropped into novel locations and figuring out how to navigate themselves around to specific targets. This research shows that we&rsquo;re still a long, long way away from theoretical breakthroughs that give us this capability, but does include some encouraging signs for our ability to automate the necessary data gathering process to create the datasets needed to develop baselines to evaluate new algorithms on.&nbsp;&nbsp;Data acquisition: The researchers used a Lenovo Phab 2 Tango phone to scan each scene by hand to create a 3D point cloud, which they then automatically decomposed into a map of specific obstacles as well as a 3D map. A &lsquo;Yujin Turtlebot 2&lsquo; robot then uses these maps along with its onboard laser scanner, RGB-D camera, and 360 camera to navigate around the scene and take a series of high resolution 360 photos, which it then stitches into a coherent scene.&nbsp;&nbsp;Results: The resear…"

---

### Import AI: #84: xView dataset means the planet is about to learn how to see itself, a $125 million investment in common sense AI, and SenseTime shows off TrumpObama AI face swap

Chinese AI startup SenseTime joins MIT&rsquo;s &lsquo;Intelligence Quest&rsquo; initiative:&hellip;Funding plus&nbsp;politics in one neat package&hellip;
Chinese AI giant SenseTime is joining the &lsquo;MIT Intelligence Quest&rsquo;, a pan-MIT AI research and development initiative. The Chinese company specializes in facial recognition and self-driving cars and has signed strategic partnerships with large companies like Honda, Qualcomm, and others. At an AI event at MIT recently SenseTime&rsquo;s founder Xiao&rsquo;ou Tang gave a short speech with a couple of eyebrow-raising demonstrations to discuss the partnership. &ldquo;I think together we will definitely go beyond just deep learning we will go to the uncharted territory of deep thinking,&rdquo; Tang said.&nbsp;&nbsp;Data growth: Tang said SenseTime is developing better facial recognition algorithms using larger amounts of data, saying the company in 2016 improved its facial recognition accuracy to &ldquo;one over a million&rdquo; using 60 million photos, then in 2017 improved that to &ldquo;one over a hundred million&rdquo; via a dataset of two billion photos. (That&rsquo;s not a typo.)&nbsp;&nbsp;Fake Presidents: He also gave a brief demonstration of a SenseTime synthetic video project which generatively morphed footage of President Obama speaking into President Trump speaking, and vice versa. I recorded a quick video of this demonstration which you can view on Twitter here (Video).Read more: MIT and SenseTime announce effort to advance artificial intelligence research (MIT).
Chinese state media calls for collaboration on AI development:&hellip;Xinhua commentary says China&rsquo;s rise in AI &lsquo;is a boon instead of a threat&rsquo;&hellip;
A comment piece in Chinese state media Xinhua tries to debunk some of the cold war lingo surrounding China&rsquo;s rise in AI, pushing back on accusations that Chinese AI is &ldquo;copycat&rdquo; and calling for more cooperation and less competition. Liu Qingfeng, iFlyTek&rsquo;s CEO, told Xinhua at CES that massive data sets, algorithms and professionals are a must-have combination for AI, which &ldquo;requires global cooperation&rdquo; and &ldquo;no company can play hegemony&rdquo;, Xinhua wrote.Read more: Commentary: AI development needs global cooperation, not China-phobia (Xinhua).
New xView dataset represents a new era of geopolitics as countries seek to automate the analysis of the world:&hellip;US defense researchers release dataset and associated competition to push the envelop on satellite imagery analysis&hellip;
Researchers with the DoD&rsquo;s Defense Innovation Unit Experimental (DIUx), DigitalGlobe, and the National Geospatial-Intelligence Agency, have released xView, a dataset and associated competition used to assess the ability for AI methods to classify overhead satellite imagery. xView includes one million distinct objects across 60 classes, spread across 1,400km2 of satellite imagery with a maximum ground sample resolution of 0.3m. The dataset is designed to test various frontiers of image recognition, including: learning efficiency, fine-grained class detection, and multiscale recognition, among others. The competition includes $100,000 of prize money, along with compute credits.Why it matters: The earth is beginning to look at itself. As launch capabilities get cheaper via new rockets like SpaceX, Rocket Labs, etc, better hardware comes online as a consequent of further improvements in electronics, and more startups stick satellites into orbit, the amount of data available about the earth is going to grow by several orders of magnitude. If we can figure out how to analyze these datasets using AI techniques we can ultimately better respond to the changes in our planet and to marshal resources for the purposes of remediating natural disasters and, more generally, to better equip large losticis organizations like militaries to better understand the world around them and plan and act accordingly. A new era of high-information geopolitics is approaching&hellip;&nbsp;&nbsp;I spy with my satelite eye: xView includes numerous objects with parent classes and sub-classes, such as &lsquo;maritime vessels&rsquo; with sub-classes including sailboat and oil tanker. Other classes include fixed wing aircraft, passenger vehicles, trucks, engineering vehicles, railway vehicles, and buildings. &ldquo;xView contributes a large, multi-class, multi-location dataset in the object detection and satellite imagery space, built with the benchmark capabilities of PASCAL VOC, the quality control methodologies of COCO, and the contributions of other overhead datasets in mind,&rdquo; they write. Some of the most frequently covered objects in the dataset include buildings and small cars, while some of the rarest include vehicles like a reach stacker and a tractor, and vessels like an oil tanker.&nbsp;&nbsp;Baseline results: The researchers created a classification baseline via implementing a Single Shot Multibox Detector meta-architecture (SSD) and testing it on three variants of the dataset: standard xView, multi-resolution, and multi-resolution augmented via image augmentation. The best results were found from training on the multi-resolution dataset, with accuracies climbing to as high as over 67% for cargo planes. The scores are mostly pretty underwhelming, so it&rsquo;ll be interesting to see what scores people get when they apply more sophisticated deep learning-based methods to the problem.&nbsp;&nbsp;Milspec data precision: &ldquo;We achieved consistency by having all annotation performed at a single facility, following detailed guidelines, with output subject to multiple quality control checks. Workers extensively annotated image chips with bounding boxes using an open source tool,&rdquo; write the authors. Other AI researchers may want to aspire to equally high standards, if they can afford it.&nbsp;&nbsp;Read more: xView: Objects in Context in Overhead Imagery (Arxiv).&nbsp;&nbsp;Get the dataset: xView website.
Adobe researchers try to give robots a better sense of navigation with &lsquo;AdobeIndoorNav&rsquo; dataset:&hellip;Plus: automating data collection with Tango phones + commodity robots&hellip;
Adobe researchers have released AdobeIndoorNav, a dataset intended to help robots navigate the real-world. The contains 3,544 distinct locations across 24 individual &lsquo;scenes&rsquo; that a virtual robot can learn to navigate. Each scene corresponds to a real-world location and contains a 3D reconstruction via a point cloud, a 360-degree panoramic view, and front/back/left/right views from the perspective of a small ground-based robot. Combined, the dataset gives AI researchers a set of environments to develop robot navigation systems in. &ldquo;The proposed setting is an intentionally simplified version of real-world robot visual navigation with neither moving obstacles nor continuous actuation,&rdquo; the researchers write.&nbsp;&nbsp;Why it matters: For real-world robotic AI systems to be more useful they&rsquo;ll have to be capable of being dropped into novel locations and figuring out how to navigate themselves around to specific targets. This research shows that we&rsquo;re still a long, long way away from theoretical breakthroughs that give us this capability, but does include some encouraging signs for our ability to automate the necessary data gathering process to create the datasets needed to develop baselines to evaluate new algorithms on.&nbsp;&nbsp;Data acquisition: The researchers used a Lenovo Phab 2 Tango phone to scan each scene by hand to create a 3D point cloud, which they then automatically decomposed into a map of specific obstacles as well as a 3D map. A &lsquo;Yujin Turtlebot 2&lsquo; robot then uses these maps along with its onboard laser scanner, RGB-D camera, and 360 camera to navigate around the scene and take a series of high resolution 360 photos, which it then stitches into a coherent scene.&nbsp;&nbsp;Results: The resear…