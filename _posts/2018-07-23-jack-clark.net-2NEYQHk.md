---

layout: post
category: product
title: "Import AI: #204: Using AirBNB to generate data for robots; Google trains AI to beat humans at lip-reading; and NIH releases massive ‘DeepLesion’ CT dataset"
date: 2018-07-23 17:17:19
link: https://vrhk.co/2NEYQHk
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Rosie the Robot takes a step closer with new CMU robotics research:&hellip;What&rsquo;s the best way to gather a new robotics research dataset &ndash; AirBNB?!&hellip;Carnegie Mellon researchers have done the robotics research equivalent of &lsquo;having cake and eating it too; &ndash; they have created a new dataset to evaluate generalization within robotics, and have successfully built low-cost robotics which have been able to show meaningful performance on the dataset. The motivation for the research is that most robotics datasets are specific to highly-controlled lab environments, and instead it&rsquo;s worth exploring generating and gathering data from more real world locations (in this case, homes rented on AirBNB), then see if it&rsquo;s possible to develop a system that can learn to grasp objects within these datasets, and see if the use of these datasets improves generalization relative to other techniques.&nbsp; How it works: The approach has three key components: a Grasp Prediction Network (GPN) which takes in pixel imagery and tries to predict the correct grasp to take (and which is fine-tuned from a pretrained ResNet-18 model); a Noise Modelling Network (NMN) which tries to estimate the latent noise based on the image of the scene and information from the robot; and a marginalization layer which helps combine the two data streams to predict the best grasp to use. &nbsp;&nbsp;The robot: They use a Dobot Magician robotic arm with five degrees of freedom, customized with a two axis wrist with electric gripper, and mounted on a Kobuki mobile base. For sensing, they re-quip it with an Intel R200 RGB camera with a pan-tilt attachment positioned 1m above the ground. The robot&rsquo;s onboard processor is a laptop with an i5-8250U CPU with 8GB of RAM. Each of these robots costs about $3,000 &ndash; far less than the $20k+ prices for most other robots.&nbsp;&nbsp;Data gathering: To gather data for the robots the researchers used six different properties from AirBNB. They then deployed the robot in this home, used a low-cost &lsquo;YOLO&rsquo; model to generate bounding boxes around objects near the robot, then let the robot&rsquo;s GPN and NMN work together to help it predict how to grasp objects. They collect about 28,000 grasps in this manner. &nbsp;&nbsp;Results: The researchers try to evaluate their new dataset (which they call Home-LCA) as well as their new &lsquo;Robust-Grasp&rsquo; two-part GPN&amp;NMN network architecture. First, they examine the test accuracy of their Robus-Grasp network trained on the Home-LCA dataset and applied to other home environments, as well as two datasets which have been collected in traditional lab settings (Lab-Baxter and Lab-LCA). The results here are very encouraging as their approach seems to generalize better to the lab datasets than other approaches, suggesting that the Home-LCA dataset is rich enough to create policies which can generalize somewhat.&nbsp; They also test their approach on deployed physical environments in unseen home environments (three novel AirBNBs). The results show that Home-LCA does substantially better than Lab-derived datasets, showing performance of around 60% accuracy, compared to between 20% and 30% for other approaches &ndash; convincing results. &nbsp;&nbsp;Why it matters: Most robotics research suffers from one of two things: 1) either the robot is being trained and tested entirely in simulation, so it&rsquo;s hard to trust the results. 2) the robot is being evaluated on such a constricted task that it&rsquo;s hard to get a sense for whether algorithmic progress leading to improved task performance will generalize to other tasks. This paper neatly deals with both of those problems by situating the task and robot in reality, collecting real data, and also evaluating generalization. It also provides further evidence that robot component costs are falling while network performance is improving sufficiently for academic researchers to conduct large-scale real world robotic trials and development, which will no doubt further accelerate progress in this domain. &nbsp;&nbsp;Read more: Robot Learning in Homes: Improving Generalization and Reducing Dataset Bias (Arxiv).
Learning to navigate over a kilometer of paths, with generalization:&hellip;Bonus: Dataset augmentation techniques and experimental methodology increase confidence in result&hellip;QUT and DeepMind researchers have successfully trained a robot to learn to navigate over two kilometers of real-world paths connected up to one another by 2,099 distinct nodes. The approach shows that it&rsquo;s possible to learn sufficiently robust policies in simulation to be subsequently transferred to the real world, and the researchers validate their system by testing it on real world data.&nbsp; The method: &ldquo;We propose to train a graph-navigation agent on data obtained from a single coverage traversal of its operational environment, and deploy the learned policy in a continuous environment on the real robot,&rdquo; the researchers write. They create a map of a given location, framed as a graph with points and connections between them, gathering 360-degree images from an omnidirectional camera to populate each point on the graph and, in addition, gathering the data lying between each point. &ldquo;This amounts to approximately 30 extra viewpoints per discrete location, given our 15-Hz camera on a robot moving at 0.5 meters per second,&rdquo; they write. They then use this data to augment the main navigation task. They also introduce techniques to randomize &ndash; in a disciplined manner &ndash; the brightness of gathered images, which lets them create more synthetic data and better defend against robots trained with the system overfitting to specific patterns of light. They then use curriculum learning to train a simulated agent using A3C to learn to navigate between successively farther apart points of the (simulated) graph. These agents themselves use image recognition systems pre-trained on the Places365 dataset and finetuned on the gathered data. &nbsp;&nbsp;Results: The researchers test their system by deploying it on a real erobot (a Pioneer 3DX) and ask it to navigate to specific areas of the campus. There are a couple of reasons to really like this evaluation approach: one) they&rsquo;re testing it in reality rather than a simulator, so the results are more trustworthy, and 2) they test on the real robot three weeks after collecting the initial data, allowing for significant intermediary changes in things like the angle of the sun at given times of day, the density of people, placement of furniture, and other things that typically confound robots. They test their system against an &lsquo;oracle&rsquo; (aka, perfect) route, as well as what was learned during training in the simulator. The results show that their technique successfully generalizes to reality, navigating successfully to defined locations on ten out of eleven tries, but at a significant cost: on average, routes come up with in reality are on the order of 2.42X more complex than optimal routes.&nbsp; Why it matters: Robots are likely one of the huge markets that will be further expanded and influenced by continued development of AI technology. What this result indicates is that existing, basic algorithms (like A3C), combined with well-understood data collection techniques, are already sufficiently powerful to let us develop proof-of-concept robot demonstrations. The next stage will be learning to traverse far larger areas while reducing the &lsquo;reality penalty&rsquo; seen here of selected routes not being as efficient as optimal ones. &nbsp;&nbsp;Read more: Learning Deployable Navigation Policies at Kilometer Scale from a Single Traversal (Arxiv). &nbsp;&nbsp;Watch videos: Deployable Navigation Policies.
Why better measurements can lead to better robot research:&hellip;New tasks, best practices, and datasets to evaluate smart robot agents&hellip;An inter…"

---

### Import AI: #204: Using AirBNB to generate data for robots; Google trains AI to beat humans at lip-reading; and NIH releases massive ‘DeepLesion’ CT dataset

Rosie the Robot takes a step closer with new CMU robotics research:&hellip;What&rsquo;s the best way to gather a new robotics research dataset &ndash; AirBNB?!&hellip;Carnegie Mellon researchers have done the robotics research equivalent of &lsquo;having cake and eating it too; &ndash; they have created a new dataset to evaluate generalization within robotics, and have successfully built low-cost robotics which have been able to show meaningful performance on the dataset. The motivation for the research is that most robotics datasets are specific to highly-controlled lab environments, and instead it&rsquo;s worth exploring generating and gathering data from more real world locations (in this case, homes rented on AirBNB), then see if it&rsquo;s possible to develop a system that can learn to grasp objects within these datasets, and see if the use of these datasets improves generalization relative to other techniques.&nbsp; How it works: The approach has three key components: a Grasp Prediction Network (GPN) which takes in pixel imagery and tries to predict the correct grasp to take (and which is fine-tuned from a pretrained ResNet-18 model); a Noise Modelling Network (NMN) which tries to estimate the latent noise based on the image of the scene and information from the robot; and a marginalization layer which helps combine the two data streams to predict the best grasp to use. &nbsp;&nbsp;The robot: They use a Dobot Magician robotic arm with five degrees of freedom, customized with a two axis wrist with electric gripper, and mounted on a Kobuki mobile base. For sensing, they re-quip it with an Intel R200 RGB camera with a pan-tilt attachment positioned 1m above the ground. The robot&rsquo;s onboard processor is a laptop with an i5-8250U CPU with 8GB of RAM. Each of these robots costs about $3,000 &ndash; far less than the $20k+ prices for most other robots.&nbsp;&nbsp;Data gathering: To gather data for the robots the researchers used six different properties from AirBNB. They then deployed the robot in this home, used a low-cost &lsquo;YOLO&rsquo; model to generate bounding boxes around objects near the robot, then let the robot&rsquo;s GPN and NMN work together to help it predict how to grasp objects. They collect about 28,000 grasps in this manner. &nbsp;&nbsp;Results: The researchers try to evaluate their new dataset (which they call Home-LCA) as well as their new &lsquo;Robust-Grasp&rsquo; two-part GPN&amp;NMN network architecture. First, they examine the test accuracy of their Robus-Grasp network trained on the Home-LCA dataset and applied to other home environments, as well as two datasets which have been collected in traditional lab settings (Lab-Baxter and Lab-LCA). The results here are very encouraging as their approach seems to generalize better to the lab datasets than other approaches, suggesting that the Home-LCA dataset is rich enough to create policies which can generalize somewhat.&nbsp; They also test their approach on deployed physical environments in unseen home environments (three novel AirBNBs). The results show that Home-LCA does substantially better than Lab-derived datasets, showing performance of around 60% accuracy, compared to between 20% and 30% for other approaches &ndash; convincing results. &nbsp;&nbsp;Why it matters: Most robotics research suffers from one of two things: 1) either the robot is being trained and tested entirely in simulation, so it&rsquo;s hard to trust the results. 2) the robot is being evaluated on such a constricted task that it&rsquo;s hard to get a sense for whether algorithmic progress leading to improved task performance will generalize to other tasks. This paper neatly deals with both of those problems by situating the task and robot in reality, collecting real data, and also evaluating generalization. It also provides further evidence that robot component costs are falling while network performance is improving sufficiently for academic researchers to conduct large-scale real world robotic trials and development, which will no doubt further accelerate progress in this domain. &nbsp;&nbsp;Read more: Robot Learning in Homes: Improving Generalization and Reducing Dataset Bias (Arxiv).
Learning to navigate over a kilometer of paths, with generalization:&hellip;Bonus: Dataset augmentation techniques and experimental methodology increase confidence in result&hellip;QUT and DeepMind researchers have successfully trained a robot to learn to navigate over two kilometers of real-world paths connected up to one another by 2,099 distinct nodes. The approach shows that it&rsquo;s possible to learn sufficiently robust policies in simulation to be subsequently transferred to the real world, and the researchers validate their system by testing it on real world data.&nbsp; The method: &ldquo;We propose to train a graph-navigation agent on data obtained from a single coverage traversal of its operational environment, and deploy the learned policy in a continuous environment on the real robot,&rdquo; the researchers write. They create a map of a given location, framed as a graph with points and connections between them, gathering 360-degree images from an omnidirectional camera to populate each point on the graph and, in addition, gathering the data lying between each point. &ldquo;This amounts to approximately 30 extra viewpoints per discrete location, given our 15-Hz camera on a robot moving at 0.5 meters per second,&rdquo; they write. They then use this data to augment the main navigation task. They also introduce techniques to randomize &ndash; in a disciplined manner &ndash; the brightness of gathered images, which lets them create more synthetic data and better defend against robots trained with the system overfitting to specific patterns of light. They then use curriculum learning to train a simulated agent using A3C to learn to navigate between successively farther apart points of the (simulated) graph. These agents themselves use image recognition systems pre-trained on the Places365 dataset and finetuned on the gathered data. &nbsp;&nbsp;Results: The researchers test their system by deploying it on a real erobot (a Pioneer 3DX) and ask it to navigate to specific areas of the campus. There are a couple of reasons to really like this evaluation approach: one) they&rsquo;re testing it in reality rather than a simulator, so the results are more trustworthy, and 2) they test on the real robot three weeks after collecting the initial data, allowing for significant intermediary changes in things like the angle of the sun at given times of day, the density of people, placement of furniture, and other things that typically confound robots. They test their system against an &lsquo;oracle&rsquo; (aka, perfect) route, as well as what was learned during training in the simulator. The results show that their technique successfully generalizes to reality, navigating successfully to defined locations on ten out of eleven tries, but at a significant cost: on average, routes come up with in reality are on the order of 2.42X more complex than optimal routes.&nbsp; Why it matters: Robots are likely one of the huge markets that will be further expanded and influenced by continued development of AI technology. What this result indicates is that existing, basic algorithms (like A3C), combined with well-understood data collection techniques, are already sufficiently powerful to let us develop proof-of-concept robot demonstrations. The next stage will be learning to traverse far larger areas while reducing the &lsquo;reality penalty&rsquo; seen here of selected routes not being as efficient as optimal ones. &nbsp;&nbsp;Read more: Learning Deployable Navigation Policies at Kilometer Scale from a Single Traversal (Arxiv). &nbsp;&nbsp;Watch videos: Deployable Navigation Policies.
Why better measurements can lead to better robot research:&hellip;New tasks, best practices, and datasets to evaluate smart robot agents&hellip;An inter…