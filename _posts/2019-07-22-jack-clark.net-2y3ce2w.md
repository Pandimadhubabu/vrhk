---

layout: post
category: product
title: "Import AI 156: The 7,500 images that break image recognition systems; open source software for deleting objects from videos; and what it takes to do multilingual translation"
date: 2019-07-22 17:56:29
link: https://vrhk.co/2y3ce2w
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Want 7,500 images designed to trick your object recognition system? Check out the &lsquo;Natural Adversarial Examples&rsquo; dataset:&hellip;Can your AI system deal with these naturally occurring optical illusions?&hellip;Have you ever been fiddling in the kitchen and dropped an orange-colored ceramic knife into a pile of orange peels and temporarily lost it? I have! These kinds of visual puzzles can be confusing for humans, and are even more tricky for machines to deal with. Therefore, researchers with the University of Berkeley, the University of Washington and the University of Chicago have developed and released a dataset full of these &lsquo;natural adversarial examples&rsquo;, which should help researchers test the robustness of AI systems and develop more powerful ones.&nbsp;
Imagenet-A: You can get the data as an ImageNet classifier test called ImageNet-A, which consists of around 7,500 images designed to confuse and frustrate modern image recognition systems.
How hard are &lsquo;natural adversarial examples&rsquo;? Extremely hard! The researchers tested out DenseNet-121 and ResNeXt-50 models on the dataset and show that both obtain an accuracy rate of less than 3% on ImageNet-A (compared to accuracies of 97%+ on standard ImageNet). Things don&rsquo;t improve much when they try to train their AI systems with techniques designed to increase robustness of classifiers, finding that using things like adversarial training, styleized imagenet augmentation, uncertainty metrics, and other approaches don&rsquo;t work particularly well.&nbsp;
Why this matters: Being able to measure all the ways in which AI systems fail is a superpower, because such measurements can highlight the ways existing systems break and point researchers towards problems that can be worked on. I hope we&rsquo;ll see more competitions that use datasets like this to test how resilient algorithms are to confounding examples.&nbsp;&nbsp;&nbsp;Read more: Natural Adversarial Examples (Arxiv).&nbsp;&nbsp;&nbsp;Get the code and the &lsquo;IMAGENET-A&rsquo; dataset here (Natural Adversarial Examples GitHub).&nbsp;
####################################################
Computer, delete! Open source software for editing videos:&hellip;AI is making video-editing much cheaper and more effective&hellip;Ever wanted to pick a person or an animal or other object in a video and make it disappear? I&rsquo;m sure the thought has struck some of you sometimes. Now, open source AI projects let you do just this: Video Object Removal is a new GitHub project that does what it says. The technology lets you draw a bounding box around an object in a video, and then the AI system will try to remove the person and inpaint the scene behind them. The software is based on two distinct technologies: Deep Video Inpainting, and Fast Online Object Tracking and Segmentation: A Unifying Approach.&nbsp;
Why this matters: Media is going to change radically as a consequence of the proliferation of AI tools like this &ndash; get ready for a world where images and video are&nbsp; so easy to manipulate that they become just another paintbrush, and be prepared to disbelieve everything you see online.&nbsp;&nbsp;&nbsp;Get the code from the GitHub page here (GitHub).&nbsp;
####################################################
Breaking drones to let others make smarter drones:&hellip;&rsquo;ALFA&rdquo; datasets gives researchers flight data for when things go wrong&hellip;Researchers with the Robotics Institute at Carnegie Mellon University have released ALFA, a dataset containing flight data and telemetry from a model plane, including data when the plane breaks. ALFA will make it easier for people to assess how well fault-spotting and fault-remediation algorithms work when exposed to real world failures.&nbsp;
ALFA consists of data for 47 autonomous flights with scenarios for eight different types of faults, including engine, rudder, and elevator errors. The data represents 66 minutes of normal flight and 13 minutes of post-fault flight time taking place over a mixture of fields and woodland near Pittsburgh, and there&rsquo;s also a larger unprocessed dataset representing &ldquo;several hours of raw autonomous, autopilot-assisted, and manual flight data with tens of different faults scenarios&rdquo;.&nbsp;
Hardware: To collect the dataset, the researchers used a modified Carbon Z T-28 model plane, equipped with an onboard Nvidia Jetson TX2 computer, and running &lsquo;Pixhawk&rsquo; autopilot software modified so that the researchers can remotely break the plan, generating the failure data.&nbsp;
Why this matters: Science tends to spend more time and resources inventing things and making forward progress on problems, rather than breaking things and casting a skeptical eye on recent events (mostly); datasets like ALFA make it easier for people to study failures, which will ultimately make it easier to develop more robust systems.&nbsp;&nbsp;&nbsp;Read more: ALFA: A Dataset for UAV Fault and Anomaly Detection (Arxiv).&nbsp;&nbsp;&nbsp;Get the ALFA data here (AIR Lab Failure and Anomaly (ALFA) Dataset website).
####################################################
How far are we from training a single AI system to translate between all languages?&hellip;Study involves 25 billion parallel sentences across 103 languages&hellip;How good are modern multilingual machine learning-based translation systems &ndash; that is, systems which can translate between a multitude of different languages, typically via using the same massive trained model? A new study from Google &ndash; which it says may be the largest ever conducted of its kind &ndash; analyzes the performance of these systems in the wild.&nbsp;
Data: For the study, the researchers evaluate &ldquo;a massive open-domain dataset containing over 25 billion parallel sentences in 103 languages&rdquo; using a large-scale machine translation system. They think that &ldquo;this is the largest multilingual NMT system to date, in terms of the amount of training data and number of languages considered at the same time&rdquo;. The datasets are distributed somewhat unevenly, though, reflecting the differing levels of documentation available for different languages. &ldquo;The number of parallel sentences per language in our corpus ranges from around tens of thousands to almost 2 billion&rdquo;, they write; there is a discrepancy of almost 5 orders of magnitude between the languages with the greatest and smallest amounts of data in the corpus. Google generated this data by crawling and extracting parallel sentences from the web, it writes.&nbsp;
Desirable features: An excellent multilingual translation system should have the following properties, according to the researchers:
Maximum throughput in terms of number of languages considered within a single model.&nbsp;
Positive transfer towards low-resource languages.&nbsp;
Minimum interference (negative transfer) for high-resource languages.&nbsp;
Models that perform well in &ldquo;realistic, open-domain settings&rdquo;.
When More Data Does Not Equal Better Data: One of the main findings of the study is the difficulty of training large models on such varied datasets, the researchers write. &ldquo;In a large multi-task setting, high resource tasks are starved for capacity while low resource tasks benefit significantly from transfer, and the extent of interference and transfer are strongly related.&rdquo; They develop some sampling techniques to train models to be more resilient to this, but find this involves its own tradeoffs between large-data and small-data languages as well. In many ways, the complexity of the task of large-scale machine translation, seems to hide subtle difficulties: &ldquo;Performance degrades for all language pairs, especially the high and medium resource ones, as the number of tasks grows&rdquo;, they write.&nbsp;
Scale: To improve performance, the researchers test our three variants of the &lsquo;Transformer&rsquo; componen…"

---

### Import AI 156: The 7,500 images that break image recognition systems; open source software for deleting objects from videos; and what it takes to do multilingual translation

Want 7,500 images designed to trick your object recognition system? Check out the &lsquo;Natural Adversarial Examples&rsquo; dataset:&hellip;Can your AI system deal with these naturally occurring optical illusions?&hellip;Have you ever been fiddling in the kitchen and dropped an orange-colored ceramic knife into a pile of orange peels and temporarily lost it? I have! These kinds of visual puzzles can be confusing for humans, and are even more tricky for machines to deal with. Therefore, researchers with the University of Berkeley, the University of Washington and the University of Chicago have developed and released a dataset full of these &lsquo;natural adversarial examples&rsquo;, which should help researchers test the robustness of AI systems and develop more powerful ones.&nbsp;
Imagenet-A: You can get the data as an ImageNet classifier test called ImageNet-A, which consists of around 7,500 images designed to confuse and frustrate modern image recognition systems.
How hard are &lsquo;natural adversarial examples&rsquo;? Extremely hard! The researchers tested out DenseNet-121 and ResNeXt-50 models on the dataset and show that both obtain an accuracy rate of less than 3% on ImageNet-A (compared to accuracies of 97%+ on standard ImageNet). Things don&rsquo;t improve much when they try to train their AI systems with techniques designed to increase robustness of classifiers, finding that using things like adversarial training, styleized imagenet augmentation, uncertainty metrics, and other approaches don&rsquo;t work particularly well.&nbsp;
Why this matters: Being able to measure all the ways in which AI systems fail is a superpower, because such measurements can highlight the ways existing systems break and point researchers towards problems that can be worked on. I hope we&rsquo;ll see more competitions that use datasets like this to test how resilient algorithms are to confounding examples.&nbsp;&nbsp;&nbsp;Read more: Natural Adversarial Examples (Arxiv).&nbsp;&nbsp;&nbsp;Get the code and the &lsquo;IMAGENET-A&rsquo; dataset here (Natural Adversarial Examples GitHub).&nbsp;
####################################################
Computer, delete! Open source software for editing videos:&hellip;AI is making video-editing much cheaper and more effective&hellip;Ever wanted to pick a person or an animal or other object in a video and make it disappear? I&rsquo;m sure the thought has struck some of you sometimes. Now, open source AI projects let you do just this: Video Object Removal is a new GitHub project that does what it says. The technology lets you draw a bounding box around an object in a video, and then the AI system will try to remove the person and inpaint the scene behind them. The software is based on two distinct technologies: Deep Video Inpainting, and Fast Online Object Tracking and Segmentation: A Unifying Approach.&nbsp;
Why this matters: Media is going to change radically as a consequence of the proliferation of AI tools like this &ndash; get ready for a world where images and video are&nbsp; so easy to manipulate that they become just another paintbrush, and be prepared to disbelieve everything you see online.&nbsp;&nbsp;&nbsp;Get the code from the GitHub page here (GitHub).&nbsp;
####################################################
Breaking drones to let others make smarter drones:&hellip;&rsquo;ALFA&rdquo; datasets gives researchers flight data for when things go wrong&hellip;Researchers with the Robotics Institute at Carnegie Mellon University have released ALFA, a dataset containing flight data and telemetry from a model plane, including data when the plane breaks. ALFA will make it easier for people to assess how well fault-spotting and fault-remediation algorithms work when exposed to real world failures.&nbsp;
ALFA consists of data for 47 autonomous flights with scenarios for eight different types of faults, including engine, rudder, and elevator errors. The data represents 66 minutes of normal flight and 13 minutes of post-fault flight time taking place over a mixture of fields and woodland near Pittsburgh, and there&rsquo;s also a larger unprocessed dataset representing &ldquo;several hours of raw autonomous, autopilot-assisted, and manual flight data with tens of different faults scenarios&rdquo;.&nbsp;
Hardware: To collect the dataset, the researchers used a modified Carbon Z T-28 model plane, equipped with an onboard Nvidia Jetson TX2 computer, and running &lsquo;Pixhawk&rsquo; autopilot software modified so that the researchers can remotely break the plan, generating the failure data.&nbsp;
Why this matters: Science tends to spend more time and resources inventing things and making forward progress on problems, rather than breaking things and casting a skeptical eye on recent events (mostly); datasets like ALFA make it easier for people to study failures, which will ultimately make it easier to develop more robust systems.&nbsp;&nbsp;&nbsp;Read more: ALFA: A Dataset for UAV Fault and Anomaly Detection (Arxiv).&nbsp;&nbsp;&nbsp;Get the ALFA data here (AIR Lab Failure and Anomaly (ALFA) Dataset website).
####################################################
How far are we from training a single AI system to translate between all languages?&hellip;Study involves 25 billion parallel sentences across 103 languages&hellip;How good are modern multilingual machine learning-based translation systems &ndash; that is, systems which can translate between a multitude of different languages, typically via using the same massive trained model? A new study from Google &ndash; which it says may be the largest ever conducted of its kind &ndash; analyzes the performance of these systems in the wild.&nbsp;
Data: For the study, the researchers evaluate &ldquo;a massive open-domain dataset containing over 25 billion parallel sentences in 103 languages&rdquo; using a large-scale machine translation system. They think that &ldquo;this is the largest multilingual NMT system to date, in terms of the amount of training data and number of languages considered at the same time&rdquo;. The datasets are distributed somewhat unevenly, though, reflecting the differing levels of documentation available for different languages. &ldquo;The number of parallel sentences per language in our corpus ranges from around tens of thousands to almost 2 billion&rdquo;, they write; there is a discrepancy of almost 5 orders of magnitude between the languages with the greatest and smallest amounts of data in the corpus. Google generated this data by crawling and extracting parallel sentences from the web, it writes.&nbsp;
Desirable features: An excellent multilingual translation system should have the following properties, according to the researchers:
Maximum throughput in terms of number of languages considered within a single model.&nbsp;
Positive transfer towards low-resource languages.&nbsp;
Minimum interference (negative transfer) for high-resource languages.&nbsp;
Models that perform well in &ldquo;realistic, open-domain settings&rdquo;.
When More Data Does Not Equal Better Data: One of the main findings of the study is the difficulty of training large models on such varied datasets, the researchers write. &ldquo;In a large multi-task setting, high resource tasks are starved for capacity while low resource tasks benefit significantly from transfer, and the extent of interference and transfer are strongly related.&rdquo; They develop some sampling techniques to train models to be more resilient to this, but find this involves its own tradeoffs between large-data and small-data languages as well. In many ways, the complexity of the task of large-scale machine translation, seems to hide subtle difficulties: &ldquo;Performance degrades for all language pairs, especially the high and medium resource ones, as the number of tasks grows&rdquo;, they write.&nbsp;
Scale: To improve performance, the researchers test our three variants of the &lsquo;Transformer&rsquo; componen…