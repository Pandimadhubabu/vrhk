---

layout: post
category: product
title: "Import AI 109: Why solving jigsaw puzzles can lead to better video recognition, learning to spy on people in simulation and transferring to reality, why robots are more insecure than you might think"
date: 2018-08-27 18:06:41
link: https://vrhk.co/2PcvhOk
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Fooling object recognition systems by adding more objects:&hellip;Some AI exploits don&rsquo;t have to be that fancy to be effective&hellip;How do object recognition systems work, and what throws them off? That&rsquo;s a hard question to answer because most AI researchers can&rsquo;t provide a good explanation for how all the different aspects of a system interact to make predictions. Now, researchers with York University and the University of Toronto have shown how to confound commonly deployed object detection systems by adding more objects to a picture in unusual places. Their approach doesn&rsquo;t rely on anything as subtle as an adversarial example &ndash; which involves subtly perturbing the pixels of an image to cause a mis-classification &ndash; and instead involves either adding new objects to a scene, or creating duplicates within a scene.&nbsp; &nbsp;Testing: The researchers test trained models from the public Tensorflow Object Detection API against images from the validation set of the 2017 version of MS-COCO. &nbsp;&nbsp;Results: The tests show that most commonly deployed object detection systems fail when objects are moved to different parts of an image (suggesting that the object classifier is conditioning heavily on the visual context surrounding a given object) or overlap with one another (suggesting that these systems have trouble segmenting objects, especially similar ones). They also show that the manipulation or addition of an object to a scene can lead to other negative effects elsewhere in the image, for instance, objects near &ndash; but not overlapping &ndash; the object can &ldquo;switch identity, bounding box, or disappear altogether.&rdquo;&nbsp; Terror in a quote: I admire the researchers for the clinical tone they adopt when describing the surreal scenes they have concocted to stress the object recognition system, for instance, this description of some results successfully confusing a system: &ldquo;The second row shows the result of adding a keyboard at a certain location. The keyboard is detected with high confidence, though now one of the hot-dogs, partially occluded, is detected as a sandwich and a doughnut.&rdquo; &nbsp;&nbsp;Google flaws: The researchers gather a small amount of qualitative data by uploading a couple of images to the Google Vision API website, in which &ldquo;no object was detected&rdquo;.&nbsp; Non-local effects: One of the more troubling discoveries relates to non-local effects. In one test on Google&rsquo;s OCR capabilities they show that: &ldquo;A keyboard placed in two different locations in an image causes a different interpretation of the text in the sign on the right. The output for the top image is &ldquo;dog bi&rdquo; and for the bottom it is &ldquo;La Cop&rdquo;&rdquo;. &nbsp;&nbsp;Why it matters: Experiments like this demonstrate the brittle and sometimes rather stupid ways in which today&rsquo;s supervised learning deep neural net-based systems can fail. The more worrying insights from this are the appearance of such dramatic non-local effects, suggesting that it&rsquo;s possible to confuse classifiers with visual elements that a human would not find disruptive.Read more: The Elephant in the Room (Arxiv).
$! AI Measurement Job: !$ The AI Index, a project to measure and assess the progress and impact of AI, is hiring for a program manager. You&rsquo;ll work with the steering committee, which today includes myself and Erik Brynjolfsson, Ray Perrault, Yoav Shoham, James Manyika &nbsp;and others (more on that subject soon!). It&rsquo;s a good role for someone interested in measuring AI progress on both technical and societal metrics and suits someone who enjoys disentangling hype from empirically verifiable reality. I spend a few hours a week working on the index (more as we finish the 2017 report!) and can answer any questions about the role:  &nbsp;&nbsp;AI Index program manager job posting here.  &nbsp;&nbsp;More about the AI Index here.
Better video classification by solving jigsaw puzzles:&hellip;Hollywood squares, AI edition&hellip;Jigsaw puzzles could be a useful way to familiarize a network with some data and give it a curriculum to train over &ndash; that&rsquo;s the implication of new research from Georgia Tech and Carnegie Mellon University which shows how to improve video recognition performance by, during training, slicing videos in a test set up into individual jigsaw pieces then tracing a neural network to predict how to piece them back together. This process involves the network learning to jointly solve two tasks: correctly piecing together the scrambled bits of each video frame, and learning to join the frames together in the appropriate order through time. &ldquo;Our goal is to create a task that not only forces a network to learn part-based appearance of complex activities but also learn how those parts change over time,&rdquo; they write.&nbsp; Slice and dice: The researchers cut up their videos by dividing &nbsp;each video frame into 2 x 2 grid of patches, then they stitch three of these frames together into tuples. &nbsp;&ldquo;There are 12! (479001600) ways to shuffle these patches&rdquo; in both space and time, they note. They implement a way to intelligently winnow down this large combinatorial space into selections geared towards helping the network learn. &nbsp;&nbsp;Testing: The researchers believe that training networks to correctly unscramble these video snippets in terms of both visual appearance and temporal placement will give them a greater raw capability to classify other, unseen videos. To test this, they train their video jigsaw network on the UCF101 (13,320 videos across 101 action categories) and Kinetics (around 400 categories with 400+ videos each) datasets, then they evaluate it on the UCF101 and HMDB51 (around 7,000 videos across 51 action categories). They train their systems with a curriculum approach, where they start off having to learn how to unscramble a few pieces at a time, then increase this figure through training, forcing it to learn to solve harder and harder tasks.&nbsp; Transfer learning: The researchers note that systems pre-trained with the larger Kinetics dataset generalize better than ones trained on the smaller UCF101 one and they test this hypothesis by training the UCF101 in a different way designed to minimize over-fitting, but discover the same phenomenon. &nbsp;&nbsp;Results: The researchers find that when they finetune their network on the UCF101 and HMDB51 datasets are pre-training on Kinetics they&rsquo;re able to obtain state-of-the-art results when compared to other unsupervised learning techniques, though obtain less accuracy than supervised learning approaches. They also obtain close-to SOTA accuracy on classification on the PASCAL VOC 2007 dataset.&nbsp; Why it matters: Approaches like this demonstrate how researchers can use the combinatorial power made available by cheap computational resources to mix-and-match datasets, letting them create natural curricula that can lead to better unsupervised learning approaches. One way to view research like this is it is increasing the value of existing image and video data by making such data potentially more useful. &nbsp;&nbsp;Read more: Video Jigsaw: Unsupervised Learning of Spatiotemporal Context for Video Action Recognition (Arxiv).
Learning to surveil a person in simulation, then transferring to reality:&hellip;sim2real, but for surveillance&hellip;Researchers with Tencent AI Lab and Peking University have shown how to use virtual environments to &ldquo;conveniently simulate active tracking, saving the expensive human labeling or real-world trial-and-error&rdquo;. This is part of a broader push by labs to use simulators to generate large amounts of synthetic data which they train their system on, substituting the compute used to run the simulator for the resources that would have otherwise been expended on gathering data from the real world. The researchers use two …"

---

### Import AI 109: Why solving jigsaw puzzles can lead to better video recognition, learning to spy on people in simulation and transferring to reality, why robots are more insecure than you might think

Fooling object recognition systems by adding more objects:&hellip;Some AI exploits don&rsquo;t have to be that fancy to be effective&hellip;How do object recognition systems work, and what throws them off? That&rsquo;s a hard question to answer because most AI researchers can&rsquo;t provide a good explanation for how all the different aspects of a system interact to make predictions. Now, researchers with York University and the University of Toronto have shown how to confound commonly deployed object detection systems by adding more objects to a picture in unusual places. Their approach doesn&rsquo;t rely on anything as subtle as an adversarial example &ndash; which involves subtly perturbing the pixels of an image to cause a mis-classification &ndash; and instead involves either adding new objects to a scene, or creating duplicates within a scene.&nbsp; &nbsp;Testing: The researchers test trained models from the public Tensorflow Object Detection API against images from the validation set of the 2017 version of MS-COCO. &nbsp;&nbsp;Results: The tests show that most commonly deployed object detection systems fail when objects are moved to different parts of an image (suggesting that the object classifier is conditioning heavily on the visual context surrounding a given object) or overlap with one another (suggesting that these systems have trouble segmenting objects, especially similar ones). They also show that the manipulation or addition of an object to a scene can lead to other negative effects elsewhere in the image, for instance, objects near &ndash; but not overlapping &ndash; the object can &ldquo;switch identity, bounding box, or disappear altogether.&rdquo;&nbsp; Terror in a quote: I admire the researchers for the clinical tone they adopt when describing the surreal scenes they have concocted to stress the object recognition system, for instance, this description of some results successfully confusing a system: &ldquo;The second row shows the result of adding a keyboard at a certain location. The keyboard is detected with high confidence, though now one of the hot-dogs, partially occluded, is detected as a sandwich and a doughnut.&rdquo; &nbsp;&nbsp;Google flaws: The researchers gather a small amount of qualitative data by uploading a couple of images to the Google Vision API website, in which &ldquo;no object was detected&rdquo;.&nbsp; Non-local effects: One of the more troubling discoveries relates to non-local effects. In one test on Google&rsquo;s OCR capabilities they show that: &ldquo;A keyboard placed in two different locations in an image causes a different interpretation of the text in the sign on the right. The output for the top image is &ldquo;dog bi&rdquo; and for the bottom it is &ldquo;La Cop&rdquo;&rdquo;. &nbsp;&nbsp;Why it matters: Experiments like this demonstrate the brittle and sometimes rather stupid ways in which today&rsquo;s supervised learning deep neural net-based systems can fail. The more worrying insights from this are the appearance of such dramatic non-local effects, suggesting that it&rsquo;s possible to confuse classifiers with visual elements that a human would not find disruptive.Read more: The Elephant in the Room (Arxiv).
$! AI Measurement Job: !$ The AI Index, a project to measure and assess the progress and impact of AI, is hiring for a program manager. You&rsquo;ll work with the steering committee, which today includes myself and Erik Brynjolfsson, Ray Perrault, Yoav Shoham, James Manyika &nbsp;and others (more on that subject soon!). It&rsquo;s a good role for someone interested in measuring AI progress on both technical and societal metrics and suits someone who enjoys disentangling hype from empirically verifiable reality. I spend a few hours a week working on the index (more as we finish the 2017 report!) and can answer any questions about the role:  &nbsp;&nbsp;AI Index program manager job posting here.  &nbsp;&nbsp;More about the AI Index here.
Better video classification by solving jigsaw puzzles:&hellip;Hollywood squares, AI edition&hellip;Jigsaw puzzles could be a useful way to familiarize a network with some data and give it a curriculum to train over &ndash; that&rsquo;s the implication of new research from Georgia Tech and Carnegie Mellon University which shows how to improve video recognition performance by, during training, slicing videos in a test set up into individual jigsaw pieces then tracing a neural network to predict how to piece them back together. This process involves the network learning to jointly solve two tasks: correctly piecing together the scrambled bits of each video frame, and learning to join the frames together in the appropriate order through time. &ldquo;Our goal is to create a task that not only forces a network to learn part-based appearance of complex activities but also learn how those parts change over time,&rdquo; they write.&nbsp; Slice and dice: The researchers cut up their videos by dividing &nbsp;each video frame into 2 x 2 grid of patches, then they stitch three of these frames together into tuples. &nbsp;&ldquo;There are 12! (479001600) ways to shuffle these patches&rdquo; in both space and time, they note. They implement a way to intelligently winnow down this large combinatorial space into selections geared towards helping the network learn. &nbsp;&nbsp;Testing: The researchers believe that training networks to correctly unscramble these video snippets in terms of both visual appearance and temporal placement will give them a greater raw capability to classify other, unseen videos. To test this, they train their video jigsaw network on the UCF101 (13,320 videos across 101 action categories) and Kinetics (around 400 categories with 400+ videos each) datasets, then they evaluate it on the UCF101 and HMDB51 (around 7,000 videos across 51 action categories). They train their systems with a curriculum approach, where they start off having to learn how to unscramble a few pieces at a time, then increase this figure through training, forcing it to learn to solve harder and harder tasks.&nbsp; Transfer learning: The researchers note that systems pre-trained with the larger Kinetics dataset generalize better than ones trained on the smaller UCF101 one and they test this hypothesis by training the UCF101 in a different way designed to minimize over-fitting, but discover the same phenomenon. &nbsp;&nbsp;Results: The researchers find that when they finetune their network on the UCF101 and HMDB51 datasets are pre-training on Kinetics they&rsquo;re able to obtain state-of-the-art results when compared to other unsupervised learning techniques, though obtain less accuracy than supervised learning approaches. They also obtain close-to SOTA accuracy on classification on the PASCAL VOC 2007 dataset.&nbsp; Why it matters: Approaches like this demonstrate how researchers can use the combinatorial power made available by cheap computational resources to mix-and-match datasets, letting them create natural curricula that can lead to better unsupervised learning approaches. One way to view research like this is it is increasing the value of existing image and video data by making such data potentially more useful. &nbsp;&nbsp;Read more: Video Jigsaw: Unsupervised Learning of Spatiotemporal Context for Video Action Recognition (Arxiv).
Learning to surveil a person in simulation, then transferring to reality:&hellip;sim2real, but for surveillance&hellip;Researchers with Tencent AI Lab and Peking University have shown how to use virtual environments to &ldquo;conveniently simulate active tracking, saving the expensive human labeling or real-world trial-and-error&rdquo;. This is part of a broader push by labs to use simulators to generate large amounts of synthetic data which they train their system on, substituting the compute used to run the simulator for the resources that would have otherwise been expended on gathering data from the real world. The researchers use two …