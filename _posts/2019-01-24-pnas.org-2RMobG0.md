---

layout: post
category: threads
title: "News Feature: What are the limits of deep learning?"
date: 2019-01-24 00:21:57
link: https://vrhk.co/2RMobG0
image: https://www.pnas.org/sites/default/files/highwire/pnas/116/4.cover-source.jpg
domain: pnas.org
author: "PNAS"
icon: https://www.pnas.org/sites/default/files/images/favicon.ico
excerpt: "The much-ballyhooed artificial intelligence approach boasts impressive feats but still falls short of human brainpower. Researchers are determined to figure out what’s missing. There’s no mistaking the image: It’s a banana—a big, ripe, bright-yellow banana. Yet the artificial intelligence (AI) identifies it as a toaster, even though it was trained with the same powerful and oft-publicized deep-learning techniques that have produced a white-hot revolution in driverless cars, speech understanding, and a multitude of other AI applications. That means the AI was shown several thousand photos of bananas, slugs, snails, and similar-looking objects, like so many flash cards, and then drilled on the answers until it had the classification down cold. And yet this advanced system was quite easily confused—all it took was a little day-glow sticker, digitally pasted in one corner of the image. Apparent shortcomings in deep-learning approaches have raised concerns among researchers and the general public as technologies such as driverless cars, which use deep-learning techniques to navigate, get involved in well-publicized mishaps. Image credit: <http://Shutterstock.com/MONOPOLY919|Shutterstock.com/MONOPOLY919>. This example of what deep-learning researchers call an “adversarial attack,” discovered by the Google Brain team in Mountain View, CA (1), highlights just how far AI still has to go before it remotely approaches human capabilities. “I initially thought that adversarial examples were just an annoyance,” says Geoffrey Hinton, a computer scientist at the University of Toronto and one of the pioneers of deep learning. “But I now think they're probably quite profound. They tell us that we're doing something wrong.” That’s a widely shared sentiment among AI practitioners, any of whom can easily rattle off a long list of deep learning’s drawbacks. In addition to its vulnerability to spoofing, for example, there is its gross inefficiency. “For a child to learn to recognize a cow,” says Hinton, “it's not like their …"

---

### News Feature: What are the limits of deep learning?

The much-ballyhooed artificial intelligence approach boasts impressive feats but still falls short of human brainpower. Researchers are determined to figure out what’s missing. There’s no mistaking the image: It’s a banana—a big, ripe, bright-yellow banana. Yet the artificial intelligence (AI) identifies it as a toaster, even though it was trained with the same powerful and oft-publicized deep-learning techniques that have produced a white-hot revolution in driverless cars, speech understanding, and a multitude of other AI applications. That means the AI was shown several thousand photos of bananas, slugs, snails, and similar-looking objects, like so many flash cards, and then drilled on the answers until it had the classification down cold. And yet this advanced system was quite easily confused—all it took was a little day-glow sticker, digitally pasted in one corner of the image. Apparent shortcomings in deep-learning approaches have raised concerns among researchers and the general public as technologies such as driverless cars, which use deep-learning techniques to navigate, get involved in well-publicized mishaps. Image credit: <http://Shutterstock.com/MONOPOLY919|Shutterstock.com/MONOPOLY919>. This example of what deep-learning researchers call an “adversarial attack,” discovered by the Google Brain team in Mountain View, CA (1), highlights just how far AI still has to go before it remotely approaches human capabilities. “I initially thought that adversarial examples were just an annoyance,” says Geoffrey Hinton, a computer scientist at the University of Toronto and one of the pioneers of deep learning. “But I now think they're probably quite profound. They tell us that we're doing something wrong.” That’s a widely shared sentiment among AI practitioners, any of whom can easily rattle off a long list of deep learning’s drawbacks. In addition to its vulnerability to spoofing, for example, there is its gross inefficiency. “For a child to learn to recognize a cow,” says Hinton, “it's not like their …