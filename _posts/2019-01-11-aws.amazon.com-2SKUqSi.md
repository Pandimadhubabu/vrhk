---

layout: post
category: engineering
title: "Ensure consistency in data processing code between training and inference in Amazon SageMaker"
date: 2019-01-11 23:22:00
link: https://vrhk.co/2SKUqSi
image: https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2018/12/21/SageMakerInferencePipelines1.png
domain: aws.amazon.com
author: "Amazon Web Services"
icon: http://a0.awsstatic.com/main/images/site/touch-icon-iphone-114-smile.png
excerpt: "In this blog post, we’ll show you how to deploy an inference pipeline consisting of pre-processing using SparkML, inferences using XGBoost, and post-processing using SparkML. For this particular example, we are using the Car Evaluation Data Set from UCI’s Machine Learning Repository and training an XGBoost model to predict the condition of a car (i.e. unacceptable, acceptable, good, or very good)."

---

### Ensure consistency in data processing code between training and inference in Amazon SageMaker | Amazon Web Services

In this blog post, we’ll show you how to deploy an inference pipeline consisting of pre-processing using SparkML, inferences using XGBoost, and post-processing using SparkML. For this particular example, we are using the Car Evaluation Data Set from UCI’s Machine Learning Repository and training an XGBoost model to predict the condition of a car (i.e. unacceptable, acceptable, good, or very good).