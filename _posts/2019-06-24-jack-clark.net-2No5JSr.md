---

layout: post
category: product
title: "Import AI 152: Robots learn to plug USB sticks in; Oxford gets $$$ for AI research; and spotting landslides with deep learning"
date: 2019-06-24 16:16:27
link: https://vrhk.co/2No5JSr
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Translating African languages is going to be harder than you think:&hellip;Massive variety of languages? Check. Small or poorly built datasets? Check. Few resources assigned to the problem? Also check!&hellip;African AI researchers have sought to demonstrate the value of translating African languages into English and vice versa, while highlighting the difficulty of this essential task. &ldquo;Machine translation of African languages would not only enable the preservation of such languages, but also empower African citizens to contribute to and learn from global scientific, social, and educational conversations, which are currently predominantly English-based,&rdquo; they write. &ldquo;We train models to perform machine translation of English to Afrikaans, isiZulu, Northern Sotho (N.Sotho), Setswana and Xitsonga&rdquo;.
Small datasets: One of the most striking things about the datasets they gather is how small they are, ranging in size from as little as 26,728 sentences (isiZulu) to 123,868 sentences (Setswana). To get a sense of scale, the European Parliament Dataset (one of the gold standard datasets for translation) has millions of sentences for many of the most common Europen languages (French, German, etc).
Training translation models: They train a couple of baseline translation systems on this dataset; one uses a Convolutional Sequence-to-Sequence (ConvS2S) model and the other uses a Tensor2Tensor implementation of a Transformer. Transformer-based systems obtain higher scores than ConvS2S in all cases, with the performance difference reaching as much as a ten point absolute improvement on BLEU scores.
Why this matters: Trained models for translation are going to become akin to the construction of international telephony infrastructure &ndash; different entities will invest different resources to create systems to let them communicate across borders, except rather than seeking to traverse the physical world, they&rsquo;re investing to traverse a linguistic (and to some extent) cultural distance. Therefore, the quality of these infrastructures will have a significant influence on how connected or disconnected different languages and their associated cultures are from the global community. As this paper shows, some languages are going to have difficulties others don&rsquo;t, and we should consider this context as we think about how to equitably distribute the benefits of AI systems.&nbsp;&nbsp;Read more: A Focus on Neural Machine Translation for African Languages (Arxiv). &nbsp;&nbsp;Get the source code and data from the project GitHub page here (GitHub).
#####################################################
Spotting landslides with deep learning:&hellip;What happens when we train a sensor to look at the entire world&hellip;Researchers with the University of Sannio in Italy and MIT in the USA have prototyped a system for detecting landslides in satellite imagery, foreshadowing a world where anyone can train a basic predictive classifier against satellite data.
Dataset: They use the NASA Open Data Global Landslide Catalog to find landslides, then cross-reference this against data from the &lsquo;Sentinel-2&rsquo; dataset. They then compose a (somewhat small) dataset of around 20 different landslide incidents.
The technique: They use a simple 8-layer convolutional neural network, trained against the corpus to try to predict the presence of a landslide in a satellite image. Their system is able to correctly predict the presence of a landscale about 60% of the time &ndash; this poor performance is mostly due to the (currently) limited size of the dataset; it&rsquo;s worth remembering that satellite datasets are getting larger over time along with the proliferation of various private sector mini- and micro-satellite startups.
Why this matters: As more and more digital satellite data becomes available, analysis like this will become commonplace. I think papers like this give us a sense of what that future research will look like &ndash; prepare for a world where millions of people are training one-off basic classifiers against vast streams of continuously updated Earth observation data.&nbsp; Read more: Landslide Geohazard Assessment with Convolutional Neural Networks Using Sentinel-2 Imagery Data (Arxiv).
#####################################################
Facebook thinks it needs a Replica of reality for its research:&hellip;High-fidelity &lsquo;Replica&rsquo; scene simulator designed for sim2real AI experiments, VR, and more&hellip;Researchers with Facebook, Georgia Institute of Technology, and Simon Fraser University have built Replica, a photorealistic dataset of various complex indoor scenes that can be used to train AI systems in.
The dataset: Replica consists of 18 photo-realistic 3D indoor scene reconstructions &ndash; they&rsquo;re not kidding about the realism and invite readers to take a &ldquo;Replica Turing Test&rdquo; to judge for themselves; I did and it&rsquo;s extremely hard to tell the difference between Replica-simulated images from actual photos. Each of the scenes includes RGB information, geometric information, and object segmentation information. Replica also uses HDR textures and reflectors to further increase the realism of a scene.
Replica + AI Habitat: Replica has been designed to plug-in to the Facebook-developed &lsquo;AI habitat&rsquo; simulator (Import AI 141), which is an AI training platform that can support multiple simulators. Replica supports rendering outputs from the dataset at up to 10,000 frames per second &ndash; that speed is crucial if you&rsquo;re trying to train sample inefficient RL systems against this.
Why this matters: How much does reality matter? That&rsquo;s a question that AI researchers are grappling with, and there are two parallel lines of research emerging: in one, researchers try to develop high-fidelity systems like Replica then train AI systems against them and transfer these systems to reality. In the other, researchers are using techniques like domain randomization to automatically augment lower quality datasets, hoping to get generalization through training against a large quantity of data. Systems like Replica will help to generate more evidence about the tradeoffs and benefits of these approaches.&nbsp;&nbsp;Read more: The Replicate Dataset: A Digital Replicate of Indoor Spaces (Arxiv). &nbsp;&nbsp;Get the code for the dataset here (Facebook GitHub).
#####################################################
Robots take on finicky factory work: cable insertion!&hellip;First signs of superhuman performance on a real-world factory task&hellip;The general task these researchers are trying to solve is &ldquo;how can we enable robots to autonomously perform complex tasks without significant engineering effort to design perception and reward systems&rdquo;.
What can be so difficult about connecting two things? As anyone who has built their own PC knows, fiddling around with connectors and ports can be challenging even for dexterous humans equipped with a visual classifier that has been trained for a couple of million years and fine-tuned against the experience of a lifetime. For robots, the challenges here are twofold: ports and connectors need to be lined up with great precision, and two, during insertion there are various unpredictable friction forces present which can confound a machine.
Three connectors, three tests: They test their robots against three tasks of increasing difficulty: inserting a USB adapter into a USB port; aligning a multi-pin D-Sub adapter and port, requiring more robustness to friction; and aligning and connecting a &lsquo;Model-E&rsquo; adapter which has &ldquo;several edges and grooves to align&rdquo; and also requires significant force.
Two solutions to one problem: For this work, they try to solve the task in two different ways: supervision from vision, where the robot is provided with a &lsquo;goal state&rsquo; image at 32X32 resolution; and learning from a sparse re…"

---

### Import AI 152: Robots learn to plug USB sticks in; Oxford gets $$$ for AI research; and spotting landslides with deep learning

Translating African languages is going to be harder than you think:&hellip;Massive variety of languages? Check. Small or poorly built datasets? Check. Few resources assigned to the problem? Also check!&hellip;African AI researchers have sought to demonstrate the value of translating African languages into English and vice versa, while highlighting the difficulty of this essential task. &ldquo;Machine translation of African languages would not only enable the preservation of such languages, but also empower African citizens to contribute to and learn from global scientific, social, and educational conversations, which are currently predominantly English-based,&rdquo; they write. &ldquo;We train models to perform machine translation of English to Afrikaans, isiZulu, Northern Sotho (N.Sotho), Setswana and Xitsonga&rdquo;.
Small datasets: One of the most striking things about the datasets they gather is how small they are, ranging in size from as little as 26,728 sentences (isiZulu) to 123,868 sentences (Setswana). To get a sense of scale, the European Parliament Dataset (one of the gold standard datasets for translation) has millions of sentences for many of the most common Europen languages (French, German, etc).
Training translation models: They train a couple of baseline translation systems on this dataset; one uses a Convolutional Sequence-to-Sequence (ConvS2S) model and the other uses a Tensor2Tensor implementation of a Transformer. Transformer-based systems obtain higher scores than ConvS2S in all cases, with the performance difference reaching as much as a ten point absolute improvement on BLEU scores.
Why this matters: Trained models for translation are going to become akin to the construction of international telephony infrastructure &ndash; different entities will invest different resources to create systems to let them communicate across borders, except rather than seeking to traverse the physical world, they&rsquo;re investing to traverse a linguistic (and to some extent) cultural distance. Therefore, the quality of these infrastructures will have a significant influence on how connected or disconnected different languages and their associated cultures are from the global community. As this paper shows, some languages are going to have difficulties others don&rsquo;t, and we should consider this context as we think about how to equitably distribute the benefits of AI systems.&nbsp;&nbsp;Read more: A Focus on Neural Machine Translation for African Languages (Arxiv). &nbsp;&nbsp;Get the source code and data from the project GitHub page here (GitHub).
#####################################################
Spotting landslides with deep learning:&hellip;What happens when we train a sensor to look at the entire world&hellip;Researchers with the University of Sannio in Italy and MIT in the USA have prototyped a system for detecting landslides in satellite imagery, foreshadowing a world where anyone can train a basic predictive classifier against satellite data.
Dataset: They use the NASA Open Data Global Landslide Catalog to find landslides, then cross-reference this against data from the &lsquo;Sentinel-2&rsquo; dataset. They then compose a (somewhat small) dataset of around 20 different landslide incidents.
The technique: They use a simple 8-layer convolutional neural network, trained against the corpus to try to predict the presence of a landslide in a satellite image. Their system is able to correctly predict the presence of a landscale about 60% of the time &ndash; this poor performance is mostly due to the (currently) limited size of the dataset; it&rsquo;s worth remembering that satellite datasets are getting larger over time along with the proliferation of various private sector mini- and micro-satellite startups.
Why this matters: As more and more digital satellite data becomes available, analysis like this will become commonplace. I think papers like this give us a sense of what that future research will look like &ndash; prepare for a world where millions of people are training one-off basic classifiers against vast streams of continuously updated Earth observation data.&nbsp; Read more: Landslide Geohazard Assessment with Convolutional Neural Networks Using Sentinel-2 Imagery Data (Arxiv).
#####################################################
Facebook thinks it needs a Replica of reality for its research:&hellip;High-fidelity &lsquo;Replica&rsquo; scene simulator designed for sim2real AI experiments, VR, and more&hellip;Researchers with Facebook, Georgia Institute of Technology, and Simon Fraser University have built Replica, a photorealistic dataset of various complex indoor scenes that can be used to train AI systems in.
The dataset: Replica consists of 18 photo-realistic 3D indoor scene reconstructions &ndash; they&rsquo;re not kidding about the realism and invite readers to take a &ldquo;Replica Turing Test&rdquo; to judge for themselves; I did and it&rsquo;s extremely hard to tell the difference between Replica-simulated images from actual photos. Each of the scenes includes RGB information, geometric information, and object segmentation information. Replica also uses HDR textures and reflectors to further increase the realism of a scene.
Replica + AI Habitat: Replica has been designed to plug-in to the Facebook-developed &lsquo;AI habitat&rsquo; simulator (Import AI 141), which is an AI training platform that can support multiple simulators. Replica supports rendering outputs from the dataset at up to 10,000 frames per second &ndash; that speed is crucial if you&rsquo;re trying to train sample inefficient RL systems against this.
Why this matters: How much does reality matter? That&rsquo;s a question that AI researchers are grappling with, and there are two parallel lines of research emerging: in one, researchers try to develop high-fidelity systems like Replica then train AI systems against them and transfer these systems to reality. In the other, researchers are using techniques like domain randomization to automatically augment lower quality datasets, hoping to get generalization through training against a large quantity of data. Systems like Replica will help to generate more evidence about the tradeoffs and benefits of these approaches.&nbsp;&nbsp;Read more: The Replicate Dataset: A Digital Replicate of Indoor Spaces (Arxiv). &nbsp;&nbsp;Get the code for the dataset here (Facebook GitHub).
#####################################################
Robots take on finicky factory work: cable insertion!&hellip;First signs of superhuman performance on a real-world factory task&hellip;The general task these researchers are trying to solve is &ldquo;how can we enable robots to autonomously perform complex tasks without significant engineering effort to design perception and reward systems&rdquo;.
What can be so difficult about connecting two things? As anyone who has built their own PC knows, fiddling around with connectors and ports can be challenging even for dexterous humans equipped with a visual classifier that has been trained for a couple of million years and fine-tuned against the experience of a lifetime. For robots, the challenges here are twofold: ports and connectors need to be lined up with great precision, and two, during insertion there are various unpredictable friction forces present which can confound a machine.
Three connectors, three tests: They test their robots against three tasks of increasing difficulty: inserting a USB adapter into a USB port; aligning a multi-pin D-Sub adapter and port, requiring more robustness to friction; and aligning and connecting a &lsquo;Model-E&rsquo; adapter which has &ldquo;several edges and grooves to align&rdquo; and also requires significant force.
Two solutions to one problem: For this work, they try to solve the task in two different ways: supervision from vision, where the robot is provided with a &lsquo;goal state&rsquo; image at 32X32 resolution; and learning from a sparse re…