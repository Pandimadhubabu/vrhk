---

layout: post
category: research
title: "Controllable Fairness in Machine Learning"
date: 2019-05-30 04:10:44
link: https://stanford.io/2WbJUsY
image: http://ai.stanford.edu/blog/assets/img/posts/2019-05-27-controllable-fairness/fair.png
domain: ai.stanford.edu
author: "SAIL Blog"
icon: http://ai.stanford.edu/blog/assets/img/favicon-32x32.png
excerpt: "TLDR: How do we finely control the fairness of machine learning systems? In our AISTATS 2019 paper, we introduce a theoretically grounded method for learning controllable fair representations. Using our method, a party who is concerned with fairness (like a data collector, community organizer, or regulatory body) can convert data to representations with controllable limits on unfairness, then release only the representations. This controls how much downstream machine learning models can discriminate."

---

### Controllable Fairness in Machine Learning

TLDR: How do we finely control the fairness of machine learning systems? In our AISTATS 2019 paper, we introduce a theoretically grounded method for learning controllable fair representations. Using our method, a party who is concerned with fairness (like a data collector, community organizer, or regulatory body) can convert data to representations with controllable limits on unfairness, then release only the representations. This controls how much downstream machine learning models can discriminate.