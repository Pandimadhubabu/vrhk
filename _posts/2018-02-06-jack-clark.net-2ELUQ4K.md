---

layout: post
category: product
title: "Import AI: #80: Facebook accidentally releases a surveillance-AI tool; why emojis are a good candidate for a universal deep learning language; and using deceptive games to explore the stupidity of AI algorithms"
date: 2018-02-06 17:42:06
link: https://vrhk.co/2ELUQ4K
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s0.wp.com/i/webclip.png
excerpt: "Researchers try to capture the web&rsquo;s now-fading Flash bounty for RL research:&hellip;FlashRL represents another attempt to make the world&rsquo;s vast archive of flash games accessible to researchers, but the initial platform has drawbacks&hellip;Researchers with the University of Agder in Norway have released FlashRL, a research platform to help AI researchers mess around with software written in Flash, an outmoded interactive media format that defined much of the most popular games of the early era of the web. The platform has a similar philosophy to OpenAI Universe by trying to give researchers a vast suite of new environments to test and develop algorithms on.&nbsp;&nbsp;The dataset: FlashRL ships with &ldquo;several thousand game environments&rdquo; taken from around the web.&nbsp;&nbsp;How it works: FlashRL uses the Linux library XVFB to create a virtual frame-buffer that it can use for graphics rendering, which then executes flash files within players such as Gnash. FlashRL can access this via a VNC Client designed for this called pyVLC, which subsequently exposes an API to the developer.&nbsp;&nbsp;Testing: The researchers test FlashRL by training a neural network to play the game &lsquo;Multitask&rsquo; on it. B,ut in the absence of comparable baselines or benchmarks it&rsquo;s difficult to work out if FlashRL holds any drawbacks with regards to training relative to other systems &ndash; a nice thing to do might be to mount a well-known suite of games like the Atari Learning Environment within the system, then provide benchmarks for those games as well.&nbsp;&nbsp;Why it might matter: Given the current Cambrian explosion in testing systems it&rsquo;s likely that FlashRL&rsquo;s utility will ultimately be derived from how much interest it receives from the community. To gain interest it&rsquo;s likely the researchers will need to tweak the system so that it can run environments faster than 30 frames-per-second (many other RL frameworks allow FPS&rsquo;s of 1,000+), because the speed with which you can run an environment is directly correlated to the speed with which you can conduct research on the platform.&ndash; Read more: FlashRL: A Reinforcement Learning Platform for Flash Games (Arxiv).&ndash;&nbsp;Check out the GitHub repository&nbsp;
Cool job alert! Harvard/MIT Assembly Project Manager:&hellip;Want to work on difficult problems in the public interest? Like helping smart and ethical people build things that matter?&hellip;Harvard University&rsquo;s Berkman Klein Center (BKC) is looking for a project manager coordinator to help manage its Assembly Program, a joint initiative with the MIT Media Lab that brings together senior developers and other technologists for a semester to build things that grapple with topics in the public interest. Last year&rsquo;s assembly program was on cybersecurity and this year&rsquo;s is on issues relating to the ethics and governance of AI (and your humble author is currently enrolled in this very program!). Beyond the Assembly program, the project manager will work on other projects with Professor Jonathan Zittrain and his team.&nbsp; For a full description of the responsibilities, qualifications, and application instructions, please visit the Harvard Human Resources Project Manager Listing. 
Mongolian researchers tackle a deep learning meme problem:&hellip;Weird things happen when internet culture inspires AI research papers..Researchers with the National University of Mongolia have published a research paper in which they apply standard techniques (transfer learning via fine-tuning and transferring) to tackle an existing machine learning problem. The novelty is that they base their research on trying to tell the difference between pictures of puppies and muffins &ndash; a fun meme/joke on Twitter a few years ago that has subsequently become a kind of deep learning meme.&nbsp;&nbsp;Why it matters: The paper is mostly interesting because it signifies that a) the border between traditional academic problems and internet-spawned semi-ironic problems is growing more porous and, b) academics are tapping into internet meme culture to draw interest to their work.&ndash;&nbsp;&nbsp;Read more: Deep Learning Approach for Very Similar Object Recognition Applicationon Chihuahua and Muffin Problem (Arxiv).
Mapping the emoji landscape with deep learning:&hellip;Learning to understand a new domain of discourse with lots &amp; lots of data&hellip;Emojis have become a kind of shadow language used by people across the world to indicate sentiments. Emojis are also a good candidate for deep learning-based analysis because they consist of a relatively small number of distinct &lsquo;words&rsquo; with around ~1,000 emojis in popular use, compared to English where most documents display a working vocabulary of around ~100,000 words. This means it&rsquo;s easier to conduct research into mapping emojis to specific meanings in language and images with less data than with datasets consisting of traditional languages.&nbsp; &nbsp;Now, researchers are experimenting with one of the internet&rsquo;s best emojilanguageimages sources: the endless blathering mountain of content on Twitter. &ldquo;Emoji have some unique advantages for retrieval tasks. The limited nature of emoji (1000+ ideograms as opposed to 100,000+ words) allows for a greater level of certainty regarding the possible query space. Furthermore, emoji are not tied to any particular natural language, and most emoji are pan-cultural,&rdquo; write the researchers.&nbsp;&nbsp;The &lsquo;Twemoji&lsquo; dataset: To analyze emojis, the researchers scraped about 15 million emoji-containing tweets during the summer of 2016, then analyzed this &lsquo;Twemoji&rsquo; dataset as well as two derivatives: Twemoji-Balanced (a smaller dataset selected so that no emoji applies to more than 10 examples, chopping out some of the edge-of-the-bell-curve emojis; the crying smiling face Emoji appears in ~1.5 million of the tweets in the corpus, while 116 other emojis are only used a single time) and Twemoji-Images (roughly one million tweets that contain an image as well as emoji). They then apply deep learning techniques to this dataset to try to see if they can complete prediction and retrieval tasks using the emojis.&nbsp;&nbsp;Results: Researchers use a bidirectional LSTM to help them perform mappings between emojis and language; use a GoogleLeNet-image classification system to help them map the relationship between emojis and images; and use a combination of the two to understand the relationship between all three. They also learn to suggest different emojis according to the text or visual content of a given tweet. Most of the results should be treated as early baselines rather than landmark results in themselves with top-5 emoji-text prediction accuracies of around ~48.3% and lower accuracies of around 40.3% top-5 predictions for images-text-emojis.&nbsp;&nbsp;Why it matters: This paper is another good example of a new trend in deep learning: the technologies have become simple enough that researchers from outside the core AI research field are starting to pick up basic components like LSTMs and pre-trained image classifiers and are using them to re-contextualize existing domains, like understanding linguistics and retrieval tasks via emojis.&ndash;&nbsp;&nbsp;Read more: The New Modality: Emoji Challenges in Prediction, Anticipation, and Retrieval (Arxiv).
Facebook researchers train models to perform unprecedentedly-detailed analysis of the human body:&hellip;Research has significant military, surveillance implications (though not discussed in paper)&hellip;Facebook researchers have trained a state-of-the-art system named &lsquo;DensePose&rsquo; which can look at 2D photos or videos of people and automatically create high-definition 3D mesh models of the depicted people; an output with broad utility and impact across a number of domains. Their motivation to do this is techniques lik…"

---

### Import AI: #80: Facebook accidentally releases a surveillance-AI tool; why emojis are a good candidate for a universal deep learning language; and using deceptive games to explore the stupidity of AI algorithms

Researchers try to capture the web&rsquo;s now-fading Flash bounty for RL research:&hellip;FlashRL represents another attempt to make the world&rsquo;s vast archive of flash games accessible to researchers, but the initial platform has drawbacks&hellip;Researchers with the University of Agder in Norway have released FlashRL, a research platform to help AI researchers mess around with software written in Flash, an outmoded interactive media format that defined much of the most popular games of the early era of the web. The platform has a similar philosophy to OpenAI Universe by trying to give researchers a vast suite of new environments to test and develop algorithms on.&nbsp;&nbsp;The dataset: FlashRL ships with &ldquo;several thousand game environments&rdquo; taken from around the web.&nbsp;&nbsp;How it works: FlashRL uses the Linux library XVFB to create a virtual frame-buffer that it can use for graphics rendering, which then executes flash files within players such as Gnash. FlashRL can access this via a VNC Client designed for this called pyVLC, which subsequently exposes an API to the developer.&nbsp;&nbsp;Testing: The researchers test FlashRL by training a neural network to play the game &lsquo;Multitask&rsquo; on it. B,ut in the absence of comparable baselines or benchmarks it&rsquo;s difficult to work out if FlashRL holds any drawbacks with regards to training relative to other systems &ndash; a nice thing to do might be to mount a well-known suite of games like the Atari Learning Environment within the system, then provide benchmarks for those games as well.&nbsp;&nbsp;Why it might matter: Given the current Cambrian explosion in testing systems it&rsquo;s likely that FlashRL&rsquo;s utility will ultimately be derived from how much interest it receives from the community. To gain interest it&rsquo;s likely the researchers will need to tweak the system so that it can run environments faster than 30 frames-per-second (many other RL frameworks allow FPS&rsquo;s of 1,000+), because the speed with which you can run an environment is directly correlated to the speed with which you can conduct research on the platform.&ndash; Read more: FlashRL: A Reinforcement Learning Platform for Flash Games (Arxiv).&ndash;&nbsp;Check out the GitHub repository&nbsp;
Cool job alert! Harvard/MIT Assembly Project Manager:&hellip;Want to work on difficult problems in the public interest? Like helping smart and ethical people build things that matter?&hellip;Harvard University&rsquo;s Berkman Klein Center (BKC) is looking for a project manager coordinator to help manage its Assembly Program, a joint initiative with the MIT Media Lab that brings together senior developers and other technologists for a semester to build things that grapple with topics in the public interest. Last year&rsquo;s assembly program was on cybersecurity and this year&rsquo;s is on issues relating to the ethics and governance of AI (and your humble author is currently enrolled in this very program!). Beyond the Assembly program, the project manager will work on other projects with Professor Jonathan Zittrain and his team.&nbsp; For a full description of the responsibilities, qualifications, and application instructions, please visit the Harvard Human Resources Project Manager Listing. 
Mongolian researchers tackle a deep learning meme problem:&hellip;Weird things happen when internet culture inspires AI research papers..Researchers with the National University of Mongolia have published a research paper in which they apply standard techniques (transfer learning via fine-tuning and transferring) to tackle an existing machine learning problem. The novelty is that they base their research on trying to tell the difference between pictures of puppies and muffins &ndash; a fun meme/joke on Twitter a few years ago that has subsequently become a kind of deep learning meme.&nbsp;&nbsp;Why it matters: The paper is mostly interesting because it signifies that a) the border between traditional academic problems and internet-spawned semi-ironic problems is growing more porous and, b) academics are tapping into internet meme culture to draw interest to their work.&ndash;&nbsp;&nbsp;Read more: Deep Learning Approach for Very Similar Object Recognition Applicationon Chihuahua and Muffin Problem (Arxiv).
Mapping the emoji landscape with deep learning:&hellip;Learning to understand a new domain of discourse with lots &amp; lots of data&hellip;Emojis have become a kind of shadow language used by people across the world to indicate sentiments. Emojis are also a good candidate for deep learning-based analysis because they consist of a relatively small number of distinct &lsquo;words&rsquo; with around ~1,000 emojis in popular use, compared to English where most documents display a working vocabulary of around ~100,000 words. This means it&rsquo;s easier to conduct research into mapping emojis to specific meanings in language and images with less data than with datasets consisting of traditional languages.&nbsp; &nbsp;Now, researchers are experimenting with one of the internet&rsquo;s best emojilanguageimages sources: the endless blathering mountain of content on Twitter. &ldquo;Emoji have some unique advantages for retrieval tasks. The limited nature of emoji (1000+ ideograms as opposed to 100,000+ words) allows for a greater level of certainty regarding the possible query space. Furthermore, emoji are not tied to any particular natural language, and most emoji are pan-cultural,&rdquo; write the researchers.&nbsp;&nbsp;The &lsquo;Twemoji&lsquo; dataset: To analyze emojis, the researchers scraped about 15 million emoji-containing tweets during the summer of 2016, then analyzed this &lsquo;Twemoji&rsquo; dataset as well as two derivatives: Twemoji-Balanced (a smaller dataset selected so that no emoji applies to more than 10 examples, chopping out some of the edge-of-the-bell-curve emojis; the crying smiling face Emoji appears in ~1.5 million of the tweets in the corpus, while 116 other emojis are only used a single time) and Twemoji-Images (roughly one million tweets that contain an image as well as emoji). They then apply deep learning techniques to this dataset to try to see if they can complete prediction and retrieval tasks using the emojis.&nbsp;&nbsp;Results: Researchers use a bidirectional LSTM to help them perform mappings between emojis and language; use a GoogleLeNet-image classification system to help them map the relationship between emojis and images; and use a combination of the two to understand the relationship between all three. They also learn to suggest different emojis according to the text or visual content of a given tweet. Most of the results should be treated as early baselines rather than landmark results in themselves with top-5 emoji-text prediction accuracies of around ~48.3% and lower accuracies of around 40.3% top-5 predictions for images-text-emojis.&nbsp;&nbsp;Why it matters: This paper is another good example of a new trend in deep learning: the technologies have become simple enough that researchers from outside the core AI research field are starting to pick up basic components like LSTMs and pre-trained image classifiers and are using them to re-contextualize existing domains, like understanding linguistics and retrieval tasks via emojis.&ndash;&nbsp;&nbsp;Read more: The New Modality: Emoji Challenges in Prediction, Anticipation, and Retrieval (Arxiv).
Facebook researchers train models to perform unprecedentedly-detailed analysis of the human body:&hellip;Research has significant military, surveillance implications (though not discussed in paper)&hellip;Facebook researchers have trained a state-of-the-art system named &lsquo;DensePose&rsquo; which can look at 2D photos or videos of people and automatically create high-definition 3D mesh models of the depicted people; an output with broad utility and impact across a number of domains. Their motivation to do this is techniques lik…