---

layout: post
category: product
title: "Import AI 154: Teaching computers how to plan; DeepNude is where dual-use meets pornography; and what happens when we test machine translation systems on real-world data"
date: 2019-07-08 21:46:29
link: https://vrhk.co/30nBgpa
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Can computers learn to plan? Stanford researchers thinks so:&hellip;Turns out being able to plan is similar to figuring out where you are and where you&rsquo;ve been&hellip;Researchers with Stanford University have developed a system that can watch instructional videos on YouTube and learn to look at the start and end of a new video then figure out the appropriate order of actions to take to transition from beginning to end.
What&rsquo;s so hard about this? The real world involves such a vast combinatorial set of possibilities that traditional planning approaches (mostly) aren&rsquo;t able to scale to work within it. &ldquo;One can imagine an indefinitely growing semantic state space, which prevents the application of classical symbolic planning approaches that require a given set of predicates for a well-defined state space&rdquo;. To get around this, they instead try to learn everything in a latent space, essentially slurping in reality and turning it into features, which they then use to map actions and observations into sequences, helping them figure out a plan.
Two models to learn the latent space:&nbsp;&nbsp;&nbsp;The system that derives the latent space and the transformations within it has two main components:
A transition model, which predicts the next state based on the current state and action.
A conjugate constraint model which maps current actions to past actions.
&nbsp;&nbsp;&nbsp;The full model takes in a video and essentially learns the transitions between states by sliding these two models along through time to the desire goal state, sampling actions and then learns the next state.&nbsp;
Two approaches to planning: The researchers experiment with two planning approaches, both of which rely on the features mined by the main system. One approach tries to map current and goal observations into a latent space while also mapping actions to prior actions, then samples from different actions to use to solve its task. The other approach is called &lsquo;walkthrough planning&rsquo; and outputs the visual observations between the current and goal state; this is a less direct approach as it doesn&rsquo;t output actions, but could serve as a useful reward signal for another system.&nbsp;
Dataset: For this work, they use the CrossTask instructional video dataset, which is a compilation of videos showing 83 different tasks, involving things like grilling steak, making pancakes, changing a tire, and so on.
Testing: Spoiler alert &ndash; this kind of task is extremely hard, so get ready for some stay-in-your-chair results. In tests, the researchers find their system using the traditional planning approach can obtain accuracies of around 31.29% tests, with an overall success rate of 12.18%. This compares to a prior state-of-the-art of 24.39% accuracy and 2.89% success rate for &lsquo;Universal Planning Networks&rsquo; (Import AI #90). (Note: UPN is the closest thing to compare to, but has some subtle differences making a direct comparison difficult). They show that the same system when using walkthrough planning can significantly improve scores over prior state-of-the-art systems as well &ndash; &ldquo;our full model is able to plan the correct order for all video clips&rdquo;, they write, compared to baselines which typically fail.&nbsp;
Why this matters: We&rsquo;re starting to see AI systems that use the big, learnable engines used in deep learning research as part of more deliberately structured systems to tackle specific tasks, like learning transitions and plans for video walkthroughs. Planning is an essential part of AI, and being able to learn plans and disentangle plans from actions (and learn appropriate associations) is an inherently complex task; progress here can give us a better sense for progress in the field of AI&nbsp;&nbsp;&nbsp;Read more: Procedure Planning in Instructional Videos (Arxiv).&nbsp;
####################################################
DeepNude: Dual Use concerns meet Pornography; trouble ensues:&hellip;Rock, meet hard place&hellip;What would a person look like without their clothes? That&rsquo;s something people can imagine fairly easily, but has been difficult for AI systems. That is, until we developed a whole bunch of recent systems capable of modeling data distributions and generating synthetic versions of said data; these techniques contributed to the rise of things like &lsquo;deepfakes&rsquo; which let people superimpose the face of one person on that of another in a video. Recently, someone took this a step further with a software tool called DeepNude which automatically removes the clothes of (predominantly women), rendering synthetic images of them in the nude.&nbsp;
Blowback, phase one: The initial DeepNude blowback centered on the dubious motivation for the project and the immense likelihood of the software being used to troll, harass, and abuse women. Coverage in Vice led to such outcry from the community that the creator of DeepNude took the application down &ndash; but not before others had implemented the same capabilities in other software and distributed it around the web.&nbsp;
Rapid proliferation makes norms difficult: Just a couple of days after taking the app down, the creator posted the code of the application to GitHub, saying that because the DeepNude application had already been replicated widely, there was no purpose in keeping the original code private, so they published it online.&nbsp;
Why this matters: DeepNude is an illustration of the larger issues inherent to increasingly powerful AI systems; these things have got really powerful and can be used in a variety of different applications and are also, perhaps unintuitively, relatively easy to program and put together once you have some pre-trained networks lying around (and the norms of publication mean this is always the case). How we figure out new norms around development and publication of such technology will have a significant influence on what happens in society, and if we&rsquo;re not careful we could enable more things like DeepNude.&nbsp;&nbsp;&nbsp;Read the statement justifying code release: Official DeepNude Algorithm (DeepNude GitHub).&nbsp;&nbsp;&nbsp;Read more: This Horrifying App Undresses a Photo of any Woman With a Single Click (Vice). (A special ImportAI shoutout to Samantha Cole, the journalist behind this story; Samantha was the first journalist to cover deepfakes back in 2017 and has been on this beat doing detailed work for a while. Worth a follow!)
####################################################
Have no pity for robots? Watch these self-driving cars try to tackle San Francisco:A short video from Cruise, a self-driving car service owned by General Motors, shows how its cars can now deal with double-parked cars in San Francisco, California.&nbsp;&nbsp;&nbsp;&nbsp;Check out the video here (official Cruise Twitter).####################################################
Think AI services are consistent across cloud providers? Think again:&hellip;Study identifies significant differences in AI inferences made by Google, Amazon, and Microsoft&hellip;Different AI cloud providers have different capabilities, and these under-documented differences could cause problems for software developers, according to research from computer science researchers with Deakin University and Monash University in Australia. In a study, they explore the differences between image labeling AI services from Amazon (&ldquo;AWS Rekognition&rdquo;), Google (&ldquo;Google Cloud Vision&rdquo;) and Microsoft (&ldquo;Azure Computer Vision&rdquo;). The researchers try to work out if &ldquo;computer vision services, as they currently stand, offer consistent behavior, and if not, how is this conveyed to developers (if it is at all)?&rdquo;
Developers may not realize that services can vary from cloud provider to provider, the researchers write; this is because if you look at the underlying storage and compute systems across major cloud providers like Micr…"

---

### Import AI 154: Teaching computers how to plan; DeepNude is where dual-use meets pornography; and what happens when we test machine translation systems on real-world data

Can computers learn to plan? Stanford researchers thinks so:&hellip;Turns out being able to plan is similar to figuring out where you are and where you&rsquo;ve been&hellip;Researchers with Stanford University have developed a system that can watch instructional videos on YouTube and learn to look at the start and end of a new video then figure out the appropriate order of actions to take to transition from beginning to end.
What&rsquo;s so hard about this? The real world involves such a vast combinatorial set of possibilities that traditional planning approaches (mostly) aren&rsquo;t able to scale to work within it. &ldquo;One can imagine an indefinitely growing semantic state space, which prevents the application of classical symbolic planning approaches that require a given set of predicates for a well-defined state space&rdquo;. To get around this, they instead try to learn everything in a latent space, essentially slurping in reality and turning it into features, which they then use to map actions and observations into sequences, helping them figure out a plan.
Two models to learn the latent space:&nbsp;&nbsp;&nbsp;The system that derives the latent space and the transformations within it has two main components:
A transition model, which predicts the next state based on the current state and action.
A conjugate constraint model which maps current actions to past actions.
&nbsp;&nbsp;&nbsp;The full model takes in a video and essentially learns the transitions between states by sliding these two models along through time to the desire goal state, sampling actions and then learns the next state.&nbsp;
Two approaches to planning: The researchers experiment with two planning approaches, both of which rely on the features mined by the main system. One approach tries to map current and goal observations into a latent space while also mapping actions to prior actions, then samples from different actions to use to solve its task. The other approach is called &lsquo;walkthrough planning&rsquo; and outputs the visual observations between the current and goal state; this is a less direct approach as it doesn&rsquo;t output actions, but could serve as a useful reward signal for another system.&nbsp;
Dataset: For this work, they use the CrossTask instructional video dataset, which is a compilation of videos showing 83 different tasks, involving things like grilling steak, making pancakes, changing a tire, and so on.
Testing: Spoiler alert &ndash; this kind of task is extremely hard, so get ready for some stay-in-your-chair results. In tests, the researchers find their system using the traditional planning approach can obtain accuracies of around 31.29% tests, with an overall success rate of 12.18%. This compares to a prior state-of-the-art of 24.39% accuracy and 2.89% success rate for &lsquo;Universal Planning Networks&rsquo; (Import AI #90). (Note: UPN is the closest thing to compare to, but has some subtle differences making a direct comparison difficult). They show that the same system when using walkthrough planning can significantly improve scores over prior state-of-the-art systems as well &ndash; &ldquo;our full model is able to plan the correct order for all video clips&rdquo;, they write, compared to baselines which typically fail.&nbsp;
Why this matters: We&rsquo;re starting to see AI systems that use the big, learnable engines used in deep learning research as part of more deliberately structured systems to tackle specific tasks, like learning transitions and plans for video walkthroughs. Planning is an essential part of AI, and being able to learn plans and disentangle plans from actions (and learn appropriate associations) is an inherently complex task; progress here can give us a better sense for progress in the field of AI&nbsp;&nbsp;&nbsp;Read more: Procedure Planning in Instructional Videos (Arxiv).&nbsp;
####################################################
DeepNude: Dual Use concerns meet Pornography; trouble ensues:&hellip;Rock, meet hard place&hellip;What would a person look like without their clothes? That&rsquo;s something people can imagine fairly easily, but has been difficult for AI systems. That is, until we developed a whole bunch of recent systems capable of modeling data distributions and generating synthetic versions of said data; these techniques contributed to the rise of things like &lsquo;deepfakes&rsquo; which let people superimpose the face of one person on that of another in a video. Recently, someone took this a step further with a software tool called DeepNude which automatically removes the clothes of (predominantly women), rendering synthetic images of them in the nude.&nbsp;
Blowback, phase one: The initial DeepNude blowback centered on the dubious motivation for the project and the immense likelihood of the software being used to troll, harass, and abuse women. Coverage in Vice led to such outcry from the community that the creator of DeepNude took the application down &ndash; but not before others had implemented the same capabilities in other software and distributed it around the web.&nbsp;
Rapid proliferation makes norms difficult: Just a couple of days after taking the app down, the creator posted the code of the application to GitHub, saying that because the DeepNude application had already been replicated widely, there was no purpose in keeping the original code private, so they published it online.&nbsp;
Why this matters: DeepNude is an illustration of the larger issues inherent to increasingly powerful AI systems; these things have got really powerful and can be used in a variety of different applications and are also, perhaps unintuitively, relatively easy to program and put together once you have some pre-trained networks lying around (and the norms of publication mean this is always the case). How we figure out new norms around development and publication of such technology will have a significant influence on what happens in society, and if we&rsquo;re not careful we could enable more things like DeepNude.&nbsp;&nbsp;&nbsp;Read the statement justifying code release: Official DeepNude Algorithm (DeepNude GitHub).&nbsp;&nbsp;&nbsp;Read more: This Horrifying App Undresses a Photo of any Woman With a Single Click (Vice). (A special ImportAI shoutout to Samantha Cole, the journalist behind this story; Samantha was the first journalist to cover deepfakes back in 2017 and has been on this beat doing detailed work for a while. Worth a follow!)
####################################################
Have no pity for robots? Watch these self-driving cars try to tackle San Francisco:A short video from Cruise, a self-driving car service owned by General Motors, shows how its cars can now deal with double-parked cars in San Francisco, California.&nbsp;&nbsp;&nbsp;&nbsp;Check out the video here (official Cruise Twitter).####################################################
Think AI services are consistent across cloud providers? Think again:&hellip;Study identifies significant differences in AI inferences made by Google, Amazon, and Microsoft&hellip;Different AI cloud providers have different capabilities, and these under-documented differences could cause problems for software developers, according to research from computer science researchers with Deakin University and Monash University in Australia. In a study, they explore the differences between image labeling AI services from Amazon (&ldquo;AWS Rekognition&rdquo;), Google (&ldquo;Google Cloud Vision&rdquo;) and Microsoft (&ldquo;Azure Computer Vision&rdquo;). The researchers try to work out if &ldquo;computer vision services, as they currently stand, offer consistent behavior, and if not, how is this conveyed to developers (if it is at all)?&rdquo;
Developers may not realize that services can vary from cloud provider to provider, the researchers write; this is because if you look at the underlying storage and compute systems across major cloud providers like Micr…