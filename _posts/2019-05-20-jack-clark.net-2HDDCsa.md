---

layout: post
category: product
title: "Import AI 147: Alibaba boosts TaoBao performance with Transformer-based recommender system; learning how smart new language models like BERT are; and a $3,000 robot dog"
date: 2019-05-20 16:26:36
link: https://vrhk.co/2HDDCsa
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Weapons of war, what are they good for?&hellip;A bunch of things, but we need to come up with laws to regulate them&hellip;Researchers with ASRC Federal, a company that supplies technology services to the government (with a particular emphasis on intelligence/defense) &nbsp;think advances in AI &ldquo;will lead inevitably to a fully automated, always on [weapon] system&rdquo;, and that we&rsquo;ll need to build such weapons to be aware of human morals, ethics, and the fundamental unknowability of war.
In the paper, the researchers observe that: &ldquo;The feedback loop between ever-increasing technical capability and the political awareness of the decreasing time window for reflective decision-making drives technical evolution towards always-on, automated, reflexive systems.&rdquo; This analysis suggests that in the long-term we&rsquo;re going to see increasingly automated systems being rolled out that will change the character of warfare.
More war, fewer humans: One of the effects of increasing the amount of automation deployed in warfare is to reduce the role humans play in war. &ldquo;We believe that the role of humans in combat systems, barring regulation through treaty, will become more peripheral over time. As such, it is critical to ensure that our design decisions and the implementations of these designs incorporate the values that we wish to express as a national and global culture&rdquo;
Why this matters: This is a quick paper that lays out the concerns of AI+War from a community we don&rsquo;t frequently hear from: people that work as direct suppliers of government technology . It&rsquo;s also encouraging to see the concerns regarding the dual use of AI outlined by the researchers. &ldquo;Determining how to thwart, for example, a terrorist organization turning a facial recognition model into a targeting system for exploding drones is certainly a prudent move,&rdquo; they write.&nbsp;&nbsp;Read more: Integrating Artificial Intelligence into Weapon Systems (Arxiv).
#####################################################
Mapping the brain with the Algonauts project:&hellip;What happens when biological and artificial intelligence researchers collaborate?&hellip;Researchers with the Freie Universitat Berlin, Singapore University Technology , and MIT, have proposed &lsquo;The Algonauts Project&rsquo;, an initiative to get biological and artificial intelligence researchers to work together to understand the brain. As part of the project, the researchers want to learn to build networks that &ldquo;simulate how the brain sees and recognizes objects&rdquo;, and are hosting a competition and workshop in 2019 to encourage work here. The inspiration for this competition is that, today, deep neural networks trained on object classification &ldquo;are currently the model class best performing in predicting visual brain activity&rdquo;.
The first challenge has two components: 
Create machine learning models that predict activity in the early and late parts of the human visual hierarchy in the brain. Participants submit their model responses to a test image set which is compared against held-out fMRI data. This part of the competition measures how well people can build things that model, at fine-detail, activity in the brain at a point in time. 
Create machine learning models that predict brain data from early and late stages of visual processing in the brain. Participants will submit model responses to a test image dataset and compare against held-out magnetoencephalography (MEG) millisecond temporal resolution data. This challenge assesses how well we can model sequences of activities in the brain.
Cautionary tale: The training datasets for the competition are small, consisting of a few hundred pairs of images and brain data in response to the images, so participants may want to use additional data.
Future projects: Future challenges within the Algonauts project might &ldquo;focus on action recognition or involve other sensory modalities such as audition or the tactile sense, or focus on other cognitive functions such as learning and memory&rdquo;.
Why this matters: Cognitive science and AI seem likely to have a mutually reinforcing relationship,l where progress on one domain helps on the other. Competitions like those run by the Algonauts project will generate more activity at the intersection between the two fields, and hopefully push progress forward.&nbsp; Find out more about the first Algonauts challenge here (official competition website). &nbsp;&nbsp;Read more: The Algonauts Project: A Platform for Communication between the Sciences of Biological and Artificial Intelligence (Arxiv).
#####################################################
Alibaba improves TaoBao e-commerce app with better recommendations:&hellip; Chinese mega e-commerce company shows how a Transformer-based system can improve recommendations at scale&hellip;Alibaba researchers have used a Transformer-based system to more efficiently recommend goods to users of Taobao, a massive Chinese e-commerce app. Their system, which they call the &lsquo;user behavior sequence transformer&rsquo; (or &ldquo;BST&rdquo;), lets them take in a bunch of datapoints relating to a specific user, then predict what product to show the user next. The main technical work here is a matter of integrating a &lsquo;Transformer&rsquo;-based core into an existing predictive system used by Alibaba.
Results: The researchers implemented the BST within TaoBao, experimenting with using it to make millions of recommendations. In tests, the BST system let to an online click through rate of 7.57% &ndash; a commercially significant performance increase. &nbsp;
Why this matters: Recommender systems are one of the best examples of &lsquo;the industrialization of AI&rsquo;, and represent a litmus test for whether a particular technique works at scale. In the same way that it was a big deal when a few years ago Google and other companies started switching to deep learning-based approaches for aspects of speech and image recognition, it seems like a big deal now that relatively new AI systems, like the &lsquo;Transformer&rsquo; component, are being integrated into at-scale, business-relevant applications. In general, it seems like the &lsquo;time to market&rsquo; for new AI research is dramatically shorter than for other fields (including software-based ones). I think the implications of this are profound and underexplored.&nbsp; Read more: Behavior Sequence Transformer for E-commerce Recommendation in Alibaba (Arxiv).
#####################################################
Stanford researchers try to commoditize robots with &lsquo;Doggo&rsquo;:&hellip;$3,000 quadruped robot meant to unlock robotics research&hellip;Stanford researchers have created &lsquo;Doggo&rsquo;, a robotic quadruped robot &ldquo;that matches or exceeds common performance metrics of state-of-the-art legged robots&rdquo;. So far, so normal. What makes this research a bit different is the focus on bringing down the cost of the robot &ndash; the researchers say people can build their own Doggo for less than $3000. This is part of a broader trend of academics trying to create low-cost robotics systems, and follows Berkeley releasing its &lsquo;BLUE&rsquo; robotic arm (Import AI 142) and Indian researchers developing a ~$1,000 quadruped named &lsquo;Stoch&rsquo; (Import AI 128).
Doggo is a four-legged robot that can run, jump, and trot around the world. It can even &ndash; and, to be clear, I&rsquo;m not making this up &ndash; use a &ldquo;pronking&rdquo; gait to get around the world. Pronking!
Cheap drives: Like most robots, the main costs inherent to Doggo lie in things it uses to move around. In this case, that&rsquo;s a quasi-direct drive (QDD), a type of drive that &ldquo;increases torque output at the expense of control bandwidth, but maintains the ability to backdrive the motor which allows sensing of external forces based on motor current,&rdquo; they writ…"

---

### Import AI 147: Alibaba boosts TaoBao performance with Transformer-based recommender system; learning how smart new language models like BERT are; and a $3,000 robot dog

Weapons of war, what are they good for?&hellip;A bunch of things, but we need to come up with laws to regulate them&hellip;Researchers with ASRC Federal, a company that supplies technology services to the government (with a particular emphasis on intelligence/defense) &nbsp;think advances in AI &ldquo;will lead inevitably to a fully automated, always on [weapon] system&rdquo;, and that we&rsquo;ll need to build such weapons to be aware of human morals, ethics, and the fundamental unknowability of war.
In the paper, the researchers observe that: &ldquo;The feedback loop between ever-increasing technical capability and the political awareness of the decreasing time window for reflective decision-making drives technical evolution towards always-on, automated, reflexive systems.&rdquo; This analysis suggests that in the long-term we&rsquo;re going to see increasingly automated systems being rolled out that will change the character of warfare.
More war, fewer humans: One of the effects of increasing the amount of automation deployed in warfare is to reduce the role humans play in war. &ldquo;We believe that the role of humans in combat systems, barring regulation through treaty, will become more peripheral over time. As such, it is critical to ensure that our design decisions and the implementations of these designs incorporate the values that we wish to express as a national and global culture&rdquo;
Why this matters: This is a quick paper that lays out the concerns of AI+War from a community we don&rsquo;t frequently hear from: people that work as direct suppliers of government technology . It&rsquo;s also encouraging to see the concerns regarding the dual use of AI outlined by the researchers. &ldquo;Determining how to thwart, for example, a terrorist organization turning a facial recognition model into a targeting system for exploding drones is certainly a prudent move,&rdquo; they write.&nbsp;&nbsp;Read more: Integrating Artificial Intelligence into Weapon Systems (Arxiv).
#####################################################
Mapping the brain with the Algonauts project:&hellip;What happens when biological and artificial intelligence researchers collaborate?&hellip;Researchers with the Freie Universitat Berlin, Singapore University Technology , and MIT, have proposed &lsquo;The Algonauts Project&rsquo;, an initiative to get biological and artificial intelligence researchers to work together to understand the brain. As part of the project, the researchers want to learn to build networks that &ldquo;simulate how the brain sees and recognizes objects&rdquo;, and are hosting a competition and workshop in 2019 to encourage work here. The inspiration for this competition is that, today, deep neural networks trained on object classification &ldquo;are currently the model class best performing in predicting visual brain activity&rdquo;.
The first challenge has two components: 
Create machine learning models that predict activity in the early and late parts of the human visual hierarchy in the brain. Participants submit their model responses to a test image set which is compared against held-out fMRI data. This part of the competition measures how well people can build things that model, at fine-detail, activity in the brain at a point in time. 
Create machine learning models that predict brain data from early and late stages of visual processing in the brain. Participants will submit model responses to a test image dataset and compare against held-out magnetoencephalography (MEG) millisecond temporal resolution data. This challenge assesses how well we can model sequences of activities in the brain.
Cautionary tale: The training datasets for the competition are small, consisting of a few hundred pairs of images and brain data in response to the images, so participants may want to use additional data.
Future projects: Future challenges within the Algonauts project might &ldquo;focus on action recognition or involve other sensory modalities such as audition or the tactile sense, or focus on other cognitive functions such as learning and memory&rdquo;.
Why this matters: Cognitive science and AI seem likely to have a mutually reinforcing relationship,l where progress on one domain helps on the other. Competitions like those run by the Algonauts project will generate more activity at the intersection between the two fields, and hopefully push progress forward.&nbsp; Find out more about the first Algonauts challenge here (official competition website). &nbsp;&nbsp;Read more: The Algonauts Project: A Platform for Communication between the Sciences of Biological and Artificial Intelligence (Arxiv).
#####################################################
Alibaba improves TaoBao e-commerce app with better recommendations:&hellip; Chinese mega e-commerce company shows how a Transformer-based system can improve recommendations at scale&hellip;Alibaba researchers have used a Transformer-based system to more efficiently recommend goods to users of Taobao, a massive Chinese e-commerce app. Their system, which they call the &lsquo;user behavior sequence transformer&rsquo; (or &ldquo;BST&rdquo;), lets them take in a bunch of datapoints relating to a specific user, then predict what product to show the user next. The main technical work here is a matter of integrating a &lsquo;Transformer&rsquo;-based core into an existing predictive system used by Alibaba.
Results: The researchers implemented the BST within TaoBao, experimenting with using it to make millions of recommendations. In tests, the BST system let to an online click through rate of 7.57% &ndash; a commercially significant performance increase. &nbsp;
Why this matters: Recommender systems are one of the best examples of &lsquo;the industrialization of AI&rsquo;, and represent a litmus test for whether a particular technique works at scale. In the same way that it was a big deal when a few years ago Google and other companies started switching to deep learning-based approaches for aspects of speech and image recognition, it seems like a big deal now that relatively new AI systems, like the &lsquo;Transformer&rsquo; component, are being integrated into at-scale, business-relevant applications. In general, it seems like the &lsquo;time to market&rsquo; for new AI research is dramatically shorter than for other fields (including software-based ones). I think the implications of this are profound and underexplored.&nbsp; Read more: Behavior Sequence Transformer for E-commerce Recommendation in Alibaba (Arxiv).
#####################################################
Stanford researchers try to commoditize robots with &lsquo;Doggo&rsquo;:&hellip;$3,000 quadruped robot meant to unlock robotics research&hellip;Stanford researchers have created &lsquo;Doggo&rsquo;, a robotic quadruped robot &ldquo;that matches or exceeds common performance metrics of state-of-the-art legged robots&rdquo;. So far, so normal. What makes this research a bit different is the focus on bringing down the cost of the robot &ndash; the researchers say people can build their own Doggo for less than $3000. This is part of a broader trend of academics trying to create low-cost robotics systems, and follows Berkeley releasing its &lsquo;BLUE&rsquo; robotic arm (Import AI 142) and Indian researchers developing a ~$1,000 quadruped named &lsquo;Stoch&rsquo; (Import AI 128).
Doggo is a four-legged robot that can run, jump, and trot around the world. It can even &ndash; and, to be clear, I&rsquo;m not making this up &ndash; use a &ldquo;pronking&rdquo; gait to get around the world. Pronking!
Cheap drives: Like most robots, the main costs inherent to Doggo lie in things it uses to move around. In this case, that&rsquo;s a quasi-direct drive (QDD), a type of drive that &ldquo;increases torque output at the expense of control bandwidth, but maintains the ability to backdrive the motor which allows sensing of external forces based on motor current,&rdquo; they writ…