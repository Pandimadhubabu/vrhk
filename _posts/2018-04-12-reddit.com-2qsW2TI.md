---

layout: post
category: threads
title: "[D] Negative Attention Weights"
date: 2018-04-12 10:23:11
link: https://vrhk.co/2qsW2TI
image: https://www.redditstatic.com/icon.png
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "Most attention mechanisms involve a softmax or normalization to make all the different attentions scores to sum up to 1. Is there any work that..."

---

### [D] Negative Attention Weights â€¢ r/MachineLearning

Most attention mechanisms involve a softmax or normalization to make all the different attentions scores to sum up to 1. Is there any work that...