---

layout: post
category: product
title: "Import AI #83: Cloning voices with a few audio samples, why malicious actors might mess with AI, and the industryacademia compute gap."
date: 2018-02-26 21:07:19
link: https://vrhk.co/2Fx0uIc
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s0.wp.com/i/webclip.png
excerpt: "### IMPENDING PROBLEM KLAXON ###Preparing for Malicious Uses of AI:&hellip;Bad things happen when good people unwittingly release AI platforms that bad people can modify to turn good AIs into bad AIs&hellip;AI, particularly deep learning, is a technology of such obvious power and utility that it seems likely malicious actors will pervert the technology and use it in ways it wasn&rsquo;t intended. That has happened to basically every other significant technology of note: axes can be used to chop down trees or cut off heads, electricity can light a home or electrocute a person, a lab bench can be used to construct cures or poisons, and so on. But AI has some other characteristics that make it particularly dangerous: it&rsquo;s, to use a phrase Rodney Brooks has used in the past to describe robots, &ldquo;fast, cheap, and out of control&rdquo;; today&rsquo;s AI systems run on generic hardware, are mostly embodied in open source software, and are seeing capabilities increase according to underlying algorithmic and compute progress, both of which are happening in the open. That means the technology holds the possibility of doing immense good in the world as well as doing immense harm &ndash; and currently the AI community is broadly making everything available in the open, which seems somewhat acceptable today but probably unacceptable in the future given a few cranks more of Moore&rsquo;s Law combined with algorithmic progression.&nbsp;&nbsp;Omni-Use Alert: AI is more than a &lsquo;dual-use&rsquo; technology, it&rsquo;s an omni-use technology. That means that figuring out how to regulate it to prevent bad people doing bad things with it is (mostly) a non-starter. Instead, we need to explore new governance regimes, community norms, standards on information sharing, and so on.&nbsp;&nbsp;101 Pages of Problems: If you&rsquo;re interested in taking a deeper look at this issue check out this report which a bunch of people (including me) spent the last year working on: The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation (Arxiv). You can also check out a summary via this OpenAI blog post about the report. I&rsquo;m hoping to broaden the discussion of Omni-Use AI in the coming months and will be trying to host events and workshops relating to this question. If you want to chat with me about it, then please get in touch. We have a limited window of time to act as a community before dangerous things start happening &ndash; let&rsquo;s get to work.
Baidu clones voices with few samples:&hellip;Don&rsquo;t worry about the omni-use concerns&hellip;Baidu research has trained an AI that can listen to a small quantity of a single person&rsquo;s voice and then use that information to condition any network to sound like that person. This form of &lsquo;adaptation&rsquo; is potentially very powerful, especially when trying to create AI services that work for multiple users with multiple accents, but it&rsquo;s also somewhat frightening, as if it gets much better it will utterly compromize our trust in the aural domain. However, the ability of the system to clone speech today still leaves much to be desired, with the best performing systems requiring a hundred distinct voice samples and still sounding like a troll speaking from the bottom of a well, so we&rsquo;ve got a few more compute turns yet before we run into real problems &ndash; but they&rsquo;re coming.&nbsp;&nbsp;What it means: Techniques like this bring closer the day when a person can say something into a compromized device, have their voice recorded by a malicious actor, and have that sample be used to train new text-to-speech systems to say completely new things. Once that era arrives then the whole notion of &ldquo;trust&rsquo; and audio samples of a person&rsquo;s voice will completely change, causing normal people to worry about these sorts of things as well as state-based intelligence organizations.&nbsp;&nbsp;Results: To get a good idea of the results, listen to the samples on this web page her (Voice Cloning: Baidu).&nbsp;&nbsp;Read more: Neural Voice Cloning with a Few Samples (Baidu Blog).&nbsp;&nbsp;Read more: Neural Voice Cloning with a Few Samples (Arxiv).
Why robots in the future could be used as speedbumps for pedestrians:&hellip;Researchers show how people slow down in the presence&nbsp;of patrolling robots&hellip;Researchers with the Department of Electrical and Computer Engineering at the Stevens Institute of Technology in Hoboken, New Jersey, have examined how crowds of people react to robots. Their research is a study of &ldquo;passive Human Robot Interaction (HRI) in an exit corridor for the purpose of robot-assisted pedestrian flow regulation.&rdquo;&nbsp;&nbsp;The results: &ldquo;Our experimental results show that in an exit corridor environment, a robot moving in a direction perpendicular to that of the uni-directional pedestrian flow can slow down the uni-directional flow, and the faster the robot moves, the lower the average pedestrian velocity becomes. Furthermore, the effect of the robot on the pedestrian velocity is more significant when people walk at a faster speed,&rdquo; they write. In other words: pedestrians will avoid a dumb robot moving right in front of them.&nbsp; Methods: To conduct the experiment, the researchers used a customized &lsquo;Adept Pioneer P3-DX mobile robot&rsquo; which was programmed to move at various speeds perpendicular to the pedestrian flow direction. To collect data, they outfitted a room with five Microsoft Kinect 3D sensors along with pedestrian detection and tracking via OpenPTrack.&nbsp; What it means: As robots become cheap thanks to a proliferation of low-cost sensors and hardware platforms it&rsquo;s likely that people will deploy more of them into the real world. Figuring out how to have very dumb, non-reactive robots do useful things will further drive adoption of these technologies and yield to increasing economies of scale to further lower the cost of the hardware platform and increase the spread of the technology. Based on this research, you can probably look forward to a future where airports and transit systems are thronged with robots shuttling to and fro across crowded routes, exerting implicit crowd-speed-control through thick-as-a-brick automation.&nbsp;&nbsp;Read more: Pedestrian-Robot Interaction Experiments in an Exit Corridor (Arxiv).
Why your next self-driving car could be sent to you with the help of reinforcement learning:&hellip;Researchers with Chinese ride-hailing giant Didi Chuxing simulate and benchmark RL algorithms for strategic car assignment&hellip;Researchers from Chinese ride-hailing giant Didi Chuxing and Michigan State University have published research on using reinforcement learning to better manage the allocation of vehicles across a given urban area. The researchers propose two algorithms to tackle this: contextual multi-agent actor-critic (cA2C) and contextual deep Q-learning (cDQN); both algorithms implement tweaks to account for geographical no-go areas (like lakes) and for the presence of other collaborative agents. The algorithms&rsquo; reward function is &ldquo;to maximize the gross merchandise volume (GMV: the value of all the orders served) of the platform by repositioning available vehicles to the locations with larger demand-supply gap than the current one&rdquo;.&nbsp;&nbsp;The dataset and environment: The researchers test their algorithms in a custom-designed large-scale gridworld which is fed with real data from Didi Chuxing&rsquo;s fleet management system. The data is based on rides taken in Chengdu China over four consecutive weeks and includes information on order price, origin, destination, and duration; as well as the trajectories and status of real Didi vehicles.&nbsp;&nbsp;The results: The researchers test out their approach by simulating the real past scenarios without fleet management; with a bunch of different techniques including T-SARSA, DQN, Value-Ite…"

---

### Import AI #83: Cloning voices with a few audio samples, why malicious actors might mess with AI, and the industryacademia compute gap.

### IMPENDING PROBLEM KLAXON ###Preparing for Malicious Uses of AI:&hellip;Bad things happen when good people unwittingly release AI platforms that bad people can modify to turn good AIs into bad AIs&hellip;AI, particularly deep learning, is a technology of such obvious power and utility that it seems likely malicious actors will pervert the technology and use it in ways it wasn&rsquo;t intended. That has happened to basically every other significant technology of note: axes can be used to chop down trees or cut off heads, electricity can light a home or electrocute a person, a lab bench can be used to construct cures or poisons, and so on. But AI has some other characteristics that make it particularly dangerous: it&rsquo;s, to use a phrase Rodney Brooks has used in the past to describe robots, &ldquo;fast, cheap, and out of control&rdquo;; today&rsquo;s AI systems run on generic hardware, are mostly embodied in open source software, and are seeing capabilities increase according to underlying algorithmic and compute progress, both of which are happening in the open. That means the technology holds the possibility of doing immense good in the world as well as doing immense harm &ndash; and currently the AI community is broadly making everything available in the open, which seems somewhat acceptable today but probably unacceptable in the future given a few cranks more of Moore&rsquo;s Law combined with algorithmic progression.&nbsp;&nbsp;Omni-Use Alert: AI is more than a &lsquo;dual-use&rsquo; technology, it&rsquo;s an omni-use technology. That means that figuring out how to regulate it to prevent bad people doing bad things with it is (mostly) a non-starter. Instead, we need to explore new governance regimes, community norms, standards on information sharing, and so on.&nbsp;&nbsp;101 Pages of Problems: If you&rsquo;re interested in taking a deeper look at this issue check out this report which a bunch of people (including me) spent the last year working on: The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation (Arxiv). You can also check out a summary via this OpenAI blog post about the report. I&rsquo;m hoping to broaden the discussion of Omni-Use AI in the coming months and will be trying to host events and workshops relating to this question. If you want to chat with me about it, then please get in touch. We have a limited window of time to act as a community before dangerous things start happening &ndash; let&rsquo;s get to work.
Baidu clones voices with few samples:&hellip;Don&rsquo;t worry about the omni-use concerns&hellip;Baidu research has trained an AI that can listen to a small quantity of a single person&rsquo;s voice and then use that information to condition any network to sound like that person. This form of &lsquo;adaptation&rsquo; is potentially very powerful, especially when trying to create AI services that work for multiple users with multiple accents, but it&rsquo;s also somewhat frightening, as if it gets much better it will utterly compromize our trust in the aural domain. However, the ability of the system to clone speech today still leaves much to be desired, with the best performing systems requiring a hundred distinct voice samples and still sounding like a troll speaking from the bottom of a well, so we&rsquo;ve got a few more compute turns yet before we run into real problems &ndash; but they&rsquo;re coming.&nbsp;&nbsp;What it means: Techniques like this bring closer the day when a person can say something into a compromized device, have their voice recorded by a malicious actor, and have that sample be used to train new text-to-speech systems to say completely new things. Once that era arrives then the whole notion of &ldquo;trust&rsquo; and audio samples of a person&rsquo;s voice will completely change, causing normal people to worry about these sorts of things as well as state-based intelligence organizations.&nbsp;&nbsp;Results: To get a good idea of the results, listen to the samples on this web page her (Voice Cloning: Baidu).&nbsp;&nbsp;Read more: Neural Voice Cloning with a Few Samples (Baidu Blog).&nbsp;&nbsp;Read more: Neural Voice Cloning with a Few Samples (Arxiv).
Why robots in the future could be used as speedbumps for pedestrians:&hellip;Researchers show how people slow down in the presence&nbsp;of patrolling robots&hellip;Researchers with the Department of Electrical and Computer Engineering at the Stevens Institute of Technology in Hoboken, New Jersey, have examined how crowds of people react to robots. Their research is a study of &ldquo;passive Human Robot Interaction (HRI) in an exit corridor for the purpose of robot-assisted pedestrian flow regulation.&rdquo;&nbsp;&nbsp;The results: &ldquo;Our experimental results show that in an exit corridor environment, a robot moving in a direction perpendicular to that of the uni-directional pedestrian flow can slow down the uni-directional flow, and the faster the robot moves, the lower the average pedestrian velocity becomes. Furthermore, the effect of the robot on the pedestrian velocity is more significant when people walk at a faster speed,&rdquo; they write. In other words: pedestrians will avoid a dumb robot moving right in front of them.&nbsp; Methods: To conduct the experiment, the researchers used a customized &lsquo;Adept Pioneer P3-DX mobile robot&rsquo; which was programmed to move at various speeds perpendicular to the pedestrian flow direction. To collect data, they outfitted a room with five Microsoft Kinect 3D sensors along with pedestrian detection and tracking via OpenPTrack.&nbsp; What it means: As robots become cheap thanks to a proliferation of low-cost sensors and hardware platforms it&rsquo;s likely that people will deploy more of them into the real world. Figuring out how to have very dumb, non-reactive robots do useful things will further drive adoption of these technologies and yield to increasing economies of scale to further lower the cost of the hardware platform and increase the spread of the technology. Based on this research, you can probably look forward to a future where airports and transit systems are thronged with robots shuttling to and fro across crowded routes, exerting implicit crowd-speed-control through thick-as-a-brick automation.&nbsp;&nbsp;Read more: Pedestrian-Robot Interaction Experiments in an Exit Corridor (Arxiv).
Why your next self-driving car could be sent to you with the help of reinforcement learning:&hellip;Researchers with Chinese ride-hailing giant Didi Chuxing simulate and benchmark RL algorithms for strategic car assignment&hellip;Researchers from Chinese ride-hailing giant Didi Chuxing and Michigan State University have published research on using reinforcement learning to better manage the allocation of vehicles across a given urban area. The researchers propose two algorithms to tackle this: contextual multi-agent actor-critic (cA2C) and contextual deep Q-learning (cDQN); both algorithms implement tweaks to account for geographical no-go areas (like lakes) and for the presence of other collaborative agents. The algorithms&rsquo; reward function is &ldquo;to maximize the gross merchandise volume (GMV: the value of all the orders served) of the platform by repositioning available vehicles to the locations with larger demand-supply gap than the current one&rdquo;.&nbsp;&nbsp;The dataset and environment: The researchers test their algorithms in a custom-designed large-scale gridworld which is fed with real data from Didi Chuxing&rsquo;s fleet management system. The data is based on rides taken in Chengdu China over four consecutive weeks and includes information on order price, origin, destination, and duration; as well as the trajectories and status of real Didi vehicles.&nbsp;&nbsp;The results: The researchers test out their approach by simulating the real past scenarios without fleet management; with a bunch of different techniques including T-SARSA, DQN, Value-Ite…