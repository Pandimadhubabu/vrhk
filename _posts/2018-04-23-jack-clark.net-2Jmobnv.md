---

layout: post
category: product
title: "Import AI: #91: European countries unite for AI grant plan; why the future of AI sensing is spatial; and testing language AI with GLUE."
date: 2018-04-23 18:22:02
link: https://vrhk.co/2Jmobnv
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Want bigger networks with lower variance? Physics to the rescue!&hellip;Combining control theory and machine learning leads to good things..Researchers with NNAISENSE, a European artificial intelligence startup, have published details on NAIS-Net (Non-Autonomous Input-Output Stable Network), a new type of neural network architecture that they say can be trained to depths of ten or twenty times greater than other networks (eg, Residual Networks, Highway Networks) while offering greater guarantees of stability.&nbsp;&nbsp;Physics + AI: The network design takes inspiration from control theory and physics and yields a component that lets designers build systems which promise to be more adaptive to varying types of input data and therefore can be trained to greater degrees of convergence for a given task. NAIS-Nets essentially shrink the size of the dartboard that the results of any given run will fall into once trained to completion, offering the potential for lower variability and therefore higher repeatability in network training. &nbsp;&nbsp;Scale: &ldquo;NAIS-Nets can also be 10 to 20 times deeper than the original ResNet without increasing the total number of network parameters, and, by stacking several stable NAIS-Net blocks, models that implement pattern-dependent processing depth can be trained without requiring any normalization,&rdquo; the researchers write.&nbsp; Results: In tests on CIFAR-100 the researchers find that a NAIS-Net can roughly match the performance of a residual network but with significantly lower variance. The architecture hasn&rsquo;t yet been tested on ImageNet, though, which is larger and seems more like the gold standard to evaluate a model on. &nbsp;&nbsp;Why it matters: One of the problems with current AI techniques is that we don&rsquo;t really understand how they work at a deep and principled level and this is empirically verifiable via the fact we can offer fairly poor guarantees about variance, generalization, and performance tradeoffs during compression. Approaches like NAIS-Nets seem to reduce our uncertainty in some of these areas, suggesting we&rsquo;re getting better at designing systems that have a sufficiently rich mathematical justification that we can offer better guarantees about some of their performance parameters. This is further indication that we&rsquo;re getting better at creating systems that we can understand and make stronger prior claims about, which seems to be a necessary foundation from which to build more elaborate systems in the future. &nbsp;&nbsp;Read more: NAIS-Net: Stable Deep Networks from Non-Autonomous Differential Equations (Arxiv).
European countries join up to ensure the AI revolution doesn&rsquo;t pass them by:&hellip;the EU AI power bloc emerges as countries seek to avoid what happened with cloud computing&hellip;25 European countries have signed a letter indicating intent to &ldquo;join forces&rdquo; on developing artificial intelligence. What the letter amounts to is a promise in good faith from each of the signatories that they will attempt to coordinate with eachother as they carry out their respective national development programs.&nbsp; &ldquo;Cooperation will focus on reinforcing European AI research centers, creating synergies in R&amp;D&amp;I funding schemes across Europe, and exchanging views on the impact of AI on society and the economy. Member States will engage in a continuous dialogue with the Commission, which will act as a facilitator,&rdquo; according to a prepared quote from European Commissioners Andrus Ansip and Mariya Gabriel. &nbsp;&nbsp;Why it matters: Both China and the US have structural advantages for the development of AI as a consequence of their scale (hundreds of millions of people speaking and writing in the same language) as well as their ability to carry out well-funded national research initiatives. Individual European countries can&rsquo;t match these assets or investment so they&rsquo;ll need to band together or else, much like the cloud computing revolution, they&rsquo;ll end up without any major companies and will therefore lack political and economic influence in the AI era. &nbsp;&nbsp;Read more: EU Member States sign up to cooperate on Artificial Intelligence (European Commission).
Why the future of AI is Spatial AI, and what this means for robots, drones, and anything that senses the world:&hellip;What does the current landscape of simultaneous&nbsp;location and mapping algorithms tell us about the future of how robots will see the world?&hellip;SLAM researcher Andrew Davison has written a paper surveying the current simultaneous, location and mapping (SLAM) landscape and predicting how it will evolve in the future based on contemporary algorithmic trends. For real-world AI systems to achieve much of their promise they will need to have what he terms &lsquo;Spatial AI&rsquo;; the suite of cognitive-like abilities that machines will need to perceive and categorize the world around themselves so that they can act effectively. This hypothetical Spatial AI system will, he hypothesizes, be central to future real world AI as it &ldquo;incrementally builds and maintains a generally useful, close to metric scene representation, in real-time and from primarily visual input, and with quantifiable performance metrics&rdquo;, allowing people to develop much richer AI applications.&nbsp; The gap between today and Spatial AI: Today&rsquo;s SLAM systems are being changed by the arrival of learned methods to to accompany hand-written rules for key capabilities, particularly in the space of systems that build maps of the surrounding environment. The Spatial AI systems of the future will likely incorporate many more learned capabilities especially for resolving ambiguity or predicting changes in the world, and will need to do this across a variety of different chip architectures to maximize performance. &nbsp;&nbsp;A global map born from many &lsquo;Spatial AIs&rsquo;: Once the world has a few systems with this kind of Spatial AI capability they will also likely pool their insights about the world into a single, globally shared map, which will be constantly updated via all of the devices that rely on it. This means once a system identifies where it is it may not need to do as much on-device processing as it can pull contextual information from the cloud.&nbsp; What might such a device look like? Multiple cameras and sensors whose form factor will change according to the goal, for instance, &ldquo;a future household robot is likely to have navigation cameras which are centrally located on its body and specialized extra cameras, perhaps mounted on its wrists to aid manipulation.&rdquo; These cameras will maintain a world model that provides the system with a continuously updated location context, along with semantic information about the world around in. The system will also constantly check new information against a forward predictive scene model to help it anticipate and respond to changes in its environment. Computationally, these systems will label the world around themselves, track themselves within it, map everything into the same space, and perform self-supervised learning to integrate new sensory inputs. Ultimately, if the world model becomes good enough then the system will only need to sample information from its sensors which is different to what it predicted, letting it further optimize its own perception for efficiency. &nbsp;&nbsp;Testing: One tough question that this idea provokes is how we can assess the performance of such Spatial AI systems. SLAM benchmarks tend to be overly narrow or restrictive, with some researchers preferring instead to make subjective, qualitative assessments of SLAM progress. Davison suggests the usage of benchmarks like SlamBench which measure performance in terms of accuracy and computational costs across a bunch of different processor platforms. Benchmarking SLAM performance is also highly contingent on the platf…"

---

### Import AI: #91: European countries unite for AI grant plan; why the future of AI sensing is spatial; and testing language AI with GLUE.

Want bigger networks with lower variance? Physics to the rescue!&hellip;Combining control theory and machine learning leads to good things..Researchers with NNAISENSE, a European artificial intelligence startup, have published details on NAIS-Net (Non-Autonomous Input-Output Stable Network), a new type of neural network architecture that they say can be trained to depths of ten or twenty times greater than other networks (eg, Residual Networks, Highway Networks) while offering greater guarantees of stability.&nbsp;&nbsp;Physics + AI: The network design takes inspiration from control theory and physics and yields a component that lets designers build systems which promise to be more adaptive to varying types of input data and therefore can be trained to greater degrees of convergence for a given task. NAIS-Nets essentially shrink the size of the dartboard that the results of any given run will fall into once trained to completion, offering the potential for lower variability and therefore higher repeatability in network training. &nbsp;&nbsp;Scale: &ldquo;NAIS-Nets can also be 10 to 20 times deeper than the original ResNet without increasing the total number of network parameters, and, by stacking several stable NAIS-Net blocks, models that implement pattern-dependent processing depth can be trained without requiring any normalization,&rdquo; the researchers write.&nbsp; Results: In tests on CIFAR-100 the researchers find that a NAIS-Net can roughly match the performance of a residual network but with significantly lower variance. The architecture hasn&rsquo;t yet been tested on ImageNet, though, which is larger and seems more like the gold standard to evaluate a model on. &nbsp;&nbsp;Why it matters: One of the problems with current AI techniques is that we don&rsquo;t really understand how they work at a deep and principled level and this is empirically verifiable via the fact we can offer fairly poor guarantees about variance, generalization, and performance tradeoffs during compression. Approaches like NAIS-Nets seem to reduce our uncertainty in some of these areas, suggesting we&rsquo;re getting better at designing systems that have a sufficiently rich mathematical justification that we can offer better guarantees about some of their performance parameters. This is further indication that we&rsquo;re getting better at creating systems that we can understand and make stronger prior claims about, which seems to be a necessary foundation from which to build more elaborate systems in the future. &nbsp;&nbsp;Read more: NAIS-Net: Stable Deep Networks from Non-Autonomous Differential Equations (Arxiv).
European countries join up to ensure the AI revolution doesn&rsquo;t pass them by:&hellip;the EU AI power bloc emerges as countries seek to avoid what happened with cloud computing&hellip;25 European countries have signed a letter indicating intent to &ldquo;join forces&rdquo; on developing artificial intelligence. What the letter amounts to is a promise in good faith from each of the signatories that they will attempt to coordinate with eachother as they carry out their respective national development programs.&nbsp; &ldquo;Cooperation will focus on reinforcing European AI research centers, creating synergies in R&amp;D&amp;I funding schemes across Europe, and exchanging views on the impact of AI on society and the economy. Member States will engage in a continuous dialogue with the Commission, which will act as a facilitator,&rdquo; according to a prepared quote from European Commissioners Andrus Ansip and Mariya Gabriel. &nbsp;&nbsp;Why it matters: Both China and the US have structural advantages for the development of AI as a consequence of their scale (hundreds of millions of people speaking and writing in the same language) as well as their ability to carry out well-funded national research initiatives. Individual European countries can&rsquo;t match these assets or investment so they&rsquo;ll need to band together or else, much like the cloud computing revolution, they&rsquo;ll end up without any major companies and will therefore lack political and economic influence in the AI era. &nbsp;&nbsp;Read more: EU Member States sign up to cooperate on Artificial Intelligence (European Commission).
Why the future of AI is Spatial AI, and what this means for robots, drones, and anything that senses the world:&hellip;What does the current landscape of simultaneous&nbsp;location and mapping algorithms tell us about the future of how robots will see the world?&hellip;SLAM researcher Andrew Davison has written a paper surveying the current simultaneous, location and mapping (SLAM) landscape and predicting how it will evolve in the future based on contemporary algorithmic trends. For real-world AI systems to achieve much of their promise they will need to have what he terms &lsquo;Spatial AI&rsquo;; the suite of cognitive-like abilities that machines will need to perceive and categorize the world around themselves so that they can act effectively. This hypothetical Spatial AI system will, he hypothesizes, be central to future real world AI as it &ldquo;incrementally builds and maintains a generally useful, close to metric scene representation, in real-time and from primarily visual input, and with quantifiable performance metrics&rdquo;, allowing people to develop much richer AI applications.&nbsp; The gap between today and Spatial AI: Today&rsquo;s SLAM systems are being changed by the arrival of learned methods to to accompany hand-written rules for key capabilities, particularly in the space of systems that build maps of the surrounding environment. The Spatial AI systems of the future will likely incorporate many more learned capabilities especially for resolving ambiguity or predicting changes in the world, and will need to do this across a variety of different chip architectures to maximize performance. &nbsp;&nbsp;A global map born from many &lsquo;Spatial AIs&rsquo;: Once the world has a few systems with this kind of Spatial AI capability they will also likely pool their insights about the world into a single, globally shared map, which will be constantly updated via all of the devices that rely on it. This means once a system identifies where it is it may not need to do as much on-device processing as it can pull contextual information from the cloud.&nbsp; What might such a device look like? Multiple cameras and sensors whose form factor will change according to the goal, for instance, &ldquo;a future household robot is likely to have navigation cameras which are centrally located on its body and specialized extra cameras, perhaps mounted on its wrists to aid manipulation.&rdquo; These cameras will maintain a world model that provides the system with a continuously updated location context, along with semantic information about the world around in. The system will also constantly check new information against a forward predictive scene model to help it anticipate and respond to changes in its environment. Computationally, these systems will label the world around themselves, track themselves within it, map everything into the same space, and perform self-supervised learning to integrate new sensory inputs. Ultimately, if the world model becomes good enough then the system will only need to sample information from its sensors which is different to what it predicted, letting it further optimize its own perception for efficiency. &nbsp;&nbsp;Testing: One tough question that this idea provokes is how we can assess the performance of such Spatial AI systems. SLAM benchmarks tend to be overly narrow or restrictive, with some researchers preferring instead to make subjective, qualitative assessments of SLAM progress. Davison suggests the usage of benchmarks like SlamBench which measure performance in terms of accuracy and computational costs across a bunch of different processor platforms. Benchmarking SLAM performance is also highly contingent on the platf…