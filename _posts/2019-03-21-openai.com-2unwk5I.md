---

layout: post
category: research
title: "Implicit Generation and Generalization Methods for Energy-Based Models"
date: 2019-03-21 16:08:41
link: https://vrhk.co/2unwk5I
image: https://openai.com/content/images/2019/03/imagenet128x128-3.png
domain: openai.com
author: "OpenAI"
icon: https://openai.com/assets/images/favicon.png
excerpt: "We've made progress towards stable and scalable training of energy-based models [<http://yann.lecun.com/exdb/publis/pdf/lecun-06.pdf>] (EBMs) resulting in better sample quality and generalization ability than existing models. Generation in EBMs spends more compute to continually refine its answers and doing so can generate samples competitive with GANs [<https://arxiv.org/abs/1406.2661>] at low temperatures[1], while also having mode coverage guarantees of likelihood-based models [<https://arxiv.or>"

---

### Implicit Generation and Generalization Methods for Energy-Based Models

We've made progress towards stable and scalable training of energy-based models [<http://yann.lecun.com/exdb/publis/pdf/lecun-06.pdf>] (EBMs) resulting in better sample quality and generalization ability than existing models. Generation in EBMs spends more compute to continually refine its answers and doing so can generate samples competitive with GANs [<https://arxiv.org/abs/1406.2661>] at low temperatures[1], while also having mode coverage guarantees of likelihood-based models [<https://arxiv.or>